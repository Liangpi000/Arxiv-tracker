<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-10 04:07</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260210_0407</div>
    <div class="row"><div class="card">
<div class="title">MedMO: Grounding and Understanding Multimodal Large Language Model for Medical Images</div>
<div class="meta-line">Authors: Ankan Deria, Komal Kumar, Adinath Madhavrao Dukre, Eran Segal, Salman Khan, Imran Razzak</div>
<div class="meta-line">First: 2026-02-06T18:59:59+00:00 · Latest: 2026-02-06T18:59:59+00:00</div>
<div class="meta-line">Comments: 21 pages, 6 figures and 4 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06965v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06965v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://genmilab.github.io/MedMO-Page">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal large language models (MLLMs) have rapidly advanced, yet their adoption in medicine remains limited by gaps in domain coverage, modality alignment, and grounded reasoning. In this work, we introduce MedMO, a medical foundation model built upon a generalized MLLM architecture and trained exclusively on large-scale, domain-specific data. MedMO follows a multi-stage training recipe: (i) cross-modal pretraining to align heterogeneous visual encoders with a medical language backbone; (ii) instruction tuning on multi-task supervision that spans captioning, VQA, report generation, retrieval, and grounded disease localization with bounding boxes; and (iii) reinforcement learning with verifiable rewards that combine factuality checks with a box-level GIoU reward to strengthen spatial grounding and step-by-step reasoning in complex clinical scenarios. MedMO consistently outperforms strong open-source medical MLLMs across multiple modalities and tasks. On VQA benchmarks, MedMO achieves an average accuracy improvement of +13.7% over the baseline and performs within 1.9% of the SOTA Fleming-VL. For text-based QA, it attains +6.9% over the baseline and +14.5% over Fleming-VL. In medical report generation, MedMO delivers significant gains in both semantic and clinical accuracy. Moreover, it exhibits strong grounding capability, achieving an IoU improvement of +40.4 over the baseline and +37.0% over Fleming-VL, underscoring its robust spatial reasoning and localization performance. Evaluations across radiology, ophthalmology, and pathology-microscopy confirm MedMO&#x27;s broad cross-modality generalization. We release two versions of MedMO: 4B and 8B. Project is available at https://genmilab.github.io/MedMO-Page</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MedMO：基于多模态大型语言模型的医学图像理解</div>
<div class="mono" style="margin-top:8px">多模态大型语言模型（MLLMs）已迅速发展，但在医学领域的应用受限于领域覆盖范围、模态对齐和基于事实的推理方面的差距。本文介绍了MedMO，这是一种基于通用MLLM架构并仅在大规模、领域特定数据上训练的医学基础模型。MedMO采用多阶段训练方案：（i）跨模态预训练，将异构视觉编码器与医学语言骨干对齐；（ii）指令调优，涵盖多任务监督，包括描述生成、VQA、报告生成、检索和带有边界框的基于事实的疾病定位；（iii）结合事实检查和边界框级别的GIoU奖励的强化学习，以增强复杂临床场景中的空间定位和逐步推理。MedMO在多个模态和任务上均优于强大的开源医学MLLMs。在VQA基准测试中，MedMO的平均准确率提高了13.7%，并在Fleming-VL基准测试中仅落后1.9%。对于基于文本的问答，它比基线提高了6.9%，比Fleming-VL提高了14.5%。在医学报告生成方面，MedMO在语义和临床准确性方面取得了显著进步。此外，它还表现出强大的空间定位能力，边界框IoU提高了40.4%，比Fleming-VL提高了37.0%，突显了其稳健的空间推理和定位性能。放射学、眼科和病理学-显微镜学的评估证实了MedMO在跨模态上的广泛泛化能力。我们发布了MedMO的两个版本：4B和8B。项目页面见https://genmilab.github.io/MedMO-Page</div>
</details>
</div>
<div class="card">
<div class="title">Learning a Generative Meta-Model of LLM Activations</div>
<div class="meta-line">Authors: Grace Luo, Jiahai Feng, Trevor Darrell, Alec Radford, Jacob Steinhardt</div>
<div class="meta-line">First: 2026-02-06T18:59:56+00:00 · Latest: 2026-02-06T18:59:56+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06964v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06964v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://generative-latent-prior.github.io">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing approaches for analyzing neural network activations, such as PCA and sparse autoencoders, rely on strong structural assumptions. Generative models offer an alternative: they can uncover structure without such assumptions and act as priors that improve intervention fidelity. We explore this direction by training diffusion models on one billion residual stream activations, creating &quot;meta-models&quot; that learn the distribution of a network&#x27;s internal states. We find that diffusion loss decreases smoothly with compute and reliably predicts downstream utility. In particular, applying the meta-model&#x27;s learned prior to steering interventions improves fluency, with larger gains as loss decreases. Moreover, the meta-model&#x27;s neurons increasingly isolate concepts into individual units, with sparse probing scores that scale as loss decreases. These results suggest generative meta-models offer a scalable path toward interpretability without restrictive structural assumptions. Project page: https://generative-latent-prior.github.io.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>学习生成元模型的LLM激活</div>
<div class="mono" style="margin-top:8px">现有用于分析神经网络激活的方法，如PCA和稀疏自编码器，依赖于强烈的结构假设。生成模型提供了一种替代方案：它们可以在没有这些假设的情况下发现结构，并作为先验知识提高干预的准确性。我们通过在十亿个残差流激活上训练扩散模型，创建了“元模型”，这些模型学习了网络内部状态的分布。我们发现，随着计算量的增加，扩散损失逐渐减少，并可靠地预测了下游的实用性。特别是，应用元模型学习到的先验知识来引导干预可以提高流畅性，随着损失减少，效果提升更大。此外，随着损失减少，元模型的神经元越来越能够将概念隔离为独立的单元，探针得分也变得稀疏。这些结果表明，生成元模型提供了一条在不依赖于限制性结构假设的情况下实现可解释性的可扩展途径。项目页面：https://generative-latent-prior.github.io/</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a generative meta-model to analyze neural network activations without strong structural assumptions. By training diffusion models on one billion residual stream activations, the study creates meta-models that capture the distribution of a network&#x27;s internal states. Key findings include a smooth decrease in diffusion loss with increased compute, which reliably predicts downstream utility. Applying the learned prior improves fluency in interventions, with larger gains as loss decreases. Additionally, the meta-model&#x27;s neurons increasingly isolate concepts into individual units, with sparse probing scores that scale as loss decreases, suggesting a scalable path to interpretability.</div>
<div class="mono" style="margin-top:8px">研究旨在通过训练扩散模型来分析神经网络激活，无需强结构假设。通过对一亿个残差流激活进行训练，研究创建了能够捕捉网络内部状态分布的元模型。关键发现包括随着计算量增加，扩散损失逐渐减少，并可靠地预测下游效果。应用学习到的先验可以提高干预的流畅性，损失减少时效果更明显。此外，元模型的神经元逐渐将概念隔离成独立单元，随着损失减少，探针得分也变得稀疏，这表明了一条可扩展的解释性路径。</div>
</details>
</div>
<div class="card">
<div class="title">InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning</div>
<div class="meta-line">Authors: Yuchen Yan, Liang Jiang, Jin Jiang, Shuaicheng Li, Zujie Wen, Zhiqiang Zhang, Jun Zhou, Jian Shao, Yueting Zhuang, Yongliang Shen</div>
<div class="meta-line">First: 2026-02-06T18:59:27+00:00 · Latest: 2026-02-06T18:59:27+00:00</div>
<div class="meta-line">Comments: Project Page: https://zju-real.github.io/InftyThink-Plus Code: https://github.com/ZJU-REAL/InftyThink-Plus</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06960v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06960v1">PDF</a> · <a href="https://github.com/ZJU-REAL/InftyThink-Plus">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a> · <a href="https://zju-real.github.io/InftyThink-Plus">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve, and how to resume reasoning. We propose InftyThink+, an end-to-end reinforcement learning framework that optimizes the entire iterative reasoning trajectory, building on model-controlled iteration boundaries and explicit summarization. InftyThink+ adopts a two-stage training scheme with supervised cold-start followed by trajectory-level reinforcement learning, enabling the model to learn strategic summarization and continuation decisions. Experiments on DeepSeek-R1-Distill-Qwen-1.5B show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning by a clear margin, while also generalizing better to out-of-distribution benchmarks. Moreover, InftyThink+ significantly reduces inference latency and accelerates reinforcement learning training, demonstrating improved reasoning efficiency alongside stronger performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>InftyThink+: 通过强化学习实现有效高效的无限期推理</div>
<div class="mono" style="margin-top:8px">大型推理模型通过扩展推理时的链式思考来实现强大的性能，但这种范式会遭受二次成本、上下文长度限制以及由于中间迷失而导致的推理退化。迭代推理通过定期总结中间想法来缓解这些问题，但现有方法依赖于监督学习或固定启发式方法，并不能优化何时总结、保留什么以及如何继续推理。我们提出了一种名为InftyThink+的端到端强化学习框架，该框架优化了整个迭代推理轨迹，基于模型控制的迭代边界和显式总结。InftyThink+采用两阶段训练方案，先进行监督冷启动，然后进行轨迹级强化学习，使模型能够学习战略性的总结和继续决策。实验表明，InftyThink+在DeepSeek-R1-Distill-Qwen-1.5B上的AIME24准确率提高了21%，在常规长链式思考强化学习中表现出明显的优势，同时在离分布基准上也表现出更好的泛化能力。此外，InftyThink+显著减少了推理延迟并加速了强化学习训练，展示了更强的推理效率和性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">InftyThink+ is an end-to-end reinforcement learning framework designed to optimize iterative reasoning for infinite-horizon problems. It addresses the limitations of existing methods by learning when and how to summarize intermediate thoughts and resume reasoning. Experiments show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning, while also reducing inference latency and accelerating training.</div>
<div class="mono" style="margin-top:8px">InftyThink+ 是一个端到端的强化学习框架，优化无限时间范围内的迭代推理，解决了大型推理模型的局限性。它采用两阶段训练方案来学习战略性总结和继续决策，提高准确性和泛化能力，同时减少推理延迟并加速训练。实验表明，InftyThink+ 在 AIME24 和其他基准上优于传统方法。</div>
</details>
</div>
<div class="card">
<div class="title">DAWN: Dependency-Aware Fast Inference for Diffusion LLMs</div>
<div class="meta-line">Authors: Lizhuo Luo, Zhuoran Shi, Jiajun Luo, Zhi Wang, Shen Ren, Wenya Wang, Tianwei Zhang</div>
<div class="meta-line">First: 2026-02-06T18:51:29+00:00 · Latest: 2026-02-06T18:51:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06953v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06953v1">PDF</a> · <a href="https://github.com/lizhuo-luo/DAWN">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion large language models (dLLMs) have shown advantages in text generation, particularly due to their inherent ability for parallel decoding. However, constrained by the quality--speed trade-off, existing inference solutions adopt conservative parallel strategies, leaving substantial efficiency potential underexplored. A core challenge is that parallel decoding assumes each position can be filled independently, but tokens are often semantically coupled. Thus, the correct choice at one position constrains valid choices at others. Without modeling these inter-token dependencies, parallel strategies produce deteriorated outputs. Motivated by this insight, we propose DAWN, a training-free, dependency-aware decoding method for fast dLLM inference. DAWN extracts token dependencies and leverages two key motivations: (1) positions dependent on unmasked certain positions become more reliable, (2) simultaneously unmasking strongly coupled uncertain positions induces errors. Given those findings, DAWN leverages a dependency graph to select more reliable unmasking positions at each iteration, achieving high parallelism with negligible loss in generation quality. Extensive experiments across multiple models and datasets demonstrate that DAWN speedups the inference by 1.80-8.06x over baselines while preserving the generation quality. Code is released at https://github.com/lizhuo-luo/DAWN.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DAWN：依赖感知的快速推理方法用于扩散大语言模型</div>
<div class="mono" style="margin-top:8px">扩散大语言模型（dLLMs）在文本生成方面表现出优势，尤其是由于其固有的并行解码能力。然而，受限于质量-速度权衡，现有的推理解决方案采用保守的并行策略，导致大量效率潜力未被充分利用。核心挑战在于并行解码假设每个位置可以独立填充，但令牌往往在语义上相互关联。因此，一个位置的正确选择会限制其他位置的有效选择。如果不建模这些令牌之间的依赖关系，那么并行策略会产生劣化的输出。基于这一洞察，我们提出DAWN，一种无需训练的依赖感知解码方法，用于快速dLLM推理。DAWN提取令牌依赖关系，并利用两个关键动机：（1）依赖于未掩码某些位置的位置变得更加可靠，（2）同时解掩码强关联的不确定位置会引发错误。基于这些发现，DAWN利用依赖图在每次迭代中选择更可靠的解掩码位置，实现高并行度的同时几乎不损失生成质量。在多个模型和数据集上的广泛实验表明，与基线相比，DAWN将推理速度提高了1.80-8.06倍，同时保持了生成质量。代码发布在https://github.com/lizhuo-luo/DAWN。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">DAWN is a training-free method that enhances the efficiency of diffusion large language models (dLLMs) by addressing the quality-speed trade-off. It uses a dependency graph to select reliable positions for parallel decoding, ensuring high parallelism without compromising generation quality. Experiments show that DAWN speeds up inference by 1.80-8.06 times compared to baseline methods while maintaining quality.</div>
<div class="mono" style="margin-top:8px">DAWN 是一种依赖感知的解码方法，用于加速扩散大型语言模型（dLLMs）的推理，通过利用依赖图在每次迭代中选择更可靠的解码位置来解决质量和速度之间的权衡问题。DAWN 实现了高并行性且几乎不影响生成质量，在多个模型和数据集上展示了 1.80-8.06 倍的加速效果，同时保持了生成质量。</div>
</details>
</div>
<div class="card">
<div class="title">Implicit Unitarity Bias in Tensor Factorization: A Theoretical Framework for Symmetry Group Discovery</div>
<div class="meta-line">Authors: Dongsung Huh, Halyun Jeong</div>
<div class="meta-line">First: 2025-11-28T12:58:13+00:00 · Latest: 2026-02-06T18:51:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.23152v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.23152v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While modern neural architectures typically generalize via smooth interpolation, it lacks the inductive biases required to uncover algebraic structures essential for systematic generalization. We present the first theoretical analysis of HyperCube, a differentiable tensor factorization architecture designed to bridge this gap. This work establishes an intrinsic geometric property of the HyperCube formulation: we prove that the architecture mediates a fundamental equivalence between geometric alignment and algebraic structure. Independent of the global optimization landscape, we show that the condition of geometric alignment imposes rigid algebraic constraints, proving that the feasible collinear manifold is non-empty if and only if the target is isotopic to a group. Within this manifold, we characterize the objective as a rank-maximizing potential that unconditionally drives factors toward full-rank, unitary representations. Finally, we propose the Collinearity Dominance mechanism to link these structural results to the global landscape. Supported by empirical scaling laws, we establish that global minima are achieved exclusively by unitary regular representations of group isotopes. This formalizes the HyperCube objective as a differentiable proxy for associativity, demonstrating how rigid geometric constraints enable the discovery of latent algebraic symmetry.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>张量分解中的隐含单位性偏差：对称群发现的理论框架</div>
<div class="mono" style="margin-top:8px">尽管现代神经架构通常通过平滑插值泛化，但缺乏发现代数结构所需的归纳偏差，这些结构对于系统泛化至关重要。我们首次对HyperCube进行了理论分析，这是一种可微张量分解架构，旨在弥合这一差距。这项工作确立了HyperCube表述的内在几何性质：我们证明该架构在几何对齐和代数结构之间建立了基本等价性。独立于全局优化景观，我们证明几何对齐的条件施加了刚性代数约束，证明目标若且仅若等同于群时，可行共线流形才非空。在该流形内，我们将目标刻画为一个最大化秩的潜在函数，无条件地驱动因子向满秩、单位表示趋近。最后，我们提出了共线性主导机制将这些结构结果与全局景观联系起来。基于实证的扩展律，我们证明全局最小值仅由群等同的单位正则表示实现。这将HyperCube目标形式化为可微的结合律代理，展示了刚性几何约束如何使潜在代数对称性的发现成为可能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address the need for inductive biases in neural architectures to uncover algebraic structures for systematic generalization. The study introduces HyperCube, a differentiable tensor factorization architecture, and proves that it imposes rigid algebraic constraints through geometric alignment. Key findings include the existence of a non-empty collinear manifold if and only if the target is isotopic to a group, and that global minima are achieved by unitary regular representations of group isotopes, formalizing the HyperCube objective as a differentiable proxy for associativity.</div>
<div class="mono" style="margin-top:8px">研究旨在解决神经架构缺乏用于发现代数结构的归纳偏置，以实现系统泛化。研究引入了HyperCube，一种可微张量分解架构，并证明它通过几何对齐施加了严格的代数约束。关键发现包括，如果目标与群的同胚等价，则存在非空共线流形，并且全局最小值仅由群同胚的幺正正规表示实现，从而将HyperCube目标形式化为关联性的可微代理。</div>
</details>
</div>
<div class="card">
<div class="title">DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</div>
<div class="meta-line">Authors: Shenyuan Gao, William Liang, Kaiyuan Zheng, Ayaan Malik, Seonghyeon Ye, Sihyun Yu, Wei-Cheng Tseng, Yuzhu Dong, Kaichun Mo, Chen-Hsuan Lin, Qianli Ma, Seungjun Nah, Loic Magne, Jiannan Xiang, Yuqi Xie, Ruijie Zheng, Dantong Niu, You Liang Tan, K. R. Zentner, George Kurian, Suneel Indupuru, Pooya Jannaty, Jinwei Gu, Jun Zhang, Jitendra Malik, Pieter Abbeel, Ming-Yu Liu, Yuke Zhu, Joel Jang, Linxi &quot;Jim&quot; Fan</div>
<div class="meta-line">First: 2026-02-06T18:49:43+00:00 · Latest: 2026-02-06T18:49:43+00:00</div>
<div class="meta-line">Comments: Project page: https://dreamdojo-world.github.io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06949v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06949v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://dreamdojo-world.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diverse interactions and dexterous controls from 44k hours of egocentric human videos. Our data mixture represents the largest video dataset to date for world model pretraining, spanning a wide range of daily scenarios with diverse objects and skills. To address the scarcity of action labels, we introduce continuous latent actions as unified proxy actions, enhancing interaction knowledge transfer from unlabeled videos. After post-training on small-scale target robot data, DreamDojo demonstrates a strong understanding of physics and precise action controllability. We also devise a distillation pipeline that accelerates DreamDojo to a real-time speed of 10.81 FPS and further improves context consistency. Our work enables several important applications based on generative world models, including live teleoperation, policy evaluation, and model-based planning. Systematic evaluation on multiple challenging out-of-distribution (OOD) benchmarks verifies the significance of our method for simulating open-world, contact-rich tasks, paving the way for general-purpose robot world models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DreamDojo：来自大规模人类视频的通用机器人世界模型</div>
<div class="mono" style="margin-top:8px">能够在多种环境中模拟动作结果将彻底改变大规模通用代理的开发。然而，建模这些世界动力学，尤其是灵巧的机器人任务，由于数据覆盖有限和动作标签稀缺，提出了重大挑战。为此，我们引入了DreamDojo，一种基础世界模型，从44000小时的主观人类视频中学习多样化的交互和灵巧控制。我们的数据混合代表了迄今为止用于世界模型预训练的最大视频数据集，涵盖了广泛的生活场景，涉及多种物体和技能。为了解决动作标签稀缺的问题，我们引入了连续潜在动作作为统一的代理动作，增强了从未标记视频中转移交互知识的能力。在小型目标机器人数据上进行后训练后，DreamDojo展示了对物理的深刻理解和精确的动作可控性。我们还设计了一种蒸馏管道，将DreamDojo加速到每秒10.81帧，并进一步提高了上下文一致性。我们的工作基于生成世界模型实现了几个重要应用，包括实时远程操作、策略评估和基于模型的规划。在多个具有挑战性的分布外(OOD)基准上的系统评估验证了我们的方法对于模拟开放世界、接触丰富的任务的重要性，为通用机器人世界模型铺平了道路。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">DreamDojo is a foundation world model that learns from 44k hours of human videos to simulate diverse interactions and dexterous controls. It addresses the challenge of limited data and scarce action labels by using continuous latent actions as proxies. After fine-tuning on robot data, DreamDojo shows strong physics understanding and precise action control. The model is accelerated to real-time speed and improves context consistency, enabling applications like live teleoperation and model-based planning. Evaluations on OOD benchmarks confirm its effectiveness for simulating complex robotic tasks.</div>
<div class="mono" style="margin-top:8px">DreamDojo 是一个从 44000 小时的人类视频中学习的基座世界模型，用于模拟多样化的交互和灵巧控制。它通过使用连续的潜在动作作为代理来解决数据有限和动作标签稀缺的问题。经过小型机器人数据的微调后，DreamDojo 展现了强大的物理理解和精确的动作控制能力。该模型被加速到实时速度，并提高了上下文一致性，使其能够应用于实时远程操作、策略评估和基于模型的规划。在多种挑战性的 OOD 基准测试中的系统评估证实了其在模拟复杂机器人任务方面的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Agentic Uncertainty Reveals Agentic Overconfidence</div>
<div class="meta-line">Authors: Jean Kaddour, Srijan Patel, Gbètondji Dovonon, Leo Richter, Pasquale Minervini, Matt J. Kusner</div>
<div class="meta-line">First: 2026-02-06T18:49:35+00:00 · Latest: 2026-02-06T18:49:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06948v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06948v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination than standard post-execution review, though differences are not always significant. Adversarial prompting reframing assessment as bug-finding achieves the best calibration.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>代理不确定性揭示代理过度自信</div>
<div class="mono" style="margin-top:8px">AI代理能否预测自己完成任务的成功率？我们通过在任务执行前、执行中和执行后获取成功概率估计来研究代理不确定性。所有结果都表现出代理过度自信：有些代理仅22%的时间成功，却预测自己有77%的成功率。出乎意料的是，执行前评估虽然信息更少，但往往能更好地区分代理，尽管差异并不总是显著。对抗性提示将评估重新定义为漏洞查找，实现了最佳校准。</div>
</details>
</div>
<div class="card">
<div class="title">Endogenous Resistance to Activation Steering in Language Models</div>
<div class="meta-line">Authors: Alex McKenzie, Keenan Pepper, Stijn Servaes, Martin Leitgab, Murat Cubuktepe, Mike Vaiana, Diogo de Lucena, Judd Rosenblatt, Michael S. A. Graziano</div>
<div class="meta-line">First: 2026-02-06T18:41:12+00:00 · Latest: 2026-02-06T18:41:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06941v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06941v1">PDF</a> · <a href="http://github.com/agencyenterprise/endogenous-steering-resistance">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models can resist task-misaligned activation steering during inference, sometimes recovering mid-generation to produce improved responses even when steering remains active. We term this Endogenous Steering Resistance (ESR). Using sparse autoencoder (SAE) latents to steer model activations, we find that Llama-3.3-70B shows substantial ESR, while smaller models from the Llama-3 and Gemma-2 families exhibit the phenomenon less frequently. We identify 26 SAE latents that activate differentially during off-topic content and are causally linked to ESR in Llama-3.3-70B. Zero-ablating these latents reduces the multi-attempt rate by 25%, providing causal evidence for dedicated internal consistency-checking circuits. We demonstrate that ESR can be deliberately enhanced through both prompting and training: meta-prompts instructing the model to self-monitor increase the multi-attempt rate by 4x for Llama-3.3-70B, and fine-tuning on self-correction examples successfully induces ESR-like behavior in smaller models. These findings have dual implications: ESR could protect against adversarial manipulation but might also interfere with beneficial safety interventions that rely on activation steering. Understanding and controlling these resistance mechanisms is important for developing transparent and controllable AI systems. Code is available at github.com/agencyenterprise/endogenous-steering-resistance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>语言模型内部对激活引导的抗性</div>
<div class="mono" style="margin-top:8px">大型语言模型在推理过程中可以抵抗任务不一致的激活引导，有时即使引导仍然有效，也能在生成过程中恢复并产生更好的响应。我们称这种现象为内生引导抗性（ESR）。使用稀疏自编码器（SAE）的潜在变量来引导模型的激活，我们发现Llama-3.3-70B表现出显著的ESR，而Llama-3和Gemma-2家族中的较小模型则较少表现出这种现象。我们确定了26个SAE潜在变量，在偏离主题的内容中激活不同，并且与Llama-3.3-70B中的ESR有因果联系。零删除这些潜在变量可将多尝试率降低25%，提供了内生一致性检查电路的因果证据。我们证明，通过提示和训练可以故意增强ESR：元提示指示模型自我监控可将Llama-3.3-70B的多尝试率提高4倍，而基于自我纠正示例的微调成功地在较小模型中诱导了ESR类似的行为。这些发现具有双重含义：ESR可以保护免受对抗性操纵，但也可能干扰依赖于激活引导的有益安全干预。理解并控制这些抗性机制对于开发透明可控的人工智能系统至关重要。代码可在github.com/agencyenterprise/endogenous-steering-resistance获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study investigates Endogenous Steering Resistance (ESR) in large language models, where models can resist task-misaligned activation steering during inference, sometimes recovering to produce better responses. Using sparse autoencoder latents, the research finds that Llama-3.3-70B exhibits significant ESR, while smaller models show it less frequently. The study identifies 26 SAE latents causally linked to ESR and demonstrates that ESR can be enhanced through prompting and training, with meta-prompts increasing the multi-attempt rate by 4x for Llama-3.3-70B. These findings suggest ESR could protect against adversarial manipulation but might interfere with safety interventions relying on activation steering, highlighting the need for transparent and controllable AI systems.</div>
<div class="mono" style="margin-top:8px">研究探讨了大型语言模型中内生激活导向抵抗（ESR）的现象，即模型在推理过程中可以抵抗任务不一致的激活导向。通过稀疏自编码器（SAE）的潜在变量，研究发现Llama-3.3-70B表现出显著的ESR，而较小的模型则较少表现出这一现象。研究确定了26个与ESR相关的因果关联潜在变量，并展示了通过提示和训练可以增强ESR，其中元提示使Llama-3.3-70B的多尝试率增加了4倍。这些发现表明，ESR可以保护免受恶意操纵，但也可能妨碍依赖于激活导向的有益安全干预。理解并控制ESR机制对于开发透明和可控的人工智能系统至关重要。</div>
</details>
</div>
<div class="card">
<div class="title">code_transformed: The Influence of Large Language Models on Code</div>
<div class="meta-line">Authors: Yuliang Xu, Siming Huang, Mingmeng Geng, Yao Wan, Xuanhua Shi, Dongping Chen</div>
<div class="meta-line">First: 2025-06-13T17:59:39+00:00 · Latest: 2026-02-06T18:40:02+00:00</div>
<div class="meta-line">Comments: EACL 2026 Findings</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.12014v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.12014v2">PDF</a> · <a href="https://github.com/ignorancex/LLM_code">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Coding remains one of the most fundamental modes of interaction between humans and machines. With the rapid advancement of Large Language Models (LLMs), code generation capabilities have begun to significantly reshape programming practices. This development prompts a central question: Have LLMs transformed code style, and how can such transformation be characterized? In this paper, we present a pioneering study that investigates the impact of LLMs on code style, with a focus on naming conventions, complexity, maintainability, and similarity. By analyzing code from over 20,000 GitHub repositories linked to arXiv papers published between 2020 and 2025, we identify measurable trends in the evolution of coding style that align with characteristics of LLM-generated code. For instance, the proportion of snake_case function names in Python code increased from 40.7% in Q1 2023 to 49.8% in Q3 2025. Furthermore, we investigate how LLMs approach algorithmic problems by examining their reasoning processes. Our experimental results may provide the first large-scale empirical evidence that LLMs affect real-world programming style. We release all the experimental dataset and source code at: https://github.com/ignorancex/LLM_code</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>code_transformed: 大型语言模型对代码的影响</div>
<div class="mono" style="margin-top:8px">编程仍然是人类与机器之间最基本的交互方式之一。随着大型语言模型（LLMs）的迅速发展，代码生成能力已经开始显著重塑编程实践。这一发展引发了核心问题：LLMs 是否已经改变了代码风格，这种变化又如何可以被描述？在本文中，我们进行了一项开创性的研究，探讨LLMs 对代码风格的影响，重点关注命名规范、复杂性、可维护性和相似性。通过分析2020年至2025年间与arXiv论文链接的超过20,000个GitHub代码库中的代码，我们发现了与LLM生成代码特征相一致的可测量趋势。例如，Python代码中使用snake_case命名的函数比例从2023年第一季度的40.7%增加到2025年第三季度的49.8%。此外，我们还研究了LLMs 如何处理算法问题，通过检查它们的推理过程。我们的实验结果可能提供了关于LLMs 影响实际编程风格的首次大规模实证证据。我们将在以下地址发布所有实验数据集和源代码：https://github.com/ignorancex/LLM_code</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper explores how Large Language Models (LLMs) influence coding practices by analyzing over 20,000 GitHub repositories. The study finds that LLMs have transformed code style, particularly in naming conventions, with an increase in snake_case function names in Python. The research also examines LLMs&#x27; approach to algorithmic problems and provides empirical evidence of their impact on real-world programming style. The dataset and source code are publicly available.</div>
<div class="mono" style="margin-top:8px">该研究通过分析超过20,000个GitHub仓库，探讨了大型语言模型（LLMs）如何影响编码实践。研究发现，LLMs已经改变了编码风格，特别是在命名规范方面，Python中的snake_case函数名比例从2023年第一季度的40.7%增加到2025年第三季度的49.8%。研究还考察了LLMs在解决算法问题时的方法，并提供了其对实际编程风格影响的实证证据。所有实验数据和源代码均已公开。</div>
</details>
</div>
<div class="card">
<div class="title">Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability</div>
<div class="meta-line">Authors: Shobhita Sundaram, John Quan, Ariel Kwiatkowski, Kartik Ahuja, Yann Ollivier, Julia Kempe</div>
<div class="meta-line">First: 2026-01-26T18:46:56+00:00 · Latest: 2026-02-06T18:38:32+00:00</div>
<div class="meta-line">Comments: Blog post: https://ssundaram21.github.io/soar/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18778v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18778v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://ssundaram21.github.io/soar/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>教学模型自我教学：边缘可学习性中的推理</div>
<div class="mono" style="margin-top:8px">模型能否学会突破自身的学习瓶颈？在初始成功率低、训练信号少的数据集上，微调大型推理模型的强化学习方法会停滞不前。我们探讨了一个基本问题：预训练的语言模型能否利用潜在知识为它无法解决的问题生成自动课程？为此，我们设计了SOAR：一种自我改进框架，通过元强化学习揭示这些教学信号。教师模型副本为学生模型副本提出合成问题，并根据其在一小部分难题上的进步获得奖励。关键的是，SOAR将课程建立在实际的学生进步上，而不是内在的代理奖励上。在数学基准中最难的子集（0/128成功率）上进行的研究揭示了三个核心发现。首先，我们展示了通过增强预训练模型生成有用阶梯的能力，实现双层元强化学习的可能性，从而在稀疏的二元奖励下解锁学习。其次，基于实际进步的奖励方案优于先前LLM自我博弈中使用的内在奖励方案，可靠地避免了它们通常表现出的不稳定性及多样性崩溃模式。第三，分析生成的问题表明，结构质量和良好定义比解的正确性对学习进步更为关键。我们的研究结果表明，生成有用阶梯的能力不需要预先具备解决难题的能力，为在不依赖额外精心策划数据的情况下逃离推理瓶颈提供了一条有原则的路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study investigates whether a pretrained language model can generate its own curriculum to improve its reasoning abilities, especially on tasks it initially struggles with. The SOAR framework uses meta-reinforcement learning to have a teacher model propose synthetic problems to a student model, rewarding the teacher based on the student&#x27;s improvement on hard problems. Key findings include the successful implementation of bi-level meta-RL, better performance with grounded rewards compared to intrinsic rewards, and the importance of structural quality in generated questions for learning progress. This suggests that models can generate useful stepping stones without needing to solve the problems themselves, potentially helping to overcome reasoning plateaus.</div>
<div class="mono" style="margin-top:8px">研究旨在探索预训练的大语言模型（LLM）是否可以通过生成自动化的课程来自我改进，解决它最初无法解决的问题。研究人员开发了SOAR框架，使用元强化学习（meta-RL），其中教师模型为学生模型提出合成问题，并根据学生的学习进展对教师进行奖励。关键发现包括成功实施了双层元强化学习，基于实际学习进展的奖励优于内在奖励，以及生成问题的结构质量和良好定义性对于学习进展更为重要。</div>
</details>
</div>
<div class="card">
<div class="title">Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI</div>
<div class="meta-line">Authors: Ehud Shapiro</div>
<div class="meta-line">First: 2026-02-06T18:30:11+00:00 · Latest: 2026-02-06T18:30:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06934v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06934v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Grassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired \emph{readers} and \emph{writers}, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers and/or writers, enabling the concise expression of rich multidirectional communication modalities.
  GLP was designed as a language for grassroots platforms -- distributed systems with multiple instances that can operate independently of each other and of any global resource, and can coalesce into ever larger instances -- with its target architecture being smartphones communicating peer-to-peer. The operational semantics of Concurrent (single-agent) GLP and of multiagent GLP (maGLP) were defined via transition systems/multiagent transition systems, respectively.
  Here, we describe the mathematics developed to facilitate the workstation- and smartphone-based implementations of GLP by AI in Dart. We developed dGLP -- implementation-ready deterministic operational semantics for single-agent GLP -- and proved it correct with respect to the Concurrent GLP operational semantics; dGLP was used by AI as a formal spec, from which it developed a workstation-based implementation of GLP. We developed madGLP -- an implementation-ready multiagent operational semantics for maGLP -- and proved it correct with respect to the maGLP operational semantics; madGLP is deterministic at the agent level (not at the system level due to communication asynchrony), and is being used by AI as a formal spec from which it develops a smartphone-based implementation of maGLP.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用多智能体转换系统和AI实现基层逻辑程序</div>
<div class="mono" style="margin-top:8px">基层逻辑程序（GLP）是一种并发逻辑编程语言，其中变量被划分为成对的“读者”和“写入者”，同时具备线性逻辑和未来/承诺的功能：一个赋值最多仅通过写入者（承诺）的唯一出现产生，并最多仅通过其配对的读者（未来）的唯一出现消费，还可以包含额外的读者和/或写入者，从而能够简洁地表达丰富的多向通信模式。
GLP 是为基层平台设计的语言——分布式系统，具有多个可以独立运行且无需任何全局资源的实例，并可以合并成更大的实例——其目标架构是通过点对点通信的智能手机。并发（单智能体）GLP 和多智能体 GLP（maGLP）的操作语义分别通过转换系统和多智能体转换系统定义。
在此，我们描述了为通过AI在Dart中实现GLP而开发的数学方法。我们开发了dGLP——单智能体GLP的实现就绪确定性操作语义，并证明其与并发GLP操作语义一致；dGLP被AI用作形式规范，从中开发了GLP的工作站实现。我们开发了madGLP——maGLP的实现就绪多智能体操作语义，并证明其与maGLP操作语义一致；madGLP在智能体级别是确定性的（由于通信异步性，在系统级别不是），并被AI用作形式规范，从中开发了maGLP的智能手机实现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to implement Grassroots Logic Programs (GLP), a concurrent logic programming language, on workstations and smartphones. GLP uses readers and writers to enable rich communication, with deterministic operational semantics (dGLP and madGLP) developed for single-agent and multiagent GLP, respectively. The correctness of these semantics was proven, and they were used as formal specifications for implementing GLP on workstations and smartphones.</div>
<div class="mono" style="margin-top:8px">研究旨在将Grassroots Logic Programs (GLP)并发逻辑编程语言实现到工作站和智能手机上。GLP通过配对的读者和写入者支持丰富的多向通信。GLP的操作语义通过过渡系统进行形式化。作者开发了单代理GLP和多代理GLP的确定性操作语义（dGLP和madGLP），并证明了它们的正确性。这些形式化为AI在工作站和智能手机上实现GLP提供了规范。</div>
</details>
</div>
<div class="card">
<div class="title">When RL Meets Adaptive Speculative Training: A Unified Training-Serving System</div>
<div class="meta-line">Authors: Junxiong Wang, Fengxiang Bie, Jisen Li, Zhongzhu Zhou, Zelei Shao, Yubo Wang, Yinghui Liu, Qingyang Wu, Avner May, Sri Yanamandra, Yineng Zhang, Ce Zhang, Tri Dao, Percy Liang, Ben Athiwaratkun, Shuaiwen Leon Song, Chenfeng Xu, Xiaoxia Wu</div>
<div class="meta-line">First: 2026-02-06T18:28:54+00:00 · Latest: 2026-02-06T18:28:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06932v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06932v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag: (1) high time-to-serve, since a speculator must be trained offline for a considerable period before deployment; (2) delayed utility feedback, since the true end-to-end decoding speedup is only known after training and cannot be inferred reliably from acceptance rate alone due to model-architecture and system-level overheads; and (3) domain-drift degradation, as the target model is repurposed to new domains and the speculator becomes stale and less effective.
  To address these issues, we present Aurora, a unified training-serving system that closes the loop by continuously learning a speculator directly from live inference traces. Aurora reframes online speculator learning as an asynchronous reinforcement-learning problem: accepted tokens provide positive feedback, while rejected speculator proposals provide implicit negative feedback that we exploit to improve sample efficiency. Our design integrates an SGLang-based inference server with an asynchronous training server, enabling hot-swapped speculator updates without service interruption. Crucially, Aurora supports day-0 deployment: a speculator can be served immediately and rapidly adapted to live traffic, improving system performance while providing immediate utility feedback. Across experiments, Aurora achieves a 1.5x day-0 speedup on recently released frontier models (e.g., MiniMax M2.1 229B and Qwen3-Coder-Next 80B). Aurora also adapts effectively to distribution shifts in user traffic, delivering an additional 1.25x speedup over a well-trained but static speculator on widely used models (e.g., Qwen3 and Llama3).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>当RL遇到自适应推测训练：一个统一的训练-服务系统</div>
<div class="mono" style="margin-top:8px">推测解码可以显著加速大语言模型的服务，但大多数部署将推测训练与服务分离，将推测训练视为独立的离线建模问题。我们展示了这种分离的表述引入了重大的部署和适应滞后：（1）高上线时间，因为推测器必须在部署前经过一段时间的离线训练；（2）延迟的效用反馈，因为只有在训练后才能知道端到端的解码加速效果，而不能仅通过接受率来可靠地推断，因为存在模型架构和系统层面的开销；（3）领域漂移退化，当目标模型被重新用于新领域时，推测器变得过时且效果较差。
 为了解决这些问题，我们提出了Aurora，一个统一的训练-服务系统，通过连续从实时推理跟踪中学习推测器来闭合回路。Aurora将在线推测学习重新定义为异步强化学习问题：接受的令牌提供正反馈，而被拒绝的推测器提案提供隐含的负反馈，我们利用这种反馈来提高样本效率。我们的设计集成了基于SGLang的推理服务器和异步训练服务器，使推测器更新可以在不中断服务的情况下热插拔。至关重要的是，Aurora支持零日部署：推测器可以立即上线并快速适应实时流量，从而提高系统性能并提供即时的效用反馈。在实验中，Aurora在最近发布的前沿模型（例如MiniMax M2.1 229B和Qwen3-Coder-Next 80B）上实现了1.5倍的零日加速。Aurora还能够有效适应用户流量分布的变化，在广泛使用的模型（例如Qwen3和Llama3）上，与训练有素但静态的推测器相比，额外实现了1.25倍的加速。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenges of deploying speculative decoding for language models by presenting Aurora, a unified training-serving system. It reframes online speculator learning as an asynchronous reinforcement-learning problem, using positive and negative feedback from live inference traces to improve sample efficiency. Aurora enables immediate deployment and rapid adaptation to live traffic, achieving a 1.5x day-0 speedup on frontier models and an additional 1.25x speedup on widely used models.</div>
<div class="mono" style="margin-top:8px">论文通过提出Aurora统一训练-服务系统来解决推测性解码中的部署滞后和延迟的效用反馈问题。Aurora使用强化学习从实时推理跟踪中连续学习推测器，提供即时效用反馈并实现零日部署。实验表明，Aurora在前沿模型上实现了1.5倍的零日加速，并且在广泛使用的模型上适应用户流量分布变化时，额外实现了1.25倍的加速。</div>
</details>
</div>
<div class="card">
<div class="title">EigenTrack: Spectral Activation Feature Tracking for Hallucination and Out-of-Distribution Detection in LLMs and VLMs</div>
<div class="meta-line">Authors: Davide Ettori, Nastaran Darabi, Sina Tayebati, Ranganath Krishnan, Mahesh Subedar, Omesh Tickoo, Amit Ranjan Trivedi</div>
<div class="meta-line">Venue: ICASSP 2026</div>
<div class="meta-line">First: 2025-09-19T08:05:28+00:00 · Latest: 2026-02-06T18:25:25+00:00</div>
<div class="meta-line">Comments: 5 pages, submitted to ICASSP 2026, September 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.15735v4">Abs</a> · <a href="https://arxiv.org/pdf/2509.15735v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) offer broad utility but remain prone to hallucination and out-of-distribution (OOD) errors. We propose EigenTrack, an interpretable real-time detector that uses the spectral geometry of hidden activations, a compact global signature of model dynamics. By streaming covariance-spectrum statistics such as entropy, eigenvalue gaps, and KL divergence from random baselines into a lightweight recurrent classifier, EigenTrack tracks temporal shifts in representation structure that signal hallucination and OOD drift before surface errors appear. Unlike black- and grey-box methods, it needs only a single forward pass without resampling. Unlike existing white-box detectors, it preserves temporal context, aggregates global signals, and offers interpretable accuracy-latency trade-offs.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">EigenTrack is an interpretable real-time detector that uses the spectral geometry of hidden activations to track temporal shifts in representation structure, signaling hallucination and out-of-distribution (OOD) errors in large language models (LLMs) and vision-language models (VLMs). It streams covariance-spectrum statistics like entropy and eigenvalue gaps into a lightweight recurrent classifier, offering interpretable accuracy-latency trade-offs without requiring resampling or detailed model knowledge.</div>
<div class="mono" style="margin-top:8px">EigenTrack 是一种可解释的实时检测器，用于识别大型语言模型和视觉-语言模型中的幻觉和离分布错误。它利用隐藏激活的谱几何来跟踪表示结构的时间变化。通过将协方差谱统计量流式传输到轻量级递归分类器中，EigenTrack 可在表面错误出现之前检测这些错误。该方法只需要一次前向传递，并保持时间上下文和全局信号的聚合，提供可解释的准确率-延迟权衡。</div>
</details>
</div>
<div class="card">
<div class="title">Constrained Group Relative Policy Optimization</div>
<div class="meta-line">Authors: Roger Girgis, Rodrigue de Schaetzen, Luke Rowe, Azalée Robitaille, Christopher Pal, Liam Paull</div>
<div class="meta-line">First: 2026-02-05T16:44:23+00:00 · Latest: 2026-02-06T18:22:59+00:00</div>
<div class="meta-line">Comments: 16 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.05863v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.05863v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Group Relative Policy Optimization (GRPO) has emerged as a scalable framework for critic-free policy learning, extending it to settings with explicit behavioral constraints remains underexplored. We introduce Constrained GRPO, a Lagrangian-based extension of GRPO for constrained policy optimization. Constraints are specified via indicator cost functions, enabling direct optimization of violation rates through a Lagrangian relaxation. We show that a naive multi-component treatment in advantage estimation can break constrained learning: mismatched component-wise standard deviations distort the relative importance of the different objective terms, which in turn corrupts the Lagrangian signal and prevents meaningful constraint enforcement. We formally derive this effect to motivate our scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a toy gridworld confirm the predicted optimization pathology and demonstrate that scalarizing advantages restores stable constraint control. In addition, we evaluate Constrained GRPO on robotics tasks, where it improves constraint satisfaction while increasing task success, establishing a simple and effective recipe for constrained policy optimization in embodied AI domains that increasingly rely on large multimodal foundation models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>约束组相对策略优化</div>
<div class="mono" style="margin-top:8px">虽然组相对策略优化（GRPO）已成为无批评家策略学习可扩展框架，但将其扩展到具有明确行为约束的环境中仍鲜有探索。我们引入了约束GRPO，这是一种基于拉格朗日乘数的GRPO扩展，用于约束策略优化。约束通过指示成本函数指定，允许通过拉格朗日松弛直接优化违反率。我们展示了在优势估计中的简单多组件处理可能会破坏约束学习：组件间标准差的不匹配扭曲了不同目标项的相对重要性，进而破坏了拉格朗日信号并阻止了有意义的约束执行。我们正式推导了这一效果，以说明我们提出的标量化优势构造，该构造保留了奖励项和约束项之间的预期权衡。在玩具网格世界的实验中，该优化病理现象得到了证实，并且证明了标量化优势可以恢复稳定的约束控制。此外，我们在机器人任务上评估了约束GRPO，它在提高约束满足率的同时增加了任务成功率，为在越来越多依赖大型多模态基础模型的实体人工智能领域提供了简单有效的约束策略优化方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenge of applying Group Relative Policy Optimization (GRPO) in settings with explicit behavioral constraints, which is underexplored. It introduces Constrained GRPO, a Lagrangian-based extension that uses indicator cost functions to optimize violation rates. The study reveals that a naive multi-component treatment in advantage estimation can lead to optimization issues due to distorted relative importance of objectives. To address this, the authors propose a scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a gridworld and robotics tasks show that scalarizing advantages stabilizes constraint control and improves task success while satisfying constraints.</div>
<div class="mono" style="margin-top:8px">论文解决了在具有明确行为约束的环境中应用Group Relative Policy Optimization (GRPO)的问题，这尚未得到充分探索。研究引入了Constrained GRPO，这是一种基于Lagrangian的扩展，使用指示成本函数来优化违反率。研究发现，由于目标重要性的失真，对优势估计的简单多组件处理会导致优化问题。为了解决这个问题，作者提出了一种标量化优势构造，以保持奖励和约束项之间的预期权衡。实验在网格世界和机器人任务中表明，标量化优势可以稳定约束控制并提高任务成功率，同时满足约束条件。</div>
</details>
</div>
<div class="card">
<div class="title">Harnessing the Unseen: The Hidden Influence of Intrinsic Knowledge in Long-Context Language Models</div>
<div class="meta-line">Authors: Yu Fu, Haz Sameen Shahgir, Hui Liu, Xianfeng Tang, Qi He, Yue Dong</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-04-11T02:06:58+00:00 · Latest: 2026-02-06T18:20:22+00:00</div>
<div class="meta-line">Comments: 17 pages,11figures (accepted to AAAI 2026)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.08202v2">Abs</a> · <a href="https://arxiv.org/pdf/2504.08202v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in long-context language models (LCLMs), designed to handle extremely long contexts, primarily focus on utilizing external contextual information, often leaving the influence of language models&#x27; parametric knowledge underexplored. In this work, we firstly investigate how this parametric knowledge affects content generation and demonstrate that its impact becomes increasingly pronounced as context length extends. Furthermore, we show that the model&#x27;s ability to utilize parametric knowledge, which we call parametric recall ability, does not improve simultaneously with its ability to leverage contextual knowledge through extrinsic retrieval ability. Moreover, better extrinsic retrieval ability can interfere with the model&#x27;s parametric recall ability, limiting its full potential. To bridge this gap, we design a simple yet effective Hybrid Needle-in-a-Haystack test that evaluates models based on their capabilities across both abilities, rather than solely emphasizing extrinsic retrieval ability. Our experimental results reveal that Qwen-2.5 models significantly outperform Llama-3.1 models, demonstrating superior potential to combine various abilities. Moreover, even the more powerful Llama-3.1-70B-Instruct model fails to exhibit better performance, highlighting the importance of evaluating models from a dual-ability perspective.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用无形之力：内在知识在长上下文语言模型中的隐秘影响</div>
<div class="mono" style="margin-top:8px">长上下文语言模型（LCLMs）的最新进展主要集中在利用外部上下文信息上，往往忽视了语言模型参数知识的影响。在本研究中，我们首先探讨了参数知识如何影响内容生成，并证明其影响随着上下文长度的增加而愈发显著。此外，我们展示了模型利用参数知识的能力，即参数回忆能力，并未与其通过外部检索能力利用上下文知识的能力同步提升。而且，更好的外部检索能力可能会干扰模型的参数回忆能力，限制其全部潜力。为了弥合这一差距，我们设计了一个简单而有效的混合“在干草堆中找针”测试，该测试基于模型在两种能力上的表现进行评估，而不仅仅是强调外部检索能力。我们的实验结果表明，Qwen-2.5模型显著优于Llama-3.1模型，显示出更强的多种能力结合潜力。此外，即使是更强大的Llama-3.1-70B-Instruct模型也未能表现出更好的性能，突显了从双能力视角评估模型的重要性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study explores the impact of intrinsic parametric knowledge on content generation in long-context language models, showing that its influence grows with context length. It also finds that while extrinsic retrieval ability improves, it can hinder the model&#x27;s parametric recall ability. To address this, the researchers developed a Hybrid Needle-in-a-Haystack test, which evaluates models based on both abilities. Experimental results indicate that Qwen-2.5 models outperform Llama-3.1 models in combining these abilities, while even the more powerful Llama-3.1-70B-Instruct model does not show better performance, emphasizing the need for dual-ability evaluation.</div>
<div class="mono" style="margin-top:8px">研究探讨了内在参数知识对长上下文语言模型（LCLMs）的影响，发现其影响随上下文长度增加而增强。研究发现，尽管外在检索能力提升，但会妨碍模型的参数回忆能力。开发了一种混合‘针扎干草堆’测试来评估两种能力，Qwen-2.5模型优于Llama-3.1模型，表明更好的双能力整合。即使更强大的Llama-3.1-70B-Instruct模型也没有表现出更好的性能，强调了从双能力视角评估模型的重要性。</div>
</details>
</div>
<div class="card">
<div class="title">From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers</div>
<div class="meta-line">Authors: Ziming Liu, Sophia Sanborn, Surya Ganguli, Andreas Tolias</div>
<div class="meta-line">First: 2026-02-06T18:17:37+00:00 · Latest: 2026-02-06T18:17:37+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06923v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06923v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on &quot;world models&quot; -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous &quot;AI Physicist&quot; approaches have successfully recovered such laws, they typically rely on strong, domain-specific priors that effectively &quot;bake in&quot; the physics. Conversely, Vafa et al. recently showed that generic Transformers fail to acquire these world models, achieving high predictive accuracy without capturing the underlying physical laws. We bridge this gap by systematically introducing three minimal inductive biases. We show that ensuring spatial smoothness (by formulating prediction as continuous regression) and stability (by training with noisy contexts to mitigate error accumulation) enables generic Transformers to surpass prior failures and learn a coherent Keplerian world model, successfully fitting ellipses to planetary trajectories. However, true physical insight requires a third bias: temporal locality. By restricting the attention window to the immediate past -- imposing the simple assumption that future states depend only on the local state rather than a complex history -- we force the model to abandon curve-fitting and discover Newtonian force representations. Our results demonstrate that simple architectural choices determine whether an AI becomes a curve-fitter or a physicist, marking a critical step toward automated scientific discovery.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从开普勒到牛顿：归纳偏置引导Transformer学习世界模型</div>
<div class="mono" style="margin-top:8px">通用人工智能架构能否超越预测，发现支配宇宙的物理定律？真正的智能依赖于“世界模型”——因果抽象，使智能体不仅能预测未来状态，还能理解其背后的动力学。虽然先前的“AI物理学家”方法成功地恢复了这些定律，但它们通常依赖于强的、特定领域的先验知识，实际上“内置”了物理学。相反，Vafa等人最近表明，通用Transformer无法获得这些世界模型，在实现高预测准确性的同时未能捕捉到底层的物理定律。我们通过系统地引入三个最小的归纳偏置来弥合这一差距。我们证明，通过将预测公式化为连续回归以确保空间平滑性，并通过使用噪声上下文进行训练以减轻累积误差，从而确保稳定性，可以使通用Transformer超越先前的失败，学习一个连贯的开普勒式世界模型，成功拟合行星轨迹的椭圆。然而，真正的物理洞察需要第三个偏置：时间局部性。通过限制注意力窗口到最近的过去——假设未来状态仅依赖于局部状态而不是复杂的过去历史——迫使模型放弃曲线拟合，发现牛顿力的表示。我们的结果表明，简单的架构选择决定了AI是成为曲线拟合者还是物理学家，标志着自动科学发现的关键一步。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study explores whether general-purpose AI architectures can discover physical laws beyond mere prediction. It introduces three inductive biases—spatial smoothness, stability, and temporal locality—to enable Transformers to learn coherent world models. By ensuring spatial smoothness and stability, generic Transformers can learn a Keplerian model, fitting planetary trajectories. However, temporal locality is crucial for capturing physical insight, forcing the model to discover Newtonian force representations rather than just fitting curves. These findings highlight the importance of architectural choices in achieving true scientific understanding.</div>
<div class="mono" style="margin-top:8px">研究旨在探索通用AI架构是否能在预测之外发现物理定律。引入了三种归纳偏置：空间平滑性、稳定性和时间局部性。空间平滑性和稳定性使模型能够学习一个连贯的开普勒世界模型，拟合行星轨迹的椭圆。时间局部性则迫使模型放弃曲线拟合，发现牛顿力的表示，实现真正的物理洞察。研究结果表明，这些架构选择显著影响了模型从曲线拟合到科学发现的能力。</div>
</details>
</div>
<div class="card">
<div class="title">Halluverse-M^3: A multitask multilingual benchmark for hallucination in LLMs</div>
<div class="meta-line">Authors: Samir Abdaljalil, Parichit Sharma, Erchin Serpedin, Hasan Kurban</div>
<div class="meta-line">First: 2026-02-06T18:16:09+00:00 · Latest: 2026-02-06T18:16:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06920v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06920v1">PDF</a> · <a href="https://huggingface.co/datasets/sabdalja/HalluVerse-M3">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Hallucinations in large language models remain a persistent challenge, particularly in multilingual and generative settings where factual consistency is difficult to maintain. While recent models show strong performance on English-centric benchmarks, their behavior across languages, tasks, and hallucination types is not yet well understood. In this work, we introduce Halluverse-M^3, a dataset designed to enable systematic analysis of hallucinations across multiple languages, multiple generation tasks, and multiple hallucination categories. Halluverse-M^3 covers four languages, English, Arabic, Hindi, and Turkish, and supports two generation tasks: question answering and dialogue summarization. The dataset explicitly distinguishes between entity-level, relation-level, and sentence-level hallucinations. Hallucinated outputs are constructed through a controlled editing process and validated by human annotators, ensuring clear alignment between original content and hallucinated generations. Using this dataset, we evaluate a diverse set of contemporary open-source and proprietary language models on fine-grained hallucination detection. Our results show that question answering is consistently easier than dialogue summarization, while sentence-level hallucinations remain challenging even for the strongest models. Performance is highest in English and degrades in lower-resource languages, with Hindi exhibiting the lowest detection accuracy. Overall, Halluverse-M^3 provides a realistic and challenging benchmark for studying hallucinations in multilingual, multi-task settings. We release the dataset to support future research on hallucination detection and mitigation\footnote{https://huggingface.co/datasets/sabdalja/HalluVerse-M3}.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Halluverse-M^3：大规模语言模型中幻觉的多任务多语言基准</div>
<div class="mono" style="margin-top:8px">大规模语言模型中的幻觉仍然是一个持续的挑战，尤其是在多语言和生成环境中，保持事实一致性非常困难。尽管最近的模型在以英语为中心的基准测试中表现出色，但它们在不同语言、任务和幻觉类型中的行为尚未得到充分理解。在本研究中，我们引入了Halluverse-M^3数据集，旨在支持对多种语言、多种生成任务和多种幻觉类别的幻觉进行系统分析。Halluverse-M^3涵盖了四种语言：英语、阿拉伯语、印地语和土耳其语，并支持两种生成任务：问答和对话总结。数据集明确区分了实体级、关系级和句子级的幻觉。幻觉输出通过受控编辑过程构建，并由人类注释员验证，确保原始内容与幻觉生成之间有明确的对齐。使用此数据集，我们对一系列当代开源和专有语言模型进行了细粒度幻觉检测评估。结果显示，问答任务始终比对话总结任务更容易，而句子级幻觉即使对于最强的模型也仍然具有挑战性。性能在英语中最高，在低资源语言中下降，印地语的检测准确性最低。总体而言，Halluverse-M^3为研究多语言、多任务环境中的幻觉提供了一个现实且具有挑战性的基准。我们发布了该数据集以支持未来关于幻觉检测和缓解的研究\footnote{https://huggingface.co/datasets/sabdalja/HalluVerse-M3}。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the challenge of hallucinations in large language models, especially in multilingual and generative settings. It introduces Halluverse-M^3, a dataset that evaluates hallucinations across four languages and two tasks. The dataset distinguishes between entity-level, relation-level, and sentence-level hallucinations and shows that question answering is easier than dialogue summarization, with performance varying by language, being highest in English and lowest in Hindi. The findings highlight the need for improved hallucination detection and mitigation in lower-resource languages.</div>
<div class="mono" style="margin-top:8px">该研究针对大型语言模型中的幻觉问题，特别是在多语言和生成性设置中的挑战。研究引入了Halluverse-M^3数据集，该数据集评估了四种语言和两种任务中的幻觉。数据集将幻觉分为实体级、关系级和句子级，并表明问答任务比对话总结任务更容易，但不同语言的表现差异较大，英语表现最佳，而印地语表现最差。研究结果强调了在低资源语言中需要改进幻觉检测和缓解的必要性。</div>
</details>
</div>
<div class="card">
<div class="title">Seeing Beyond Redundancy: Task Complexity&#x27;s Role in Vision Token Specialization in VLLMs</div>
<div class="meta-line">Authors: Darryl Hannan, John Cooper, Dylan White, Yijing Watkins</div>
<div class="meta-line">First: 2026-02-06T18:13:01+00:00 · Latest: 2026-02-06T18:13:01+00:00</div>
<div class="meta-line">Comments: 25 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06914v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06914v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision capabilities in vision large language models (VLLMs) have consistently lagged behind their linguistic capabilities. In particular, numerous benchmark studies have demonstrated that VLLMs struggle when fine-grained visual information or spatial reasoning is required. However, we do not yet understand exactly why VLLMs struggle so much with these tasks relative to others. Some works have focused on visual redundancy as an explanation, where high-level visual information is uniformly spread across numerous tokens and specific, fine-grained visual information is discarded. In this work, we investigate this premise in greater detail, seeking to better understand exactly how various types of visual information are processed by the model and what types of visual information are discarded. To do so, we introduce a simple synthetic benchmark dataset that is specifically constructed to probe various visual features, along with a set of metrics for measuring visual redundancy, allowing us to better understand the nuances of their relationship. Then, we explore fine-tuning VLLMs on a number of complex visual tasks to better understand how redundancy and compression change based upon the complexity of the data that a model is trained on. We find that there is a connection between task complexity and visual compression, implying that having a sufficient ratio of high complexity visual data is crucial for altering the way that VLLMs distribute their visual representation and consequently improving their performance on complex visual tasks. We hope that this work will provide valuable insights for training the next generation of VLLMs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>超越冗余：任务复杂性在VLLMs视觉标记专业化中的作用</div>
<div class="mono" style="margin-top:8px">视觉能力在视觉大型语言模型（VLLMs）中一直落后于语言能力。特别是，许多基准研究表明，当需要细粒度的视觉信息或空间推理时，VLLMs会遇到困难。然而，我们尚未完全理解为什么VLLMs在这些任务上比其他任务更困难。一些研究将视觉冗余视为解释之一，其中高级视觉信息均匀分布在许多标记中，而特定的细粒度视觉信息被丢弃。在本研究中，我们更详细地探讨了这一假设，旨在更好地了解模型如何处理各种类型的视觉信息以及丢弃了哪些类型的视觉信息。为此，我们引入了一个简单的合成基准数据集，该数据集特别设计用于探测各种视觉特征，以及一套衡量视觉冗余的指标，使我们能够更好地理解它们之间的细微差别。然后，我们探索在多种复杂视觉任务上微调VLLMs，以更好地了解冗余和压缩如何根据模型训练的数据复杂性而变化。我们发现任务复杂性与视觉压缩之间存在联系，表明拥有足够的高复杂度视觉数据的比例对于改变VLLMs的视觉表示方式并相应提高其在复杂视觉任务上的性能至关重要。我们希望这项工作能为训练下一代VLLMs提供有价值的见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates why vision large language models (VLLMs) struggle with complex visual tasks, focusing on visual redundancy. The researchers developed a synthetic dataset to measure visual redundancy and fine-tuned VLLMs on various complex visual tasks. They found that task complexity influences visual compression, suggesting that a higher proportion of complex visual data is necessary to improve VLLMs&#x27; performance on intricate visual tasks.</div>
<div class="mono" style="margin-top:8px">该研究探讨了为什么视觉大型语言模型（VLLMs）在处理复杂视觉任务时表现不佳，重点关注视觉冗余的作用。研究人员开发了一个合成数据集来衡量视觉冗余，并探索在各种复杂视觉任务上微调VLLMs。他们发现任务复杂性影响视觉压缩，表明需要更高比例的复杂视觉数据来提高VLLMs在复杂视觉任务上的表现。</div>
</details>
</div>
<div class="card">
<div class="title">TamperBench: Systematically Stress-Testing LLM Safety Under Fine-Tuning and Tampering</div>
<div class="meta-line">Authors: Saad Hossain, Tom Tseng, Punya Syon Pandey, Samanvay Vajpayee, Matthew Kowal, Nayeema Nonta, Samuel Simko, Stephen Casper, Zhijing Jin, Kellin Pelrine, Sirisha Rambhatla</div>
<div class="meta-line">First: 2026-02-06T18:04:38+00:00 · Latest: 2026-02-06T18:04:38+00:00</div>
<div class="meta-line">Comments: 28 pages, 13 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06911v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06911v1">PDF</a> · <a href="https://github.com/criticalml-uw/TamperBench">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As increasingly capable open-weight large language models (LLMs) are deployed, improving their tamper resistance against unsafe modifications, whether accidental or intentional, becomes critical to minimize risks. However, there is no standard approach to evaluate tamper resistance. Varied data sets, metrics, and tampering configurations make it difficult to compare safety, utility, and robustness across different models and defenses. To this end, we introduce TamperBench, the first unified framework to systematically evaluate the tamper resistance of LLMs. TamperBench (i) curates a repository of state-of-the-art weight-space fine-tuning attacks and latent-space representation attacks; (ii) enables realistic adversarial evaluation through systematic hyperparameter sweeps per attack-model pair; and (iii) provides both safety and utility evaluations. TamperBench requires minimal additional code to specify any fine-tuning configuration, alignment-stage defense method, and metric suite while ensuring end-to-end reproducibility. We use TamperBench to evaluate 21 open-weight LLMs, including defense-augmented variants, across nine tampering threats using standardized safety and capability metrics with hyperparameter sweeps per model-attack pair. This yields novel insights, including effects of post-training on tamper resistance, that jailbreak-tuning is typically the most severe attack, and that Triplet emerges as a leading alignment-stage defense. Code is available at: https://github.com/criticalml-uw/TamperBench</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>TamperBench：系统地测试细调和篡改下LLM的安全性</div>
<div class="mono" style="margin-top:8px">随着越来越强大的开放权重大型语言模型（LLMs）的部署，提高其对不安全修改的抗篡改能力变得至关重要，无论是偶然的还是故意的，以最小化风险。然而，目前没有标准的方法来评估抗篡改能力。不同的数据集、度量标准和篡改配置使得难以在不同模型和防御措施之间比较安全性、实用性和鲁棒性。为此，我们引入了TamperBench，这是第一个统一框架，用于系统地评估LLM的抗篡改能力。TamperBench（i）收集了最先进的权重空间细调攻击和潜在空间表示攻击的仓库；（ii）通过针对每种攻击-模型对进行系统超参数扫描，实现现实的对抗评估；（iii）提供安全性和实用性评估。TamperBench 只需最少的额外代码即可指定任何细调配置、对齐阶段防御方法和度量标准集，同时确保端到端可再现性。我们使用TamperBench对21个开放权重LLM进行了评估，包括防御增强变体，使用标准化的安全性和能力度量，在每种模型-攻击对上进行超参数扫描。这产生了新的见解，包括后训练对抗篡改的影响，jailbreak-tuning通常是最严重的攻击，Triplet作为对齐阶段防御的领先方法。代码可在：https://github.com/criticalml-uw/TamperBench</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">TamperBench is a unified framework designed to systematically evaluate the tamper resistance of large language models (LLMs) under fine-tuning and tampering. It curates a repository of state-of-the-art attacks, enables realistic adversarial evaluations through hyperparameter sweeps, and provides both safety and utility evaluations. The framework evaluates 21 open-weight LLMs across nine tampering threats, revealing insights such as the severity of jailbreak-tuning attacks and the effectiveness of Triplet as an alignment-stage defense.</div>
<div class="mono" style="margin-top:8px">TamperBench 是一个统一框架，旨在系统地评估大型语言模型（LLMs）在面对各种微调和潜在空间表示攻击时的抗篡改能力。它包含了一个最先进的攻击库，通过超参数扫描实现现实的对抗评估，并提供安全性和实用性评估。研究评估了21个开源的LLMs，包括增强防御的变体，针对九种篡改威胁，揭示了诸如 jailbreak-tuning 攻击的严重性以及 Triplet 作为对齐阶段防御的有效性等新见解。</div>
</details>
</div>
<div class="card">
<div class="title">Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation</div>
<div class="meta-line">Authors: Min-Seop Kwak, Junho Kim, Sangdoo Yun, Dongyoon Han, Taekyung Kim, Seungryong Kim, Jin-Hwa Kim</div>
<div class="meta-line">First: 2025-06-13T16:19:00+00:00 · Latest: 2026-02-06T17:56:06+00:00</div>
<div class="meta-line">Comments: Project page at https://cvlab-kaist.github.io/MoAI</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.11924v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.11924v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://cvlab-kaist.github.io/MoAI">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce a diffusion-based framework that performs aligned novel view image and geometry generation via a warping-and-inpainting methodology. Unlike prior methods that require dense posed images or pose-embedded generative models limited to in-domain views, our method leverages off-the-shelf geometry predictors to predict partial geometries viewed from reference images, and formulates novel-view synthesis as an inpainting task for both image and geometry. To ensure accurate alignment between generated images and geometry, we propose cross-modal attention distillation, where attention maps from the image diffusion branch are injected into a parallel geometry diffusion branch during both training and inference. This multi-task approach achieves synergistic effects, facilitating geometrically robust image synthesis as well as well-defined geometry prediction. We further introduce proximity-based mesh conditioning to integrate depth and normal cues, interpolating between point cloud and filtering erroneously predicted geometry from influencing the generation process. Empirically, our method achieves high-fidelity extrapolative view synthesis on both image and geometry across a range of unseen scenes, delivers competitive reconstruction quality under interpolation settings, and produces geometrically aligned colored point clouds for comprehensive 3D completion. Project page is available at https://cvlab-kaist.github.io/MoAI.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过跨模态注意力灌输实现对齐的新视角图像和几何合成</div>
<div class="mono" style="margin-top:8px">我们提出了一种基于扩散的框架，通过扭曲和修复方法实现对齐的新视角图像和几何生成。与需要密集姿态图像或姿态嵌入生成模型的先前方法不同，我们的方法利用现成的几何预测器预测参考图像中的部分几何形状，并将新视角合成公式化为图像和几何的修复任务。为了确保生成的图像和几何之间的准确对齐，我们提出了跨模态注意力蒸馏，其中图像扩散分支的注意力图在训练和推理过程中注入到并行的几何扩散分支中。这种多任务方法实现了协同效应，促进了几何稳健的图像合成以及几何预测的明确性。我们进一步引入基于邻近的网格条件，整合深度和法线线索，插值点云并过滤错误预测的几何形状以影响生成过程。实验证明，我们的方法在不同未见场景的图像和几何的高保真外推视图合成方面表现出色，在插值设置下提供了竞争力的重建质量，并生成了几何对齐的彩色点云以实现全面的3D完成。项目页面可在https://cvlab-kaist.github.io/MoAI获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces a diffusion-based framework for aligned novel view image and geometry synthesis using a warping-and-inpainting approach. Unlike previous methods that rely on dense posed images or pose-embedded models, this method uses off-the-shelf geometry predictors and formulates novel-view synthesis as an inpainting task. The key innovation is cross-modal attention distillation, which ensures accurate alignment between generated images and geometry. The method also incorporates proximity-based mesh conditioning to improve geometry prediction. Experiments show high-fidelity view synthesis and competitive reconstruction quality across various scenes, and the generation of geometrically aligned colored point clouds for 3D completion.</div>
<div class="mono" style="margin-top:8px">研究提出了一种基于扩散的框架，使用变形和修复方法实现对齐的新视角图像和几何生成。不同于需要密集姿态图像或姿态嵌入生成模型的先前方法，该方法从参考图像中预测部分几何，并将新颖视角合成视为图像和几何的修复任务。通过交叉模态注意力蒸馏确保生成的图像和几何之间的准确对齐，并通过基于邻近的网格条件整合深度和法线线索，提高几何稳健的图像合成和定义良好的几何预测。该方法实现了高保真度的外推视角合成和各种未见场景下的竞争性重建质量，并生成几何对齐的彩色点云，实现全面的3D完成。</div>
</details>
</div>
<div class="card">
<div class="title">Demystifying Mergeability: Interpretable Properties to Predict Model Merging Success</div>
<div class="meta-line">Authors: Luca Zhou, Bo Zhao, Rose Yu, Emanuele Rodolà</div>
<div class="meta-line">First: 2026-01-29T20:00:26+00:00 · Latest: 2026-02-06T17:53:23+00:00</div>
<div class="meta-line">Comments: 8 pages of main paper, 3 figures in the main paper, 4 tables in the main paper, many more figures and tables in the appendix</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22285v3">Abs</a> · <a href="https://arxiv.org/pdf/2601.22285v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Model merging combines knowledge from separately fine-tuned models, yet success factors remain poorly understood. While recent work treats mergeability as an intrinsic property, we show with an architecture-agnostic framework that it fundamentally depends on both the merging method and the partner tasks. Using linear optimization over a set of interpretable pairwise metrics (e.g., gradient L2 distance), we uncover properties correlating with post-merge performance across four merging methods. We find substantial variation in success drivers (46.7% metric overlap; 55.3% sign agreement), revealing method-specific &quot;fingerprints&quot;. Crucially, however, subspace overlap and gradient alignment metrics consistently emerge as foundational, method-agnostic prerequisites for compatibility. These findings provide a diagnostic foundation for understanding mergeability and motivate future fine-tuning strategies that explicitly encourage these properties.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>揭开可合并性的面纱：可解释的属性预测模型合并成功率</div>
<div class="mono" style="margin-top:8px">模型合并将来自独立微调模型的知识结合起来，但其成功因素仍不甚明了。尽管近期工作将可合并性视为一种固有属性，但我们通过一个架构无关的框架表明，它实际上取决于合并方法和合作伙伴任务。利用线性优化在一组可解释的成对度量（例如梯度L2距离）上，我们发现与合并后性能相关联的属性。我们发现成功驱动因素存在显著差异（46.7%的度量重叠；55.3%的符号一致性），揭示了方法特定的“指纹”。然而，关键的是，子空间重叠和梯度对齐度量始终作为兼容性的基础、方法无关的先决条件出现。这些发现为理解可合并性提供了诊断基础，并激发了未来明确鼓励这些属性的微调策略。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study aims to demystify the factors that determine the success of model merging by developing an architecture-agnostic framework. Using linear optimization over interpretable pairwise metrics, the research identifies that while there is substantial variation in success drivers, subspace overlap and gradient alignment metrics are consistently foundational prerequisites for compatibility across different merging methods. These findings offer a diagnostic basis for understanding model mergeability and suggest future fine-tuning strategies that explicitly encourage these properties.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过开发一个架构无关的框架来揭开模型合并成功因素的神秘面纱。通过线性优化一组可解释的成对度量，研究发现虽然成功驱动因素存在显著差异，但子空间重叠和梯度对齐度量始终是不同合并方法中兼容性的基础前提。这些发现为理解模型合并能力提供了诊断基础，并建议未来调优策略应明确促进这些属性。</div>
</details>
</div>
<div class="card">
<div class="title">DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise Injection and Auxiliary Networks</div>
<div class="meta-line">Authors: Nghiem T. Diep, Hien Dang, Tuan Truong, Tan Dinh, Huy Nguyen, Nhat Ho</div>
<div class="meta-line">First: 2025-10-05T19:27:48+00:00 · Latest: 2026-02-06T17:31:48+00:00</div>
<div class="meta-line">Comments: Nghiem T. Diep, Hien Dang, and Tuan Truong contributed equally to this work</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.04331v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.04331v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Parameter-efficient fine-tuning (PEFT) methods have become the standard paradigm for adapting large-scale models. Among these techniques, Weight-Decomposed Low-Rank Adaptation (DoRA) has been shown to improve both the learning capacity and training stability of the Low-Rank Adaptation (LoRA) method by explicitly decomposing pre-trained weights into magnitude and directional components. In this work, we propose DoRAN, a new technique designed to stabilize training and boost the sample efficiency of DoRA. Our framework introduces two key components: (i) the injection of learnable noise into the denominator of DoRA weight decomposition, which serves as an adaptive regularizer to mitigate instabilities and improve the estimation rate of low-rank matrices; and (ii) the replacement of static low-rank matrices with auxiliary networks that generate them dynamically, enabling parameter coupling between the query and value projection matrices, leading to improved sample efficiency both theoretically and empirically. Comprehensive experiments on vision and language benchmarks show that DoRAN consistently outperforms LoRA, DoRA, and other PEFT baselines, underscoring the effectiveness of combining noise-based regularization with network-based parameter generation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DoRAN：通过噪声注入和辅助网络稳定分解低秩适应</div>
<div class="mono" style="margin-top:8px">参数高效微调(PEFT)方法已成为适应大规模模型的标准范式。在这些技术中，分解低秩适应(DoRA)通过显式地将预训练权重分解为幅度和方向分量，已被证明能够提高低秩适应(LoRA)方法的学习能力和训练稳定性。在本文中，我们提出了一种新的技术DoRAN，旨在稳定训练并提高DoRA的样本效率。我们的框架引入了两个关键组件：(i) 在DoRA权重分解的分母中注入可学习的噪声，作为自适应正则化器，以减轻不稳定性并提高低秩矩阵的估计率；(ii) 用生成动态低秩矩阵的辅助网络替换静态低秩矩阵，使查询和值投影矩阵之间的参数耦合成为可能，从而在理论上和实验上都提高了样本效率。在视觉和语言基准上的全面实验表明，DoRAN在性能上始终优于LoRA、DoRA和其他PEFT基线，证明了结合基于噪声的正则化与基于网络的参数生成的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">DoRAN is a method designed to stabilize training and enhance the sample efficiency of DoRA, a parameter-efficient fine-tuning technique. It introduces learnable noise injection and auxiliary networks to improve the estimation of low-rank matrices, leading to better performance on vision and language benchmarks compared to LoRA, DoRA, and other PEFT baselines.</div>
<div class="mono" style="margin-top:8px">DoRAN 是一种旨在稳定 Weight-Decomposed Low-Rank Adaptation (DoRA) 训练并提高其样本效率的方法。它引入了可学习的噪声注入和辅助网络，以改进低秩矩阵的估计并实现参数耦合。在视觉和语言基准测试上的实验表明，DoRAN 在性能上优于 LoRA、DoRA 以及其他参数高效微调技术。</div>
</details>
</div>
<div class="card">
<div class="title">Inverse problems with diffusion models: MAP estimation via mode-seeking loss</div>
<div class="meta-line">Authors: Sai Bharath Chandra Gutha, Ricardo Vinuesa, Hossein Azizpour</div>
<div class="meta-line">First: 2025-12-11T10:51:34+00:00 · Latest: 2026-02-06T17:30:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.10524v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.10524v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A pre-trained unconditional diffusion model, combined with posterior sampling or maximum a posteriori (MAP) estimation techniques, can solve arbitrary inverse problems without task-specific training or fine-tuning. However, existing posterior sampling and MAP estimation methods often rely on modeling approximations and can also be computationally demanding. In this work, we propose a new MAP estimation strategy for solving inverse problems with a pre-trained unconditional diffusion model. Specifically, we introduce the variational mode-seeking loss (VML) and show that its minimization at each reverse diffusion step guides the generated sample towards the MAP estimate (modes in practice). VML arises from a novel perspective of minimizing the Kullback-Leibler (KL) divergence between the diffusion posterior $p(\mathbf{x}_0|\mathbf{x}_t)$ and the measurement posterior $p(\mathbf{x}_0|\mathbf{y})$, where $\mathbf{y}$ denotes the measurement. Importantly, for linear inverse problems, VML can be analytically derived without any modeling approximations. Based on further theoretical insights, we propose VML-MAP, an empirically effective algorithm for solving inverse problems via VML minimization, and validate its efficacy in both performance and computational time through extensive experiments on diverse image-restoration tasks across multiple datasets.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of solving inverse problems using a pre-trained unconditional diffusion model. It introduces a new MAP estimation strategy called variational mode-seeking loss (VML), which guides the generated sample towards the MAP estimate during reverse diffusion steps. Theoretical insights show that VML can be analytically derived for linear inverse problems without modeling approximations. Experiments demonstrate that VML-MAP effectively solves various image-restoration tasks with improved performance and computational efficiency.</div>
<div class="mono" style="margin-top:8px">本文提出了一种使用预训练无条件扩散模型解决逆问题的新MAP估计策略。该方法引入了变分模式搜索损失（VML），在反向扩散步骤中引导生成样本向MAP估计靠拢。对于线性逆问题，VML可以无需建模近似进行解析推导。通过在多个数据集上的图像恢复任务中进行广泛实验，验证了VML-MAP算法在性能和计算时间上的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks</div>
<div class="meta-line">Authors: Haotian Li, Shijun Yang, Weizhen Qi, Silei Zhao, Rui Hua, Mingzhu Song, Xiaojian Yang, Chao Peng</div>
<div class="meta-line">First: 2026-01-26T07:27:47+00:00 · Latest: 2026-02-06T17:29:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18226v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18226v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system&#x27;s capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>云阙代理技术报告：一种完全可复现的零起点就地自我演化代理系统用于开放性任务</div>
<div class="mono" style="margin-top:8px">传统的代理系统在任务分布持续漂移且外部监督稀缺的开放性环境中往往难以应对。它们依赖于静态工具集或离线训练，无法跟上这些动态变化，使系统的能效边界变得僵化且未知。为解决这一问题，我们提出了就地自我演化范式。该方法将顺序任务交互视为连续的经验流，使系统能够通过短期执行反馈提炼出长期可重用的能力，而无需访问真实标签。在此框架下，我们将工具演化视为能力扩展的关键路径，提供可验证的二元反馈信号。在此框架下，我们开发了云阙代理系统，该系统通过迭代合成、优化和重用工具来应对新兴挑战。为了优化演化效率，我们进一步引入了并行批处理演化策略。在零起点设置下的五个不同基准上的实证评估表明，与专有基线相比，性能显著提升。此外，补充的温启动评估证实，积累的一般知识可以无缝转移到新领域。最后，我们提出了一种新的度量标准来监控演化收敛，类似于传统优化中的训练损失函数。我们开源了我们的代码库、系统跟踪和演化工具，以促进未来在稳健的自我演化智能方面的研究。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the limitations of conventional agent systems in open-ended environments by proposing the In-Situ Self-Evolving paradigm. This paradigm treats task interactions as a continuous stream of experience, allowing the system to evolve its capabilities through short-term feedback without ground-truth labels. The authors developed Yunjue Agent, which iteratively synthesizes and optimizes tools to handle emerging challenges. They introduced a Parallel Batch Evolution strategy to enhance evolutionary efficiency. Empirical evaluations across five benchmarks showed significant performance gains over proprietary baselines, and the accumulated knowledge could be transferred to new domains. A novel metric was proposed to monitor evolution convergence, similar to training loss in conventional optimization. The system is open-sourced to promote further research in self-evolving intelligence.</div>
<div class="mono" style="margin-top:8px">论文提出了一种基于现场自我进化的范式，以解决传统代理系统在开放环境中的局限性。该范式将任务交互视为连续的经验流，使系统能够在没有地面真实标签的情况下进化其能力。作者开发了Yunjue代理，该代理通过迭代合成、优化和重用工具来应对新兴挑战。他们还引入了并行批处理进化策略以提高进化效率。在五个基准上的实证评估显示，与专有基线相比，性能有了显著提升，系统的一般知识可以无缝转移到新领域。还提出了一种新的进化收敛度度量，类似于传统优化中的训练损失。代码库、系统跟踪和进化工具已开源，以支持未来的研究。</div>
</details>
</div>
<div class="card">
<div class="title">FlashBlock: Attention Caching for Efficient Long-Context Block Diffusion</div>
<div class="meta-line">Authors: Zhuokun Chen, Jianfei Cai, Bohan Zhuang</div>
<div class="meta-line">First: 2026-02-05T04:57:21+00:00 · Latest: 2026-02-06T17:20:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.05305v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.05305v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://caesarhhh.github.io/FlashBlock/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Generating long-form content, such as minute-long videos and extended texts, is increasingly important for modern generative models. Block diffusion improves inference efficiency via KV caching and block-wise causal inference and has been widely adopted in diffusion language models and video generation. However, in long-context settings, block diffusion still incurs substantial overhead from repeatedly computing attention over a growing KV cache. We identify an underexplored property of block diffusion: cross-step redundancy of attention within a block. Our analysis shows that attention outputs from tokens outside the current block remain largely stable across diffusion steps, while block-internal attention varies significantly. Based on this observation, we propose FlashBlock, a cached block-external attention mechanism that reuses stable attention output, reducing attention computation and KV cache access without modifying the diffusion process. Moreover, FlashBlock is orthogonal to sparse attention and can be combined as a complementary residual reuse strategy, substantially improving model accuracy under aggressive sparsification. Experiments on diffusion language models and video generation demonstrate up to 1.44$\times$ higher token throughput and up to 1.6$\times$ reduction in attention time, with negligible impact on generation quality. Project page: https://caesarhhh.github.io/FlashBlock/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FlashBlock：高效长上下文块扩散中的注意力缓存</div>
<div class="mono" style="margin-top:8px">生成长形式内容，如一分钟的视频和扩展文本，对于现代生成模型来说越来越重要。块扩散通过键值缓存和块级因果推理来提高推理效率，并已在扩散语言模型和视频生成中广泛采用。然而，在长上下文设置中，块扩散仍然会因反复计算不断扩大的键值缓存而产生大量开销。我们发现块扩散的一个未被充分探索的特性：块内步骤之间的注意力交叉冗余。我们的分析表明，在扩散步骤中，当前块外部的令牌的注意力输出保持相对稳定，而块内部的注意力显著变化。基于这一观察，我们提出了FlashBlock，这是一种缓存块外部注意力机制，通过重用稳定的注意力输出来减少注意力计算和键值缓存访问，而不修改扩散过程。此外，FlashBlock 与稀疏注意力是正交的，可以作为补充的残差重用策略结合使用，在激进稀疏化下显著提高模型准确性。在扩散语言模型和视频生成上的实验表明，FlashBlock 可以将令牌吞吐量提高多达 1.44 倍，将注意力时间减少多达 1.6 倍，且对生成质量几乎没有影响。项目页面：https://caesarhhh.github.io/FlashBlock/</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">FlashBlock addresses the inefficiency of block diffusion in long-context settings by proposing a cached block-external attention mechanism that reuses stable attention outputs, reducing attention computation and KV cache access. Experiments show up to 1.44 times higher token throughput and 1.6 times less attention time with minimal impact on generation quality.</div>
<div class="mono" style="margin-top:8px">论文提出了一种名为FlashBlock的缓存块外部注意力机制，以解决使用扩散模型生成长内容时的效率问题。该机制减少了在长上下文中不断对增长的KV缓存进行注意力计算的计算开销。实验结果显示，FlashBlock可以实现最高1.44倍的令牌吞吐量提升和1.6倍的注意力时间减少，同时不影响生成质量。</div>
</details>
</div>
<div class="card">
<div class="title">Prompt Reinjection: Alleviating Prompt Forgetting in Multimodal Diffusion Transformers</div>
<div class="meta-line">Authors: Yuxuan Yao, Yuxuan Chen, Hui Li, Kaihui Cheng, Qipeng Guo, Yuwei Sun, Zilong Dong, Jingdong Wang, Siyu Zhu</div>
<div class="meta-line">First: 2026-02-06T17:19:53+00:00 · Latest: 2026-02-06T17:19:53+00:00</div>
<div class="meta-line">Comments: 18 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06886v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06886v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal Diffusion Transformers (MMDiTs) for text-to-image generation maintain separate text and image branches, with bidirectional information flow between text tokens and visual latents throughout denoising. In this setting, we observe a prompt forgetting phenomenon: the semantics of the prompt representation in the text branch is progressively forgotten as depth increases. We further verify this effect on three representative MMDiTs--SD3, SD3.5, and FLUX.1 by probing linguistic attributes of the representations over the layers in the text branch. Motivated by these findings, we introduce a training-free approach, prompt reinjection, which reinjects prompt representations from early layers into later layers to alleviate this forgetting. Experiments on GenEval, DPG, and T2I-CompBench++ show consistent gains in instruction-following capability, along with improvements on metrics capturing preference, aesthetics, and overall text--image generation quality.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>提示重注入：多模态扩散变换器中的提示遗忘缓解</div>
<div class="mono" style="margin-top:8px">多模态扩散变换器（MMDiTs）在文本到图像生成中保持独立的文本和图像分支，在去噪过程中文本令牌和视觉潜在变量之间存在双向信息流。在这种设置中，我们观察到一种提示遗忘现象：文本分支中的提示表示的语义会随着深度增加而逐渐被遗忘。我们进一步通过在文本分支的各层中探测表示的语言属性，验证了这一效果。受这些发现的启发，我们提出了一种无需训练的方法——提示重注入，该方法将早期层中的提示表示重新注入到后续层中，以缓解这种遗忘现象。在GenEval、DPG和T2I-CompBench++上的实验显示，该方法在指令遵循能力方面表现出一致的改进，并且在偏好、美学和整体文本-图像生成质量方面也有所提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study addresses the prompt forgetting issue in Multimodal Diffusion Transformers (MMDiTs) by observing that the semantic information of prompt representations in the text branch is gradually lost as the depth increases. To mitigate this, the authors propose prompt reinjection, a training-free method that reintroduces prompt representations from earlier layers into later layers. The approach is evaluated on GenEval, DPG, and T2I-CompBench++, demonstrating consistent improvements in instruction-following capability and quality metrics such as preference, aesthetics, and overall text-image generation quality.</div>
<div class="mono" style="margin-top:8px">研究关注了多模态扩散变换器（MMDiTs）中提示遗忘的问题，即文本分支中的提示表示的语义信息会随着深度增加而逐渐丢失。为此，提出了一种无需训练的方法——提示重注入，该方法将早期层中的提示表示重新注入到后续层中，以减轻遗忘现象。该方法在GenEval、DPG和T2I-CompBench++上的一系列实验中，展示了在指令遵循能力和其他质量指标上的持续改进。</div>
</details>
</div>
<div class="card">
<div class="title">You Had One Job: Per-Task Quantization Using LLMs&#x27; Hidden Representations</div>
<div class="meta-line">Authors: Amit LeVi, Raz Lapid, Rom Himelstein, Chaim Baskin, Ravid Shwartz Ziv, Avi Mendelson</div>
<div class="meta-line">First: 2025-11-09T19:58:24+00:00 · Latest: 2026-02-06T17:13:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.06516v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.06516v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Many applications of large language models (LLMs) require only a narrow capability, yet common post-training quantization (PTQ) pipelines assign precision largely without regard to the target task. As a result, they may spend bits on layers that are less relevant to the task. We propose per-task mixed-precision PTQ guided by hidden representations. Given a small set of unlabeled calibration prompts from the target task, we estimate layer importance and allocate higher precision to task-relevant layers while lower to the rest, under a bits allocation budget. We introduce three task-aware allocation signals: \textbf{TAQ}, which scores layers using an information-stability criterion derived from activation geometry; \textbf{TAQO}, which ranks layers by direct sensitivity to single-layer quantization; and \textbf{TAQ-KL}, which measures output sensitivity via KL divergence under a noise proxy for quantization error. Together, these methods provide a simple, post-training framework that connects mechanistic signals to quantization decisions, enabling task-aligned compression without additional training.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>你只有一项任务：使用LLM隐藏表示的逐任务量化</div>
<div class="mono" style="margin-top:8px">许多大型语言模型（LLMs）的应用只需要狭窄的能力，但常见的后训练量化（PTQ）管道在分配精度时往往不考虑目标任务。因此，它们可能会在对任务影响较小的层上浪费比特。我们提出了一种由隐藏表示指导的逐任务混合精度PTQ。给定目标任务的一小组未标记校准提示，我们估计各层的重要性，并在预算内将更高精度分配给与任务相关的层，而将较低精度分配给其他层。我们引入了三种任务感知分配信号：\textbf{TAQ}，使用来自激活几何的信息稳定性标准评分层；\textbf{TAQO}，通过单层量化直接敏感性对层进行排序；以及\textbf{TAQ-KL}，通过量化误差的噪声代理下的KL散度测量输出敏感性。这些方法一起提供了一个简单的后训练框架，将机械信号与量化决策联系起来，无需额外训练即可实现任务对齐的压缩。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve the efficiency of large language models (LLMs) by applying task-specific quantization. The method uses hidden representations from a small set of calibration prompts to estimate the importance of each layer and allocate higher precision to task-relevant layers. Three task-aware allocation signals—TAQ, TAQO, and TAQ-KL—are introduced to guide the quantization process, resulting in a more efficient and task-aligned compression without additional training.</div>
<div class="mono" style="margin-top:8px">研究旨在通过任务特定的量化提高大型语言模型（LLMs）的效率。方法使用少量校准提示的隐藏表示来估计每一层的重要性，并将更高的精度分配给与任务相关的层。引入了三种任务感知分配信号——TAQ、TAQO 和 TAQ-KL，以指导量化过程，从而实现更高效的、与任务对齐的压缩，无需额外训练。</div>
</details>
</div>
<div class="card">
<div class="title">Constella: Supporting Storywriters&#x27; Interconnected Character Creation through LLM-based Multi-Agents</div>
<div class="meta-line">Authors: Syemin Park, Soobin Park, Youn-kyung Lim</div>
<div class="meta-line">First: 2025-07-08T09:39:02+00:00 · Latest: 2026-02-06T17:07:11+00:00</div>
<div class="meta-line">Comments: Accepted to ACM Transactions on Computer-Human Interaction (TOCHI)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.05820v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.05820v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Creating a cast of characters by attending to their relational dynamics is a critical aspect of most long-form storywriting. However, our formative study (N=14) reveals that writers struggle to envision new characters that could influence existing ones, balance similarities and differences among characters, and intricately flesh out their relationships. Based on these observations, we designed Constella, an LLM-based multi-agent tool that supports storywriters&#x27; interconnected character creation process. Constella suggests related characters (FRIENDS DISCOVERY feature), reveals the inner mindscapes of several characters simultaneously (JOURNALS feature), and manifests relationships through inter-character responses (COMMENTS feature). Our 7-8 day deployment study with storywriters (N=11) shows that Constella enabled the creation of expansive communities composed of related characters, facilitated the comparison of characters&#x27; thoughts and emotions, and deepened writers&#x27; understanding of character relationships. We conclude by discussing how multi-agent interactions can help distribute writers&#x27; attention and effort across the character cast.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Constella：基于LLM的多智能体支持故事创作者的关联性角色创作</div>
<div class="mono" style="margin-top:8px">构建角色群组并关注其关系动态是大多数长篇故事创作的关键方面。然而，我们的初步研究（N=14）表明，作家在构想能够影响现有角色的新角色、平衡角色间的相似性和差异性以及细致描绘角色关系方面存在困难。基于这些观察，我们设计了Constella，一种基于LLM的多智能体工具，以支持故事创作者的关联性角色创作过程。Constella 提出了相关角色（FRIENDS DISCOVERY 功能）、同时揭示多个角色的内心世界（JOURNALS 功能），并通过角色间的回应来表现关系（COMMENTS 功能）。我们的为期7-8天的部署研究（N=11）表明，Constella 使创作者能够创建由相关角色组成的广阔社区，促进了角色思想和情感的比较，并加深了创作者对角色关系的理解。最后，我们讨论了多智能体交互如何帮助分散创作者对角色群组的注意力和努力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of creating interconnected characters in long-form storywriting, which writers often find difficult. It introduces Constella, an LLM-based tool that suggests related characters, reveals inner thoughts of multiple characters, and shows relationships through inter-character responses. The study with 11 writers over 7-8 days demonstrated that Constella helped in creating extensive character communities, comparing characters&#x27; thoughts, and deepening understanding of character relationships.</div>
<div class="mono" style="margin-top:8px">研究旨在通过解决作家在构思新角色、平衡相似性和差异性以及描绘关系方面的挑战，帮助作家创建相互关联的角色。Constella，一个基于LLM的多代理工具，被设计来建议相关角色、揭示内心世界，并通过角色间的互动来表现关系。在为期7-8天的研究中，11位作家使用Constella创建了广泛的角色社区，促进了角色比较，并加深了对角色关系的理解。</div>
</details>
</div>
<div class="card">
<div class="title">TraceCoder: A Trace-Driven Multi-Agent Framework for Automated Debugging of LLM-Generated Code</div>
<div class="meta-line">Authors: Jiangping Huang, Wenguang Ye, Weisong Sun, Jian Zhang, Mingyue Zhang, Yang Liu</div>
<div class="meta-line">First: 2026-02-06T16:59:48+00:00 · Latest: 2026-02-06T16:59:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06875v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06875v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) often generate code with subtle but critical bugs, especially for complex tasks. Existing automated repair methods typically rely on superficial pass/fail signals, offering limited visibility into program behavior and hindering precise error localization. In addition, without a way to learn from prior failures, repair processes often fall into repetitive and inefficient cycles. To overcome these challenges, we present TraceCoder, a collaborative multi-agent framework that emulates the observe-analyze-repair process of human experts. The framework first instruments the code with diagnostic probes to capture fine-grained runtime traces, enabling deep insight into its internal execution. It then conducts causal analysis on these traces to accurately identify the root cause of the failure. This process is further enhanced by a novel Historical Lesson Learning Mechanism (HLLM), which distills insights from prior failed repair attempts to inform subsequent correction strategies and prevent recurrence of similar mistakes. To ensure stable convergence, a Rollback Mechanism enforces that each repair iteration constitutes a strict improvement toward the correct solution. Comprehensive experiments across multiple benchmarks show that TraceCoder achieves up to a 34.43\% relative improvement in Pass@1 accuracy over existing advanced baselines. Ablation studies verify the significance of each system component, with the iterative repair process alone contributing a 65.61\% relative gain in accuracy. Furthermore, TraceCoder significantly outperforms leading iterative methods in terms of both accuracy and cost-efficiency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>TraceCoder：一种基于跟踪的多智能体框架，用于自动调试LLM生成的代码</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）经常生成带有细微但关键错误的代码，尤其是在处理复杂任务时。现有的自动修复方法通常依赖于表面的通过/失败信号，这限制了对程序行为的可见性，阻碍了精确的错误定位。此外，没有从先前失败中学习的方法，修复过程往往陷入重复且低效的循环中。为克服这些挑战，我们提出了TraceCoder，这是一种协作的多智能体框架，模拟了人类专家的观察-分析-修复过程。该框架首先通过诊断探针对代码进行仪器化，以捕获细粒度的运行时跟踪，从而深入了解其内部执行情况。然后，通过对这些跟踪进行因果分析，准确地识别出失败的根本原因。这一过程进一步通过一种新颖的历史教训学习机制（HLLM）得到增强，该机制从先前失败的修复尝试中提炼出见解，以指导后续的纠正策略并防止类似错误的重复发生。为了确保稳定收敛，回滚机制确保每次修复迭代都严格向正确解决方案改进。在多个基准测试中的全面实验表明，TraceCoder在Pass@1准确率上相对于现有先进基线实现了高达34.43%的相对改进。消融研究验证了每个系统组件的重要性，仅迭代修复过程就贡献了65.61%的相对准确率提升。此外，TraceCoder在准确性和成本效率方面均显著优于领先的迭代方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">TraceCoder is a trace-driven multi-agent framework designed to automate the debugging of code generated by Large Language Models (LLMs). It uses diagnostic probes to capture detailed runtime traces, conducts causal analysis to pinpoint the root cause of errors, and incorporates a Historical Lesson Learning Mechanism to improve future repairs. Experiments show that TraceCoder achieves up to a 34.43% relative improvement in Pass@1 accuracy over existing methods and significantly outperforms leading iterative methods in terms of both accuracy and cost-efficiency.</div>
<div class="mono" style="margin-top:8px">TraceCoder 是一个基于追踪的多代理框架，旨在自动化调试大型语言模型（LLMs）生成的代码，尤其是复杂任务。它使用诊断探针捕获详细的运行时追踪，进行因果分析以确定错误的根本原因，并结合历史教训学习机制从过去的失败中学习以指导后续的修正策略。实验表明，TraceCoder 的 Pass@1 准确率相比现有方法提高了最多 34.43%，并且仅迭代修复过程就实现了 65.61% 的相对准确率提升。</div>
</details>
</div>
<div class="card">
<div class="title">RFDM: Residual Flow Diffusion Model for Efficient Causal Video Editing</div>
<div class="meta-line">Authors: Mohammadreza Salehi, Mehdi Noroozi, Luca Morreale, Ruchika Chavhan, Malcolm Chadwick, Alberto Gil Ramos, Abhinav Mehrotra</div>
<div class="meta-line">First: 2026-02-06T16:56:30+00:00 · Latest: 2026-02-06T16:56:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.06871v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.06871v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://smsd75.github.io/RFDM_page/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Instructional video editing applies edits to an input video using only text prompts, enabling intuitive natural-language control. Despite rapid progress, most methods still require fixed-length inputs and substantial compute. Meanwhile, autoregressive video generation enables efficient variable-length synthesis, yet remains under-explored for video editing. We introduce a causal, efficient video editing model that edits variable-length videos frame by frame. For efficiency, we start from a 2D image-to-image (I2I) diffusion model and adapt it to video-to-video (V2V) editing by conditioning the edit at time step t on the model&#x27;s prediction at t-1. To leverage videos&#x27; temporal redundancy, we propose a new I2I diffusion forward process formulation that encourages the model to predict the residual between the target output and the previous prediction. We call this Residual Flow Diffusion Model (RFDM), which focuses the denoising process on changes between consecutive frames. Moreover, we propose a new benchmark that better ranks state-of-the-art methods for editing tasks. Trained on paired video data for global/local style transfer and object removal, RFDM surpasses I2I-based methods and competes with fully spatiotemporal (3D) V2V models, while matching the compute of image models and scaling independently of input video length. More content can be found in: https://smsd75.github.io/RFDM_page/</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>RFDM：残差流扩散模型在高效因果视频编辑中的应用</div>
<div class="mono" style="margin-top:8px">指令视频编辑仅使用文本提示对输入视频进行编辑，实现直观的自然语言控制。尽管取得了快速进展，但大多数方法仍然需要固定长度的输入和大量计算。同时，自回归视频生成能够实现高效的可变长度合成，但在视频编辑方面的应用尚未得到充分探索。我们提出了一种因果高效视频编辑模型，能够逐帧编辑可变长度的视频。为了提高效率，我们从2D图像到图像（I2I）扩散模型出发，并通过在时间步t的编辑条件化于模型在t-1步的预测来适应视频到视频（V2V）编辑。为了利用视频的时间冗余性，我们提出了一种新的I2I扩散前向过程公式，鼓励模型预测目标输出与先前预测之间的残差。我们称之为残差流扩散模型（RFDM），该模型将去噪过程集中在连续帧之间的变化上。此外，我们还提出了一种新的基准测试，更好地评估最先进的方法在编辑任务中的表现。RFDM在配对视频数据上训练，用于全局/局部风格转换和对象去除，超越了基于I2I的方法，并与完全时空（3D）V2V模型竞争，同时与图像模型的计算量相当，并且与输入视频长度无关地扩展。有关更多信息，请参阅：https://smsd75.github.io/RFDM_page/</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop an efficient causal video editing model that can handle variable-length videos using text prompts. The method involves adapting a 2D image-to-image diffusion model to a video-to-video editing model, where the edit at each frame is conditioned on the previous frame&#x27;s prediction. The Residual Flow Diffusion Model (RFDM) focuses on predicting the differences between consecutive frames, which enhances efficiency. Experimental results show that RFDM outperforms 2D-based methods and matches the computational efficiency of image models, while achieving competitive performance with 3D spatiotemporal models for editing tasks like global/local style transfer and object removal, and it scales independently of input video length.</div>
<div class="mono" style="margin-top:8px">研究旨在开发一种高效的时间因果视频编辑模型，能够使用文本提示对可变长度的视频进行编辑。方法是将2D图像到图像的扩散模型适应为视频到视频编辑模型，通过在每个编辑步骤中条件化于上一步的预测来实现。残差流扩散模型（RFDM）专注于预测连续帧之间的变化，从而提高效率。实验结果表明，RFDM在性能上超越了基于2D的方法，并且在计算效率上与图像模型相当，同时在输入视频长度增加时仍能保持竞争力。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260209_0330.html">20260209_0330</a>
<a href="archive/20260208_0328.html">20260208_0328</a>
<a href="archive/20260207_0346.html">20260207_0346</a>
<a href="archive/20260206_0343.html">20260206_0343</a>
<a href="archive/20260205_0342.html">20260205_0342</a>
<a href="archive/20260204_0351.html">20260204_0351</a>
<a href="archive/20260202_0327.html">20260202_0327</a>
<a href="archive/20260201_0324.html">20260201_0324</a>
<a href="archive/20260131_0335.html">20260131_0335</a>
<a href="archive/20260130_0334.html">20260130_0334</a>
<a href="archive/20260129_0331.html">20260129_0331</a>
<a href="archive/20260128_0330.html">20260128_0330</a>
<a href="archive/20260127_0327.html">20260127_0327</a>
<a href="archive/20260126_0321.html">20260126_0321</a>
<a href="archive/20260125_0320.html">20260125_0320</a>
<a href="archive/20260124_0329.html">20260124_0329</a>
<a href="archive/20260123_0328.html">20260123_0328</a>
<a href="archive/20260122_0333.html">20260122_0333</a>
<a href="archive/20260121_0416.html">20260121_0416</a>
<a href="archive/20260120_0324.html">20260120_0324</a>
<a href="archive/20260119_0320.html">20260119_0320</a>
<a href="archive/20260118_0318.html">20260118_0318</a>
<a href="archive/20260117_0326.html">20260117_0326</a>
<a href="archive/20260116_0329.html">20260116_0329</a>
<a href="archive/20260115_0326.html">20260115_0326</a>
<a href="archive/20260114_0325.html">20260114_0325</a>
<a href="archive/20260113_0324.html">20260113_0324</a>
<a href="archive/20260112_0323.html">20260112_0323</a>
<a href="archive/20260111_0321.html">20260111_0321</a>
<a href="archive/20260110_0324.html">20260110_0324</a>
<a href="archive/20260109_0325.html">20260109_0325</a>
<a href="archive/20260108_0325.html">20260108_0325</a>
<a href="archive/20260107_0320.html">20260107_0320</a>
<a href="archive/20260106_0327.html">20260106_0327</a>
<a href="archive/20260105_0320.html">20260105_0320</a>
<a href="archive/20260104_0319.html">20260104_0319</a>
<a href="archive/20260103_0317.html">20260103_0317</a>
<a href="archive/20260102_0329.html">20260102_0329</a>
<a href="archive/20260101_0320.html">20260101_0320</a>
<a href="archive/20251231_0326.html">20251231_0326</a>
<a href="archive/20251230_0324.html">20251230_0324</a>
<a href="archive/20251229_0320.html">20251229_0320</a>
<a href="archive/20251228_0323.html">20251228_0323</a>
<a href="archive/20251227_0321.html">20251227_0321</a>
<a href="archive/20251226_0320.html">20251226_0320</a>
<a href="archive/20251225_0320.html">20251225_0320</a>
<a href="archive/20251224_0323.html">20251224_0323</a>
<a href="archive/20251223_0323.html">20251223_0323</a>
<a href="archive/20251222_0320.html">20251222_0320</a>
<a href="archive/20251221_0320.html">20251221_0320</a>
<a href="archive/20251220_0323.html">20251220_0323</a>
<a href="archive/20251219_0323.html">20251219_0323</a>
<a href="archive/20251218_0335.html">20251218_0335</a>
<a href="archive/20251217_0324.html">20251217_0324</a>
<a href="archive/20251216_0325.html">20251216_0325</a>
<a href="archive/20251215_1246.html">20251215_1246</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
