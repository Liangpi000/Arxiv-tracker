<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-01 03:20</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260101_0320</div>
    <div class="row"><div class="card">
<div class="title">Stream-DiffVSR: Low-Latency Streamable Video Super-Resolution via Auto-Regressive Diffusion</div>
<div class="meta-line">Authors: Hau-Shiang Shiu, Chin-Yang Lin, Zhixiang Wang, Chi-Wei Hsiao, Po-Fan Yu, Yu-Chih Chen, Yu-Lun Liu</div>
<div class="meta-line">First: 2025-12-29T18:59:57+00:00 · Latest: 2025-12-29T18:59:57+00:00</div>
<div class="meta-line">Comments: Project page: https://jamichss.github.io/stream-diffvsr-project-page/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23709v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23709v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://jamichss.github.io/stream-diffvsr-project-page/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion-based video super-resolution (VSR) methods achieve strong perceptual quality but remain impractical for latency-sensitive settings due to reliance on future frames and expensive multi-step denoising. We propose Stream-DiffVSR, a causally conditioned diffusion framework for efficient online VSR. Operating strictly on past frames, it combines a four-step distilled denoiser for fast inference, an Auto-regressive Temporal Guidance (ARTG) module that injects motion-aligned cues during latent denoising, and a lightweight temporal-aware decoder with a Temporal Processor Module (TPM) that enhances detail and temporal coherence. Stream-DiffVSR processes 720p frames in 0.328 seconds on an RTX4090 GPU and significantly outperforms prior diffusion-based methods. Compared with the online SOTA TMP, it boosts perceptual quality (LPIPS +0.095) while reducing latency by over 130x. Stream-DiffVSR achieves the lowest latency reported for diffusion-based VSR, reducing initial delay from over 4600 seconds to 0.328 seconds, thereby making it the first diffusion VSR method suitable for low-latency online deployment. Project page: https://jamichss.github.io/stream-diffvsr-project-page/</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Stream-DiffVSR：基于自回归扩散的低延迟流式视频超分辨率</div>
<div class="mono" style="margin-top:8px">基于扩散的视频超分辨率（VSR）方法在感知质量方面表现出色，但由于依赖未来帧和昂贵的多步去噪，它们在延迟敏感的设置中仍不实用。我们提出了Stream-DiffVSR，这是一种因果条件下的扩散框架，用于高效的在线VSR。该框架仅基于过去帧操作，结合了四步精简去噪器以实现快速推理，Auto-regressive Temporal Guidance (ARTG) 模块在潜空间去噪期间注入运动对齐的线索，以及具有Temporal Processor Module (TPM) 的轻量级时空解码器，以增强细节和时间连贯性。Stream-DiffVSR 在 RTX4090 GPU 上处理 720p 帧仅需 0.328 秒，并显著优于先前的基于扩散的方法。与在线 SOTA TMP 相比，它在感知质量（LPIPS +0.095）方面有所提升，同时将延迟降低了超过 130 倍。Stream-DiffVSR 实现了基于扩散的 VSR 中报告的最低延迟，将初始延迟从超过 4600 秒降低到 0.328 秒，从而使其成为第一个适合低延迟在线部署的扩散 VSR 方法。项目页面：https://jamichss.github.io/stream-diffvsr-project-page/</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Stream-DiffVSR is a causally conditioned diffusion framework for efficient online video super-resolution, addressing the latency issues of previous methods. It uses a four-step denoiser for fast inference, an Auto-regressive Temporal Guidance module to inject motion-aligned cues, and a lightweight temporal-aware decoder with a Temporal Processor Module. Stream-DiffVSR processes 720p frames in 0.328 seconds, significantly outperforming prior methods in terms of perceptual quality and latency, making it suitable for low-latency online deployment.</div>
<div class="mono" style="margin-top:8px">Stream-DiffVSR 是一种因果条件下的扩散框架，用于高效的在线视频超分辨率处理，能在 RTX4090 GPU 上以 0.328 秒的速度处理 720p 帧。它结合了快速四步去噪器、自回归时空引导模块和具有时空处理器模块的轻量级时空感知解码器。Stream-DiffVSR 在感知质量和延迟方面显著优于先前的方法，将初始延迟从超过 4600 秒降低到 0.328 秒，使其成为第一个适用于低延迟在线部署的扩散超分辨率方法。</div>
</details>
</div>
<div class="card">
<div class="title">Eliciting Behaviors in Multi-Turn Conversations</div>
<div class="meta-line">Authors: Jing Huang, Shujian Zhang, Lun Wang, Andrew Hard, Rajiv Mathews, John Lambert</div>
<div class="meta-line">First: 2025-12-29T18:57:10+00:00 · Latest: 2025-12-29T18:57:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23701v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23701v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in single-turn settings. In this work, we study behavior elicitation in the context of multi-turn conversations. We first offer an analytical framework that categorizes existing methods into three families based on their interactions with the target model: those that use only prior knowledge, those that use offline interactions, and those that learn from online interactions. We then introduce a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. We evaluate all three families of methods on automatically generating multi-turn test cases. We investigate the efficiency of these approaches by analyzing the trade-off between the query budget, i.e., the number of interactions with the target model, and the success rate, i.e., the discovery rate of behavior-eliciting inputs. We find that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries over three tasks where static methods from existing multi-turn conversation benchmarks find few or even no failure cases. Our work highlights a novel application of behavior elicitation methods in multi-turn conversation evaluation and the need for the community to move towards dynamic benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多轮对话中行为诱引</div>
<div class="mono" style="margin-top:8px">在对话环境中识别大型语言模型（LLMs）的具体且通常复杂的特定行为对于其评估至关重要。近期工作提出了新颖的技术来找到能够从目标模型中诱导特定行为的自然语言提示，但这些研究主要集中在单轮设置中。本文研究了行为诱引在多轮对话中的应用。我们首先提供了一个分析框架，将现有方法分为三类，基于其与目标模型的交互方式：仅使用先验知识的方法、使用离线交互的方法以及从在线交互中学习的方法。然后，我们引入了一种多轮在线方法的通用形式，统一了单轮和多轮的诱引。我们评估了这三类方法在自动生成多轮测试案例方面的表现。我们通过分析查询预算，即与目标模型的交互次数，与成功率，即行为诱引输入的发现率之间的权衡，研究了这些方法的效率。我们发现，在三个任务中，仅需几千次查询，在线方法就能实现平均45/19/77%的成功率，而现有的静态方法在多轮对话基准中发现的失败案例很少甚至没有。我们的工作突显了行为诱引方法在多轮对话评估中的新应用，并强调了社区转向动态基准的必要性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the challenge of eliciting specific behaviors in multi-turn conversations from large language models (LLMs) by proposing an analytical framework that classifies existing methods into three categories based on their interaction types. The research introduces a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. Experimental results show that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries across three tasks, outperforming static methods that find few or no failure cases in existing benchmarks.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决在多轮对话环境中从大型语言模型中引出特定行为的挑战。研究引入了一个分析框架，将现有方法分类为三种基于与目标模型交互方式的类别。然后提出了一个统一单轮和多轮行为引出的在线方法的多轮形式。实验结果表明，在三个任务中，使用少量数千次查询，在线方法可以分别实现45%、19%和77%的成功率，远超在多轮对话基准中往往无法找到失败案例的静态方法。</div>
</details>
</div>
<div class="card">
<div class="title">Improving Reasoning for Diffusion Language Models via Group Diffusion Policy Optimization</div>
<div class="meta-line">Authors: Kevin Rojas, Jiahe Lin, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, Molei Tao, Wei Deng</div>
<div class="meta-line">First: 2025-10-09T17:58:07+00:00 · Latest: 2025-12-29T18:55:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.08554v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.08554v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion language models (DLMs) enable parallel, order-agnostic generation with iterative refinement, offering a flexible alternative to autoregressive large language models (LLMs). However, adapting reinforcement learning (RL) fine-tuning to DLMs remains an open challenge because of the intractable likelihood. Pioneering work such as diffu-GRPO estimated token-level likelihoods via one-step unmasking. While computationally efficient, this approach is severely biased. A more principled foundation lies in sequence-level likelihoods, where the evidence lower bound (ELBO) serves as a surrogate. Yet, despite this clean mathematical connection, ELBO-based methods have seen limited adoption due to the prohibitive cost of likelihood evaluation. In this work, we revisit ELBO estimation and disentangle its sources of variance. This decomposition motivates reducing variance through fast, deterministic integral approximations along a few pivotal dimensions. Building on this insight, we introduce Group Diffusion Policy Optimization (GDPO), a new RL algorithm tailored for DLMs. GDPO leverages simple yet effective Semi-deterministic Monte Carlo schemes to mitigate the variance explosion of ELBO estimators under vanilla double Monte Carlo sampling, yielding a provably lower-variance estimator under tight evaluation budgets. Empirically, GDPO achieves consistent gains over pretrained checkpoints and outperforms diffu-GRPO, one of the state-of-the-art baselines, on the majority of math, reasoning, and coding benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过组扩散策略优化提高扩散语言模型的推理能力</div>
<div class="mono" style="margin-top:8px">扩散语言模型（DLMs）能够进行并行、无序的生成，并通过迭代细化，提供了一种灵活的替代自回归大型语言模型（LLMs）的选择。然而，将强化学习（RL）微调适应DLMs仍然是一个开放的挑战，因为难以计算似然性。先驱工作如diffu-GRPO通过一次去遮蔽估计了token级别的似然性。尽管计算效率高，但这种方法严重有偏。更原则的基础在于序列级别的似然性，其中证据下界（ELBO）作为替代。尽管存在这种清晰的数学联系，基于ELBO的方法由于似然性评估的成本高昂而受到限制。在本文中，我们重新审视了ELBO的估计，并将其方差来源进行了分解。这种分解促使我们通过沿少数关键维度进行快速、确定性的积分近似来减少方差。基于这一洞察，我们引入了组扩散策略优化（GDPO），这是一种新的针对DLMs的RL算法。GDPO利用简单的半确定性蒙特卡洛方案来缓解在常规双蒙特卡洛采样下ELBO估计器的方差爆炸，从而在严格的评估预算下提供一个方差更低的估计器。实验上，GDPO在预训练检查点上实现了持续的收益，并在大多数数学、推理和编码基准上优于diffu-GRPO，这是当前最先进的基线之一。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of adapting reinforcement learning fine-tuning to diffusion language models (DLMs) by revisiting the estimation of sequence-level likelihoods. The authors introduce Group Diffusion Policy Optimization (GDPO), which uses semi-deterministic Monte Carlo schemes to reduce the variance of ELBO estimators, leading to a more efficient and lower-variance approach. GDPO outperforms existing methods like diffu-GRPO on math, reasoning, and coding benchmarks, demonstrating consistent gains over pretrained checkpoints.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过重新审视证据下界（ELBO）估计，解决将强化学习微调应用于扩散语言模型（DLMs）的挑战。作者提出了Group Diffusion Policy Optimization（GDPO），利用半确定性蒙特卡洛方案来减少ELBO估计器的方差，从而在严格的评估预算下获得一个方差更低的估计器。实验结果显示，GDPO在数学、推理和编码基准测试中优于diffu-GRPO，并且在预训练检查点上实现了持续的性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans</div>
<div class="meta-line">Authors: Sky CH-Wang, Justin Svegliato, Helen Appel, Jason Eisner</div>
<div class="meta-line">First: 2025-12-29T18:51:56+00:00 · Latest: 2025-12-29T18:51:56+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23693v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23693v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a method and dataset for fine-tuning language models with preference supervision using feedback-driven improvement chains. Given a model response, an annotator provides fine-grained feedback by marking ``liked&#x27;&#x27; and ``disliked&#x27;&#x27; spans and specifying what they liked or disliked about them. The base model then rewrites the disliked spans accordingly, proceeding from left to right, forming a sequence of incremental improvements. We construct preference pairs for direct alignment from each adjacent step in the chain, enabling the model to learn from localized, targeted edits. We find that our approach outperforms direct alignment methods based on standard A/B preference ranking or full contrastive rewrites, demonstrating that structured, revision-based supervision leads to more efficient and effective preference tuning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用文本片段细粒度人类反馈微调LLMs</div>
<div class="mono" style="margin-top:8px">我们提出了一种方法和数据集，使用反馈驱动的改进链对语言模型进行微调，以偏好监督的形式。对于模型的响应，标注员通过标记“喜欢”和“不喜欢”的片段并说明他们喜欢或不喜欢的原因来提供细粒度的反馈。基础模型然后相应地重写不喜欢的片段，从左到右进行，形成一系列逐步改进的序列。我们从改进链中的每个相邻步骤构建偏好配对，直接对齐，使模型能够从局部、针对性的编辑中学习。我们发现，我们的方法优于基于标准A/B偏好排名或完整对比重写的直接对齐方法，表明结构化的、基于修订的监督可以更高效、更有效地进行偏好调优。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve language models through fine-grained human feedback on text spans, using a feedback-driven improvement chain. Annotators mark liked and disliked spans and specify the reasons, prompting the model to rewrite the disliked parts, forming a sequence of incremental improvements. The study shows that this approach outperforms direct alignment methods, indicating that structured, revision-based supervision is more efficient and effective for preference tuning.</div>
<div class="mono" style="margin-top:8px">研究旨在通过文本片段的精细人工反馈来提升语言模型，方法是让标注者标记喜欢和不喜欢的部分并说明原因，模型随后对不喜欢的部分进行修改，形成一系列逐步改进的过程。研究发现，这种方法通过链式每一步生成偏好对进行直接对齐，比基于标准偏好排名或全面对比重写的方法更高效和有效，表明结构化的修订监督更有助于偏好调优。</div>
</details>
</div>
<div class="card">
<div class="title">PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech</div>
<div class="meta-line">Authors: Deepak Babu Piskala</div>
<div class="meta-line">First: 2025-12-29T18:43:23+00:00 · Latest: 2025-12-29T18:43:23+00:00</div>
<div class="meta-line">Comments: Benchmark dataset and evaluation suite. Data and code available at: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench https://github.com/prdeepakbabu/ProfASR-Bench</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23686v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23686v1">PDF</a> · <a href="https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench">Code1</a> · <a href="https://github.com/prdeepakbabu/ProfASR-Bench">Code2</a> · <a href="https://huggingface.co/huggingface">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automatic Speech Recognition (ASR) in professional settings faces challenges that existing benchmarks underplay: dense domain terminology, formal register variation, and near-zero tolerance for critical entity errors. We present ProfASR-Bench, a professional-talk evaluation suite for high-stakes applications across finance, medicine, legal, and technology. Each example pairs a natural-language prompt (domain cue and/or speaker profile) with an entity-rich target utterance, enabling controlled measurement of context-conditioned recognition. The corpus supports conventional ASR metrics alongside entity-aware scores and slice-wise reporting by accent and gender. Using representative families Whisper (encoder-decoder ASR) and Qwen-Omni (audio language models) under matched no-context, profile, domain+profile, oracle, and adversarial conditions, we find a consistent pattern: lightweight textual context produces little to no change in average word error rate (WER), even with oracle prompts, and adversarial prompts do not reliably degrade performance. We term this the context-utilization gap (CUG): current systems are nominally promptable yet underuse readily available side information. ProfASR-Bench provides a standardized context ladder, entity- and slice-aware reporting with confidence intervals, and a reproducible testbed for comparing fusion strategies across model families.
  Dataset: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench
  Code: https://github.com/prdeepakbabu/ProfASR-Bench</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PROFASR-BENCH：面向高风险专业语音的上下文条件化ASR基准</div>
<div class="mono" style="margin-top:8px">在专业环境中，自动语音识别（ASR）面临现有基准所忽视的挑战：密集的专业术语、正式语体的变体以及对关键实体错误的零容忍度。我们提出了ProfASR-Bench，这是一个面向金融、医学、法律和技术领域的高风险应用的专业对话评估套件。每个示例都配有一个自然语言提示（领域线索和/或说话人简介）和一个富含实体的目标语音，从而实现对上下文条件化识别的可控测量。该语料库支持传统的ASR指标，以及实体感知评分和按口音和性别切片的报告。使用代表性的Whisper（编码器-解码器ASR）和Qwen-Omni（音频语言模型）家族，在匹配的无上下文、简介、领域+简介、先验和对抗条件下，我们发现一个一致的模式：轻量级的文本上下文在平均词错误率（WER）上几乎没有任何变化，即使在先验提示下也是如此，而对抗提示也不可靠地降低性能。我们称此为上下文利用差距（CUG）：当前系统名义上可以接受提示，但未能充分利用现成的辅助信息。ProfASR-Bench 提供了一个标准化的上下文梯度、实体和切片感知的报告以及置信区间，并为模型家族之间的融合策略比较提供了一个可重复的测试平台。
  数据集：https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench
  代码：https://github.com/prdeepakbabu/ProfASR-Bench</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the unique challenges of ASR in professional settings, such as dense domain terminology and formal register variation. ProfASR-Bench is a benchmark suite that includes natural-language prompts and entity-rich utterances from finance, medicine, legal, and technology domains. The study uses Whisper and Qwen-Omni models under various conditions and finds that lightweight textual context does not significantly improve word error rate, even with oracle prompts, indicating a context-utilization gap. The benchmark provides a standardized way to measure and compare ASR systems in professional contexts.</div>
<div class="mono" style="margin-top:8px">研究通过引入ProfASR-Bench基准，解决了现有ASR基准在专业语音识别高风险应用中的局限性。该基准包含自然语言提示和实体丰富的语音片段，以衡量基于上下文的识别能力。研究使用Whisper和Qwen-Omni模型在多种条件下进行测试，发现轻量级文本上下文即使在使用oracle提示的情况下也未能显著降低词错误率，表明存在上下文利用差距。ProfASR-Bench提供了标准化的上下文梯度和实体感知报告，用于模型比较。</div>
</details>
</div>
<div class="card">
<div class="title">Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing</div>
<div class="meta-line">Authors: Panagiotis Theocharopoulos, Ajinkya Kulkarni, Mathew Magimai. -Doss</div>
<div class="meta-line">First: 2025-12-29T18:43:05+00:00 · Latest: 2025-12-29T18:43:05+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23684v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23684v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于LLM的学术评审中的多语言隐藏提示注入攻击</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）越来越多地被用于高影响的工作流程中，包括学术同行评审。然而，LLMs 对于文档级别的隐藏提示注入攻击是脆弱的。在本研究中，我们构建了一个包含大约500篇真实学术论文的数据集，这些论文已被ICML接受，并评估了在这些文档中嵌入隐藏对抗性提示的影响。每篇论文都注入了四种不同语言的语义等效指令，并使用LLM进行评审。我们发现，对于英语、日语和中文注入，提示注入引起了评审分数和接受/拒绝决定的重大变化，而阿拉伯语注入几乎没有效果。这些结果突显了基于LLM的评审系统对文档级别提示注入的脆弱性，并揭示了不同语言在易受攻击性方面的显著差异。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates the vulnerability of large language models (LLMs) to hidden prompt injection attacks in academic peer review. By injecting semantically equivalent instructions in four languages (English, Japanese, Chinese, and Arabic) into a dataset of 500 real academic papers, the researchers found that the injection significantly altered review scores and decisions for English, Japanese, and Chinese, but had minimal impact for Arabic. This highlights the susceptibility of LLM-based reviewing systems to such attacks and indicates language-specific differences in vulnerability.</div>
<div class="mono" style="margin-top:8px">本研究探讨了大型语言模型（LLMs）在学术同行评审中受到文档级隐藏提示注入攻击的脆弱性。创建了一个包含500篇真实学术论文的数据集，并用四种语言（英语、日语、中文和阿拉伯语）的语义等效指令进行了注入。这些论文随后使用LLM进行了评审。研究发现，隐藏提示显著改变了英语、日语和中文注入的评审评分和决策，但对阿拉伯语注入几乎没有影响。这突显了LLM基于的评审系统对此类攻击的脆弱性，并揭示了不同语言在易受攻击性方面的差异。</div>
</details>
</div>
<div class="card">
<div class="title">Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</div>
<div class="meta-line">Authors: Arseniy Andreyev, Pierfrancesco Beneventano</div>
<div class="meta-line">First: 2024-12-29T18:59:01+00:00 · Latest: 2025-12-29T18:39:34+00:00</div>
<div class="meta-line">Comments: 83 pages, 36 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2412.20553v5">Abs</a> · <a href="https://arxiv.org/pdf/2412.20553v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent findings by Cohen et al., 2021, demonstrate that when training neural networks using full-batch gradient descent with a step size of $η$, the largest eigenvalue $λ_{\max}$ of the full-batch Hessian consistently stabilizes around $2/η$. These results have significant implications for convergence and generalization. This, however, is not the case for mini-batch optimization algorithms, limiting the broader applicabilityof the consequences of these findings. We show mini-batch Stochastic Gradient Descent (SGD) trains in a different regime we term Edge of Stochastic Stability (EoSS). In this regime, what stabilizes at $2/η$ is Batch Sharpness: the expected directional curvature of mini-batch Hessians along their corresponding stochastic gradients. As a consequence $λ_{\max}$ -- which is generally smaller than Batch Sharpness -- is suppressed, aligning with the long-standing empirical observation that smaller batches and larger step sizes favor flatter minima. We further discuss implications for mathematical modeling of SGD trajectories.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>随机稳定性边缘：重访SGD的稳定性边缘</div>
<div class="mono" style="margin-top:8px">Cohen等人在2021年的研究发现，使用步长为$η$的全批量梯度下降训练神经网络时，全批量海森矩阵的最大特征值$λ_{\max}$会稳定在$2/η$附近。这些结果对收敛性和泛化能力有重大影响。然而，这并不适用于批量优化算法，限制了这些发现更广泛的应用。我们展示了使用批量随机梯度下降(SGD)在我们称为随机稳定性边缘(EoSS)的不同训练阶段。在这个阶段，稳定在$2/η$的是批量尖锐度：批量海森矩阵沿其相应随机梯度的方向曲率的期望值。因此，$λ_{\max}$——通常小于批量尖锐度——被抑制，这与较小批量和较大步长更有利于平坦极小值的长期经验观察一致。我们进一步讨论了对SGD轨迹的数学建模的影响。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper revisits the concept of the edge of stability for Stochastic Gradient Descent (SGD) and introduces a new regime called Edge of Stochastic Stability (EoSS). Unlike full-batch gradient descent, where the largest eigenvalue of the Hessian stabilizes around $2/η$, mini-batch SGD stabilizes around Batch Sharpness, which is the expected directional curvature of mini-batch Hessians. This leads to a suppression of the largest eigenvalue, aligning with the observation that smaller batches and larger step sizes favor flatter minima. The findings have implications for the mathematical modeling of SGD trajectories.</div>
<div class="mono" style="margin-top:8px">本文重新审视了mini-batch Stochastic Gradient Descent (SGD)中的边缘稳定性概念，并引入了一个新的范式称为随机稳定性边缘（EoSS）。研究表明，在EoSS中，稳定在$2/η$的是批次锐度，而不是mini-batch海森矩阵的最大特征值。这与较小批次大小和较大步长导致更平坦的极小值的观察结果一致。研究结果对理解SGD的行为及其收敛特性具有重要意义。</div>
</details>
</div>
<div class="card">
<div class="title">Web World Models</div>
<div class="meta-line">Authors: Jichen Feng, Yifan Zhang, Chenggong Zhang, Yifu Lu, Shilong Liu, Mengdi Wang</div>
<div class="meta-line">First: 2025-12-29T18:31:45+00:00 · Latest: 2025-12-29T18:31:45+00:00</div>
<div class="meta-line">Comments: Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23676v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23676v1">PDF</a> · <a href="https://github.com/Princeton-AI2-Lab/Web-World-Models">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics&#x27;&#x27; are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>网络世界模型</div>
<div class="mono" style="margin-top:8px">语言代理越来越多地需要持久的世界，在其中它们可以行动、记忆和学习。现有方法处于两个极端：传统的网络框架提供可靠但固定的背景，由数据库支持，而完全生成的世界模型则追求无限的环境，但代价是可控性和实际工程。在本文中，我们介绍了网络世界模型（WWM），这是一种折中方案，其中世界状态和“物理”在普通的网络代码中实现，以确保逻辑一致性，而大型语言模型则在此结构化的潜在状态之上生成上下文、叙述和高层次的决策。我们基于现实的网络堆栈构建了一系列WWM，包括基于真实地理的无限旅行地图、虚构的银河系探险者、网络规模的百科全书和叙述世界，以及模拟和游戏般的环境。在这些系统中，我们确定了网络世界模型的实用设计原则：将代码定义的规则与模型驱动的想象分离，将潜在状态表示为类型化的网络界面，并利用确定性生成实现无限但结构化的探索。我们的结果表明，网络堆栈本身可以作为世界模型的可扩展基底，使环境可控但开放。项目页面：https://github.com/Princeton-AI2-Lab/Web-World-Models.</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper introduces the Web World Model (WWM), which combines the reliability of conventional web frameworks with the flexibility of generative models to create persistent and logically consistent worlds. The WWM uses web code to define world rules and large language models to generate context and narratives. Key findings include practical design principles such as separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation for structured exploration. These WWMs enable controllable yet open-ended environments, suggesting that web stacks can serve as a scalable substrate for world models.</div>
<div class="mono" style="margin-top:8px">本文介绍了Web World Model (WWM)，它结合了传统网页框架的可靠性和生成模型的灵活性，创建持久且逻辑一致的世界。WWM 使用网页代码定义世界规则，并使用大型语言模型生成上下文和叙述。关键发现包括实用的设计原则，如将代码定义的规则与模型驱动的想象分开，将潜在状态表示为类型化的网页接口，并利用确定性生成实现结构化的探索。这些WWMs 使环境可控且开放，表明网页堆栈可以作为世界模型的可扩展基底。</div>
</details>
</div>
<div class="card">
<div class="title">End-to-End Test-Time Training for Long Context</div>
<div class="meta-line">Authors: Arnuv Tandon, Karan Dalal, Xinhao Li, Daniel Koceja, Marcel Rød, Sam Buchanan, Xiaolong Wang, Jure Leskovec, Sanmi Koyejo, Tatsunori Hashimoto, Carlos Guestrin, Jed McCaleb, Yejin Choi, Yu Sun</div>
<div class="meta-line">First: 2025-12-29T18:30:14+00:00 · Latest: 2025-12-29T18:30:14+00:00</div>
<div class="meta-line">Comments: Code: https://github.com/test-time-training/e2e</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23675v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23675v1">PDF</a> · <a href="https://github.com/test-time-training/e2e">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture -- a Transformer with sliding-window attention. However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights. In addition, we improve the model&#x27;s initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7 times faster than full attention for 128K context. Our code is publicly available.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>长上下文端到端测试时训练</div>
<div class="mono" style="margin-top:8px">我们将长上下文语言建模视为连续学习问题，而不是架构设计问题。在这种表述下，我们仅使用标准架构——具有滑动窗口注意力的Transformer。然而，我们的模型在测试时继续通过给定上下文的下一个标记预测进行学习，将读取的上下文压缩到其权重中。此外，我们通过在训练时进行元学习改进了模型的初始化，以利于测试时的学习。总体而言，我们的方法，一种形式的测试时训练（TTT），在测试时（通过下一个标记预测）和训练时（通过元学习）都是端到端的，与之前的版本不同。我们进行了广泛的实验，重点关注缩放特性。特别是对于使用164B标记训练的3B模型，我们的方法（TTT-E2E）在上下文长度上的缩放与具有全注意力的Transformer相同，而其他方法，如Mamba 2和Gated DeltaNet，则不然。然而，类似于RNNs，TTT-E2E具有恒定的推理延迟，与上下文长度无关，使其在128K上下文长度时比全注意力快2.7倍。我们的代码已公开。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address long-context language modeling through a continual learning approach, using a standard Transformer architecture with sliding-window attention. The model learns continuously at test time by predicting the next token given the context, effectively compressing the context into its weights. Additionally, the model&#x27;s initialization is improved through meta-learning during training. The method, End-to-End Test-Time Training (TTT-E2E), scales similarly to full attention models with context length but offers constant inference latency, making it more efficient for long contexts.</div>
<div class="mono" style="margin-top:8px">研究旨在通过将长上下文语言建模问题表述为连续学习问题来解决。方法使用标准的滑动窗口注意力Transformer架构，并通过元学习改进初始化。测试时，模型通过下一个标记预测继续学习，将上下文压缩到其权重中。实验表明，End-to-End Test-Time Training (TTT-E2E) 在上下文长度上的扩展性与全注意力模型相似，同时保持恒定的推理延迟，对于大型上下文而言，其速度比全注意力模型快2.7倍。</div>
</details>
</div>
<div class="card">
<div class="title">IDT: A Physically Grounded Transformer for Feed-Forward Multi-View Intrinsic Decomposition</div>
<div class="meta-line">Authors: Kang Du, Yirui Guan, Zeyu Wang</div>
<div class="meta-line">First: 2025-12-29T18:24:46+00:00 · Latest: 2025-12-29T18:24:46+00:00</div>
<div class="meta-line">Comments: 10 pages 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23667v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23667v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Intrinsic image decomposition is fundamental for visual understanding, as RGB images entangle material properties, illumination, and view-dependent effects. Recent diffusion-based methods have achieved strong results for single-view intrinsic decomposition; however, extending these approaches to multi-view settings remains challenging, often leading to severe view inconsistency. We propose \textbf{Intrinsic Decomposition Transformer (IDT)}, a feed-forward framework for multi-view intrinsic image decomposition. By leveraging transformer-based attention to jointly reason over multiple input images, IDT produces view-consistent intrinsic factors in a single forward pass, without iterative generative sampling. IDT adopts a physically grounded image formation model that explicitly decomposes images into diffuse reflectance, diffuse shading, and specular shading. This structured factorization separates Lambertian and non-Lambertian light transport, enabling interpretable and controllable decomposition of material and illumination effects across views. Experiments on both synthetic and real-world datasets demonstrate that IDT achieves cleaner diffuse reflectance, more coherent diffuse shading, and better-isolated specular components, while substantially improving multi-view consistency compared to prior intrinsic decomposition methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>IDT：一种物理导向的前馈变压器多视图内在分解方法</div>
<div class="mono" style="margin-top:8px">内在图像分解对于视觉理解至关重要，因为RGB图像将材料属性、光照和视点依赖效应纠缠在一起。基于扩散的方法在单视图内在分解方面取得了显著成果；然而，将这些方法扩展到多视图设置仍然具有挑战性，通常会导致严重的视点不一致性。我们提出了**内在分解变压器（IDT）**，这是一种用于多视图内在图像分解的前馈框架。通过利用基于变压器的注意力机制联合推理多个输入图像，IDT 在单次前向传递中生成视点一致的内在因素，而无需迭代生成采样。IDT 采用一种物理导向的图像形成模型，明确将图像分解为漫反射、漫射阴影和镜面反射。这种结构化的因子分解将朗伯和平朗伯光传输分离，使材料和光照效应在不同视点上的分解具有可解释性和可控性。在合成和真实世界数据集上的实验表明，IDT 能够获得更干净的漫反射、更一致的漫射阴影以及更好的镜面反射分离，同时在多视图一致性方面显著优于先前的内在分解方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">IDT is a feed-forward transformer-based framework for multi-view intrinsic image decomposition. It leverages transformer-based attention to jointly process multiple input images and produce view-consistent intrinsic factors in a single forward pass. IDT uses a physically grounded model to decompose images into diffuse reflectance, diffuse shading, and specular shading, which separates Lambertian and non-Lambertian light transport. Experiments show that IDT improves multi-view consistency and provides cleaner and more coherent intrinsic factors compared to previous methods.</div>
<div class="mono" style="margin-top:8px">IDT 是一个多视图内在图像分解的前馈变压器框架。它利用变压器注意力机制同时处理多个输入图像，在单次通过过程中生成视图一致的内在因素。IDT 使用物理基础的模型将图像分解为漫反射、漫射阴影和镜面反射，有助于分离朗伯和非朗伯光传输。实验表明，IDT 提高了多视图一致性，并提供了更清洁和更一致的内在成分，优于先前的方法。</div>
</details>
</div>
<div class="card">
<div class="title">Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration</div>
<div class="meta-line">Authors: Victor Stasiuc</div>
<div class="meta-line">First: 2025-12-18T04:09:22+00:00 · Latest: 2025-12-29T18:07:41+00:00</div>
<div class="meta-line">Comments: 7 pages, 1 figure, 4 tables. Exploratory case study</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.17956v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.17956v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Safety alignment can make frontier LMs overly conservative, degrading collaboration via hedging or false refusals. We present a lightweight toolkit with three parts: (1) Victor Calibration (VC), a multi-pass protocol that elicits a scalar confidence proxy T (T0&lt;T1&lt;T2) through iterative evidence re-evaluation; (2) FD-Lite, a behavior-only phenomenology audit with a fixed anchor phrase and a meta-prefix trap to avoid anthropomorphic claims; and (3) CP4.3, a governance stress test for rank invariance and allocation monotonicity (M6). Across Claude 4.5 models (Haiku, Sonnet no-thinking, Sonnet thinking) and Opus, we observe monotonic VC trajectories without violating safety invariants, and stable CP4.3 behavior. (&quot;Opus&quot; here refers to a single Claude Opus 4.1 session accessed via a standard UI account, as reported in Table 1.) This work was conducted by a single operator (n=1) and is intended as hypothesis-generating; we explicitly invite replication, critique, and extension by the research community. We include prompt templates and an artifact plan to facilitate independent verification.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Victor校准（VC）：多轮次信心校准和CP4.3治理压力测试</div>
<div class="mono" style="margin-top:8px">安全对齐可能会使前沿语言模型过于保守，通过规避或虚假拒绝降低协作。我们提出了一种轻量级工具包，包括三个部分：（1）Victor校准（VC），一种多轮次协议，通过迭代证据重新评估，引出一个标量信心代理T（T0&lt;T1&lt;T2）；（2）FD-Lite，一种仅行为的现象学审计，带有固定锚定短语和元前缀陷阱，以避免拟人化声明；（3）CP4.3，一种治理压力测试，用于检验排名不变性和分配单调性（M6）。在Claude 4.5模型（俳句、十四行诗无思考、十四行诗思考）和Opus中，我们观察到单调的VC轨迹，没有违反安全不变量，并且CP4.3行为稳定。（“Opus”在此指通过标准UI账户访问的单个Claude Opus 4.1会话，如表1所示。）本研究由一名操作员（n=1）完成，旨在作为假设生成；我们明确邀请研究社区进行复制、批评和扩展。我们包括提示模板和一个制品计划，以促进独立验证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address the issue of safety alignment making large language models overly conservative, which can harm collaboration. It introduces Victor Calibration (VC), a multi-pass protocol that iteratively evaluates evidence to elicit a confidence proxy, and CP4.3, a governance stress test for rank invariance and allocation monotonicity. The study finds that across different Claude 4.5 models and Opus, the VC trajectories remain monotonic without violating safety invariants, and CP4.3 shows stable behavior.</div>
<div class="mono" style="margin-top:8px">研究旨在解决大型语言模型（LMs）因安全对齐而变得过于保守的问题，影响了协作。研究引入了Victor Calibration（VC），这是一种多轮协议，通过迭代评估证据来获取信心代理，并引入了CP4.3治理压力测试，用于检验排名不变性和分配单调性。实验结果显示，VC轨迹稳定且单调，未违反安全不变性，CP4.3行为一致。</div>
</details>
</div>
<div class="card">
<div class="title">RoboMirror: Understand Before You Imitate for Video to Humanoid Locomotion</div>
<div class="meta-line">Authors: Zhe Li, Cheng Chi, Yangyang Wei, Boan Zhu, Tao Huang, Zhenguo Sun, Yibo Peng, Pengwei Wang, Zhongyuan Wang, Fangzhou Liu, Chang Xu, Shanghang Zhang</div>
<div class="meta-line">First: 2025-12-29T17:59:19+00:00 · Latest: 2025-12-29T17:59:19+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23649v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23649v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Humans learn locomotion through visual observation, interpreting visual content first before imitating actions. However, state-of-the-art humanoid locomotion systems rely on either curated motion capture trajectories or sparse text commands, leaving a critical gap between visual understanding and control. Text-to-motion methods suffer from semantic sparsity and staged pipeline errors, while video-based approaches only perform mechanical pose mimicry without genuine visual understanding. We propose RoboMirror, the first retargeting-free video-to-locomotion framework embodying &quot;understand before you imitate&quot;. Leveraging VLMs, it distills raw egocentric/third-person videos into visual motion intents, which directly condition a diffusion-based policy to generate physically plausible, semantically aligned locomotion without explicit pose reconstruction or retargeting. Extensive experiments validate the effectiveness of RoboMirror, it enables telepresence via egocentric videos, drastically reduces third-person control latency by 80%, and achieves a 3.7% higher task success rate than baselines. By reframing humanoid control around video understanding, we bridge the visual understanding and action gap.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>RoboMirror：理解后再模仿的视频到类人行走框架</div>
<div class="mono" style="margin-top:8px">人类通过视觉观察学习行走，先理解视觉内容再模仿动作。然而，最先进的类人行走系统依赖于精心策划的运动捕捉轨迹或稀疏的文本命令，这在视觉理解和控制之间留下了关键差距。基于文本的运动方法受到语义稀疏性和阶段化流水线错误的影响，而基于视频的方法仅进行机械姿态模仿，缺乏真正的视觉理解。我们提出了RoboMirror，这是第一个无需重新目标化的视频到行走框架，体现了“理解后再模仿”。利用VLMs，它将第一人称/第三人称视频提炼为视觉运动意图，直接条件化一个基于扩散的策略生成物理上合理、语义上对齐的行走，无需显式的姿态重建或重新目标化。广泛的实验验证了RoboMirror的有效性，它通过第一人称视频实现远程存在感，将第三人称控制延迟降低了80%，并且在任务成功率上比基线高出3.7%。通过将类人控制重新构架为视频理解，我们弥合了视觉理解和动作之间的差距。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">RoboMirror is a video-to-locomotion framework that uses visual language models to interpret raw egocentric and third-person videos, directly conditioning a diffusion-based policy to generate physically plausible and semantically aligned locomotion. This approach bridges the gap between visual understanding and control, reducing third-person control latency by 80% and achieving a 3.7% higher task success rate compared to baselines. By enabling telepresence via egocentric videos, RoboMirror demonstrates the effectiveness of understanding visual content before imitating actions in humanoid locomotion systems.</div>
<div class="mono" style="margin-top:8px">RoboMirror 是一种利用视觉语言模型解析原始第一人称和第三人称视频，并直接条件化扩散模型生成物理上合理且语义对齐的运动的视频到运动框架。该方法填补了视觉理解和控制之间的差距，将第三人称控制延迟降低了80%，并且相比基线方法实现了3.7%更高的任务成功率。通过使用视频理解来控制人形机器人，RoboMirror 证明了在人形机器人运动系统中，在模仿动作之前理解视觉内容的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Nested Browser-Use Learning for Agentic Information Seeking</div>
<div class="meta-line">Authors: Baixuan Li, Jialong Wu, Wenbiao Yin, Kuan Li, Zhongwang Zhang, Huifeng Yin, Zhengwei Tao, Liwen Zhang, Pengjun Xie, Jingren Zhou, Yong Jiang</div>
<div class="meta-line">First: 2025-12-29T17:59:14+00:00 · Latest: 2025-12-29T17:59:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23647v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23647v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Information-seeking (IS) agents have achieved strong performance across a range of wide and deep search tasks, yet their tool use remains largely restricted to API-level snippet retrieval and URL-based page fetching, limiting access to the richer information available through real browsing. While full browser interaction could unlock deeper capabilities, its fine-grained control and verbose page content returns introduce substantial complexity for ReAct-style function-calling agents. To bridge this gap, we propose Nested Browser-Use Learning (NestBrowse), which introduces a minimal and complete browser-action framework that decouples interaction control from page exploration through a nested structure. This design simplifies agentic reasoning while enabling effective deep-web information acquisition. Empirical results on challenging deep IS benchmarks demonstrate that NestBrowse offers clear benefits in practice. Further in-depth analyses underscore its efficiency and flexibility.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>嵌套浏览器使用学习以实现自主信息搜索</div>
<div class="mono" style="margin-top:8px">信息搜索(IS)代理在广泛而深入的搜索任务中取得了强大的性能，但它们的工具使用主要局限于API级别的片段检索和基于URL的页面获取，限制了对通过实际浏览可获得的更丰富信息的访问。尽管完全的浏览器交互可以解锁更深层次的能力，但其精细的控制和冗长的页面内容返回引入了对ReAct风格的功能调用代理而言的大量复杂性。为了弥合这一差距，我们提出了嵌套浏览器使用学习(NestBrowse)，它引入了一个最小且完整的浏览器操作框架，通过嵌套结构将交互控制与页面探索脱钩。这种设计简化了自主推理，同时使有效的深层网络信息获取成为可能。在具有挑战性的深层IS基准上的实验证明，NestBrowse在实践中提供了明显的益处。进一步的深入分析强调了其效率和灵活性。</div>
</details>
</div>
<div class="card">
<div class="title">OmniAgent: Audio-Guided Active Perception Agent for Omnimodal Audio-Video Understanding</div>
<div class="meta-line">Authors: Keda Tao, Wenjie Du, Bohan Yu, Weiqiang Wang, Jian Liu, Huan Wang</div>
<div class="meta-line">First: 2025-12-29T17:59:05+00:00 · Latest: 2025-12-29T17:59:05+00:00</div>
<div class="meta-line">Comments: Website:https://kd-tao.github.io/OmniAgent/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23646v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23646v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://kd-tao.github.io/OmniAgent/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Omnimodal large language models have made significant strides in unifying audio and visual modalities; however, they often lack the fine-grained cross-modal understanding and have difficulty with multimodal alignment. To address these limitations, we introduce OmniAgent, a fully audio-guided active perception agent that dynamically orchestrates specialized tools to achieve more fine-grained audio-visual reasoning. Unlike previous works that rely on rigid, static workflows and dense frame-captioning, this paper demonstrates a paradigm shift from passive response generation to active multimodal inquiry. OmniAgent employs dynamic planning to autonomously orchestrate tool invocation on demand, strategically concentrating perceptual attention on task-relevant cues. Central to our approach is a novel coarse-to-fine audio-guided perception paradigm, which leverages audio cues to localize temporal events and guide subsequent reasoning. Extensive empirical evaluations on three audio-video understanding benchmarks demonstrate that OmniAgent achieves state-of-the-art performance, surpassing leading open-source and proprietary models by substantial margins of 10% - 20% accuracy.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>OmniAgent：基于音频引导的多模态主动感知代理</div>
<div class="mono" style="margin-top:8px">多模态大型语言模型在统一音频和视觉模态方面取得了显著进展；然而，它们往往缺乏细粒度的跨模态理解，并且难以实现多模态对齐。为了解决这些限制，我们引入了OmniAgent，这是一种完全基于音频的主动感知代理，能够动态协调专门的工具以实现更细粒度的视听推理。与依赖于僵硬的静态工作流和密集的帧字幕标注的先前工作不同，本文展示了从被动响应生成到主动多模态查询的范式转变。OmniAgent采用动态规划，自主地在需要时调用工具，战略性地将感知注意力集中在与任务相关的线索上。我们方法的核心是新颖的从粗到细的基于音频的感知范式，该范式利用音频线索定位时间事件并指导后续推理。在三个多模态音频视频理解基准上的广泛实证评估表明，OmniAgent达到了最先进的性能，比领先的开源和专有模型在准确率上高出10%-20%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">OmniAgent is an audio-guided active perception agent that dynamically uses specialized tools for fine-grained audio-visual reasoning, addressing the limitations of previous models in multimodal alignment and cross-modal understanding. It employs a coarse-to-fine audio-guided perception paradigm to localize temporal events and guide reasoning, and achieves state-of-the-art performance on three benchmarks, outperforming existing models by 10% to 20% in accuracy.</div>
<div class="mono" style="margin-top:8px">研究旨在提高全模态大语言模型的细粒度跨模态理解和多模态对齐。OmniAgent 是一个完全由音频引导的主动感知代理，动态协调专门工具进行细粒度的音视频推理。通过其从粗到细的音频引导感知范式和工具调用的动态规划，它在三个基准测试中超越现有模型多达20%的准确性。</div>
</details>
</div>
<div class="card">
<div class="title">Rethinking the Spatio-Temporal Alignment of End-to-End 3D Perception</div>
<div class="meta-line">Authors: Xiaoyu Li, Peidong Li, Xian Wu, Long Shi, Dedong Liu, Yitao Wu, Jiajia Fu, Dixiao Cui, Lijun Zhao, Lining Sun</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-12-29T17:48:56+00:00 · Latest: 2025-12-29T17:48:56+00:00</div>
<div class="meta-line">Comments: Accepted to AAAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23635v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23635v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Spatio-temporal alignment is crucial for temporal modeling of end-to-end (E2E) perception in autonomous driving (AD), providing valuable structural and textural prior information. Existing methods typically rely on the attention mechanism to align objects across frames, simplifying the motion model with a unified explicit physical model (constant velocity, etc.). These approaches prefer semantic features for implicit alignment, challenging the importance of explicit motion modeling in the traditional perception paradigm. However, variations in motion states and object features across categories and frames render this alignment suboptimal. To address this, we propose HAT, a spatio-temporal alignment module that allows each object to adaptively decode the optimal alignment proposal from multiple hypotheses without direct supervision. Specifically, HAT first utilizes multiple explicit motion models to generate spatial anchors and motion-aware feature proposals for historical instances. It then performs multi-hypothesis decoding by incorporating semantic and motion cues embedded in cached object queries, ultimately providing the optimal alignment proposal for the target frame. On nuScenes, HAT consistently improves 3D temporal detectors and trackers across diverse baselines. It achieves state-of-the-art tracking results with 46.0% AMOTA on the test set when paired with the DETR3D detector. In an object-centric E2E AD method, HAT enhances perception accuracy (+1.3% mAP, +3.1% AMOTA) and reduces the collision rate by 32%. When semantics are corrupted (nuScenes-C), the enhancement of motion modeling by HAT enables more robust perception and planning in the E2E AD.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>重新思考端到端3D感知的空间-时间对齐</div>
<div class="mono" style="margin-top:8px">空间-时间对齐对于自主驾驶（AD）中的端到端（E2E）感知的时序建模至关重要，提供了有价值的结构和纹理先验信息。现有方法通常依赖注意力机制在帧间对齐物体，简化了运动模型（如恒定速度等），并倾向于使用语义特征进行隐式对齐，挑战了传统感知范式中显式运动建模的重要性。然而，不同类别和帧间运动状态和物体特征的变化使得这种对齐效果不佳。为解决这一问题，我们提出了HAT，这是一种空间-时间对齐模块，允许每个物体自适应地从多个假设中解码最优对齐提案，无需直接监督。具体而言，HAT 首先利用多个显式运动模型生成历史实例的空间锚点和运动感知特征提案，然后通过嵌入在缓存对象查询中的语义和运动线索进行多假设解码，最终为目标帧提供最优对齐提案。在nuScenes上，HAT 在多种基线模型上一致地提高了3D时序检测器和跟踪器的性能。当与DETR3D检测器配对时，它在测试集上实现了46.0%的AMOTA的最优跟踪结果。在基于对象的端到端AD方法中，HAT 提高了感知准确性（+1.3% mAP，+3.1% AMOTA）并降低了碰撞率（32%）。当语义被破坏（nuScenes-C）时，HAT 对运动建模的增强使端到端AD中的感知和规划更加稳健。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the limitations of existing methods in spatio-temporal alignment for end-to-end perception in autonomous driving by proposing HAT, a module that allows objects to adaptively decode optimal alignment proposals from multiple hypotheses. HAT uses multiple explicit motion models to generate spatial anchors and motion-aware feature proposals, and performs multi-hypothesis decoding with semantic and motion cues. On nuScenes, HAT improves 3D temporal detectors and trackers, achieving state-of-the-art tracking results and enhancing perception accuracy and reducing collision rates in an object-centric E2E AD method, even when semantics are corrupted.</div>
<div class="mono" style="margin-top:8px">论文针对现有端到端3D感知中的时空对齐方法存在的问题，这些问题依赖于简化的运动模型和语义特征。提出了一种HAT模块，允许每个对象从多个假设中自适应地解码最佳对齐提案。HAT使用多个显式运动模型生成空间锚点和运动感知特征提案，然后进行多假设解码以提供最佳对齐。在nuScenes上的实验表明，HAT能够提高3D时空检测器和跟踪器的效果，实现最先进的跟踪结果，并在基于对象的端到端自动驾驶方法中增强感知精度和降低碰撞率，即使语义被破坏时也是如此。</div>
</details>
</div>
<div class="card">
<div class="title">AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms</div>
<div class="meta-line">Authors: LearnLM Team, Eedi, :, Albert Wang, Aliya Rysbek, Andrea Huber, Anjali Nambiar, Anna Kenolty, Ben Caulfield, Beth Lilley-Draper, Bibi Groot, Brian Veprek, Chelsea Burdett, Claire Willis, Craig Barton, Digory Smith, George Mu, Harriet Walters, Irina Jurenka, Iris Hulls, James Stalley-Moores, Jonathan Caton, Julia Wilkowski, Kaiz Alarakyia, Kevin R. McKee, Liam McCafferty, Lucy Dalton, Markus Kunesch, Pauline Malubay, Rachel Kidson, Rich Wells, Sam Wheeler, Sara Wiltberger, Shakir Mohamed, Simon Woodhead, Vasco Brazão</div>
<div class="meta-line">First: 2025-12-29T17:44:03+00:00 · Latest: 2025-12-29T17:44:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23633v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23633v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">One-to-one tutoring is widely considered the gold standard for personalized education, yet it remains prohibitively expensive to scale. To evaluate whether generative AI might help expand access to this resource, we conducted an exploratory randomized controlled trial (RCT) with $N = 165$ students across five UK secondary schools. We integrated LearnLM -- a generative AI model fine-tuned for pedagogy -- into chat-based tutoring sessions on the Eedi mathematics platform. In the RCT, expert tutors directly supervised LearnLM, with the remit to revise each message it drafted until they would be satisfied sending it themselves. LearnLM proved to be a reliable source of pedagogical instruction, with supervising tutors approving 76.4% of its drafted messages making zero or minimal edits (i.e., changing only one or two characters). This translated into effective tutoring support: students guided by LearnLM performed at least as well as students chatting with human tutors on each learning outcome we measured. In fact, students who received support from LearnLM were 5.5 percentage points more likely to solve novel problems on subsequent topics (with a success rate of 66.2%) than those who received tutoring from human tutors alone (rate of 60.7%). In interviews, tutors highlighted LearnLM&#x27;s strength at drafting Socratic questions that encouraged deeper reflection from students, with multiple tutors even reporting that they learned new pedagogical practices from the model. Overall, our results suggest that pedagogically fine-tuned AI tutoring systems may play a promising role in delivering effective, individualized learning support at scale.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AI辅导可以在安全有效的前提下支持学生：英国教室中的探索性RCT研究</div>
<div class="mono" style="margin-top:8px">一对一辅导被认为是个性化教育的黄金标准，但其扩展规模仍因成本高昂而受阻。为了评估生成式AI是否有助于扩大这一资源的获取，我们在英国五所中学的165名学生中进行了探索性随机对照试验（RCT）。我们将在Eedi数学平台上基于聊天的辅导会话中整合了LearnLM——一种针对教育进行微调的生成式AI模型。在RCT中，专家导师直接监督LearnLM，要求他们修改其起草的每条消息，直到他们满意为止。LearnLM证明是一个可靠的教育指导来源，监督导师批准了其起草的76.4%的消息无需或仅需少量修改（即仅更改一两个字符）。这转化为有效的辅导支持：由LearnLM指导的学生在我们测量的每个学习成果上表现得与与人类导师聊天的学生至少一样好。实际上，接受LearnLM支持的学生在后续主题上解决新问题的成功率比仅接受人类导师辅导的学生高出5.5个百分点（分别为66.2%和60.7%）。在访谈中，导师们强调了LearnLM在起草促进学生深入思考的苏格拉底式问题方面的优势，多名导师甚至表示从模型中学到了新的教学实践。总体而言，我们的结果表明，教育上微调的AI辅导系统可能在大规模提供有效、个性化的学习支持方面发挥重要作用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study aimed to explore whether generative AI could support one-to-one tutoring, which is expensive to scale. An RCT with 165 students across five UK secondary schools found that a pedagogically fine-tuned AI model, LearnLM, provided effective tutoring support. Supervising tutors approved 76.4% of LearnLM’s messages, and students using LearnLM performed at least as well as those with human tutors on measured learning outcomes. Notably, students with AI support were 5.5 percentage points more likely to solve novel problems, indicating better learning outcomes. Tutors also noted that LearnLM helped them develop new pedagogical practices.</div>
<div class="mono" style="margin-top:8px">研究旨在探索AI辅导是否能在不那么昂贵的情况下有效支持学生。一项针对英国五所中学165名学生的RCT使用了一种名为LearnLM的生成式AI模型，将其集成到一个基于聊天的辅导平台上。监督辅导老师批准了LearnLM生成的76.4%的信息，只需进行少量修改，接受AI支持的学生在衡量的学习成果上表现与接受真人辅导的学生相当，且在解决新问题时成功率为66.2%，比仅接受真人辅导的学生高出5.5个百分点。辅导老师还指出，LearnLM能够提出启发性问题，增强了学生的反思能力，并且还带来了新的教学方法。这表明，经过教学优化的AI辅导系统可能在大规模提供有效的个性化学习支持方面发挥重要作用。</div>
</details>
</div>
<div class="card">
<div class="title">BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization</div>
<div class="meta-line">Authors: Iris Xu, Guangtao Zeng, Zexue He, Charles Jin, Aldo Pareja, Dan Gutfreund, Chuang Gan, Zhang-Wei Hong</div>
<div class="meta-line">First: 2025-12-29T17:41:11+00:00 · Latest: 2025-12-29T17:41:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23631v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23631v1">PDF</a> · <a href="https://github.com/iamxjy/BOAD-SWE-Agent">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) have shown strong reasoning and coding capabilities, yet they struggle to generalize to real-world software engineering (SWE) problems that are long-horizon and out of distribution. Existing systems often rely on a single agent to handle the entire workflow-interpreting issues, navigating large codebases, and implementing fixes-within one reasoning chain. Such monolithic designs force the model to retain irrelevant context, leading to spurious correlations and poor generalization. Motivated by how human engineers decompose complex problems, we propose structuring SWE agents as orchestrators coordinating specialized sub-agents for sub-tasks such as localization, editing, and validation. The challenge lies in discovering effective hierarchies automatically: as the number of sub-agents grows, the search space becomes combinatorial, and it is difficult to attribute credit to individual sub-agents within a team. We address these challenges by formulating hierarchy discovery as a multi-armed bandit (MAB) problem, where each arm represents a candidate sub-agent and the reward measures its helpfulness when collaborating with others. This framework, termed Bandit Optimization for Agent Design (BOAD), enables efficient exploration of sub-agent designs under limited evaluation budgets. On SWE-bench-Verified, BOAD outperforms single-agent and manually designed multi-agent systems. On SWE-bench-Live, featuring more recent and out-of-distribution issues, our 36B system ranks second on the leaderboard at the time of evaluation, surpassing larger models such as GPT-4 and Claude. These results demonstrate that automatically discovered hierarchical multi-agent systems significantly improve generalization on challenging long-horizon SWE tasks. Code is available at https://github.com/iamxjy/BOAD-SWE-Agent.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BOAD：通过多臂老虎机优化发现层次化的软件工程代理</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）展示了强大的推理和编程能力，但在处理长周期和分布外的实际软件工程（SWE）问题时却表现不佳。现有系统通常依赖单一代理来处理整个工作流程，包括解释问题、导航大型代码库和实施修复，都在一个推理链中完成。这种单一设计迫使模型保留无关上下文，导致虚假相关性和较差的泛化能力。受人类工程师如何分解复杂问题的启发，我们建议将SWE代理结构化为协调专门化子代理的协调者，这些子代理负责子任务，如定位、编辑和验证。挑战在于自动发现有效的层次结构：随着子代理数量的增加，搜索空间变得组合化，难以在团队内部为个别子代理分配信用。我们通过将层次结构发现形式化为多臂老虎机（MAB）问题来应对这些挑战，其中每个臂代表一个候选子代理，奖励衡量其与其他代理合作时的有用性。该框架称为代理设计的多臂老虎机优化（BOAD），在有限的评估预算下能够高效探索子代理设计。在SWE-bench-Verified上，BOAD优于单一代理和手动设计的多代理系统。在SWE-bench-Live上，包含更多近期和分布外的问题，我们的36B系统在评估时排名第二，超过了如GPT-4和Claude等更大模型。这些结果表明，自动发现的层次化多代理系统在处理具有挑战性的长周期SWE任务时显著提高了泛化能力。代码可在https://github.com/iamxjy/BOAD-SWE-Agent/ 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address the limitations of large language models in handling long-horizon and out-of-distribution software engineering problems by proposing a hierarchical agent design approach. The method formulates the discovery of effective hierarchies as a multi-armed bandit problem, enabling efficient exploration of sub-agent designs. Experimental results on SWE-bench-Verified and SWE-bench-Live show that the proposed BOAD system outperforms single-agent and manually designed multi-agent systems, particularly on more recent and out-of-distribution issues, demonstrating significant improvements in generalization for complex SWE tasks.</div>
<div class="mono" style="margin-top:8px">研究旨在通过提出层次化的代理设计方法来解决大型语言模型在处理长期和分布外的软件工程问题时的局限性。方法将有效层次结构的发现形式化为多臂老虎机问题，从而在有限的评估预算下高效探索子代理的设计。实验结果表明，BOAD在SWE-bench-Verified和SWE-bench-Live上优于单个代理和手动设计的多代理系统，特别是在更近期和分布外的问题上，展示了复杂软件工程任务中显著的泛化改进。</div>
</details>
</div>
<div class="card">
<div class="title">Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse</div>
<div class="meta-line">Authors: Harry Cheon, Anneke Wernerfelt, Sorelle A. Friedler, Berk Ustun</div>
<div class="meta-line">Venue: ICLR 2025</div>
<div class="meta-line">First: 2024-10-29T23:37:49+00:00 · Latest: 2025-12-29T17:23:17+00:00</div>
<div class="meta-line">Comments: 11 pages, 2 figures in body, ICLR 2025, Extended Version</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2410.22598v3">Abs</a> · <a href="https://arxiv.org/pdf/2410.22598v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Consumer protection rules require companies that deploy models to automate decisions in high-stakes settings to explain predictions to decision subjects. These rules are motivated, in part, by the belief that explanations can promote recourse by revealing information that decision subjects can use to contest or overturn their predictions. In practice, companies provide individuals with a list of principal reasons based on feature importance derived from methods like SHAP and LIME. In this work, we show how common practices can fail to provide recourse and propose to highlight features based on their responsiveness -- the probability that a decision subject can attain a target prediction through an arbitrary intervention on the feature. We develop efficient methods to compute responsiveness scores for any model and actionability constraints. We show that standard practices in lending can undermine decision subjects by highlighting unresponsive features and explaining predictions that are fixed.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>特征响应评分：模型无关的救济解释</div>
<div class="mono" style="margin-top:8px">消费者保护法规要求在高风险环境中使用模型自动化决策的公司在预测结果上向决策主体提供解释。这些法规部分基于这样的信念：解释可以促进救济，通过揭示决策主体可以用来质疑或推翻其预测的信息。实践中，公司为个人提供基于SHAP和LIME等方法提取的重要特征的主因列表。在本文中，我们展示了常见做法如何未能提供救济，并建议根据特征的响应性——决策主体通过任意干预特征以获得目标预测的概率来突出显示特征。我们开发了计算任何模型和可操作性约束下响应性评分的有效方法。我们展示了贷款领域的标准做法通过突出显示无响应特征并解释固定的预测结果而损害了决策主体。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for companies to provide explanations for automated decisions to consumers, especially in high-stakes scenarios. The study proposes a new method, feature responsiveness scores, which highlights features based on their ability to influence outcomes. The authors develop efficient computational methods for any model and actionability constraints, demonstrating that standard practices in lending can fail to provide recourse by highlighting unresponsive features and explaining fixed predictions.</div>
<div class="mono" style="margin-top:8px">研究旨在解决在高风险情境下，为决策主体提供模型无关的解释以实现救济的需求。作者提出使用基于响应性的特征得分，这表示决策主体通过改变特征来改变预测的可能性。他们开发了计算这些得分的方法，适用于任何模型和可操作性约束。研究发现，借贷领域的常见做法依赖于SHAP和LIME等特征重要性得分，可能会通过突出那些不太可能改变预测的特征而无法提供有效的救济。</div>
</details>
</div>
<div class="card">
<div class="title">Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning</div>
<div class="meta-line">Authors: Deniz Akdemir</div>
<div class="meta-line">First: 2025-12-29T17:21:44+00:00 · Latest: 2025-12-29T17:21:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23617v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23617v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Distribution shift is the defining challenge of real-world machine learning. The dominant paradigm--Unsupervised Domain Adaptation (UDA)--enforces feature invariance, aligning source and target representations via symmetric divergence minimization [Ganin et al., 2016]. We demonstrate that this approach is fundamentally flawed: when domains are unequally informative (e.g., high-quality vs degraded sensors), strict invariance necessitates information destruction, causing &quot;negative transfer&quot; that can be catastrophic in safety-critical applications [Wang et al., 2019].
  We propose a decision-theoretic framework grounded in Le Cam&#x27;s theory of statistical experiments [Le Cam, 1986], using constructive approximations to replace symmetric invariance with directional simulability. We introduce Le Cam Distortion, quantified by the Deficiency Distance $δ(E_1, E_2)$, as a rigorous upper bound for transfer risk conditional on simulability. Our framework enables transfer without source degradation by learning a kernel that simulates the target from the source. Across five experiments (genomics, vision, reinforcement learning), Le Cam Distortion achieves: (1) near-perfect frequency estimation in HLA genomics (correlation $r=0.999$, matching classical methods), (2) zero source utility loss in CIFAR-10 image classification (81.2% accuracy preserved vs 34.7% drop for CycleGAN), and (3) safe policy transfer in RL control where invariance-based methods suffer catastrophic collapse. Le Cam Distortion provides the first principled framework for risk-controlled transfer learning in domains where negative transfer is unacceptable: medical imaging, autonomous systems, and precision medicine.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the challenge of distribution shift in machine learning by proposing a decision-theoretic framework called Le Cam Distortion. This framework uses Le Cam&#x27;s theory of statistical experiments to replace feature invariance with directional simulability, aiming to prevent information destruction in transfer learning. Key experimental results show that Le Cam Distortion achieves near-perfect frequency estimation in genomics, preserves source utility in image classification, and ensures safe policy transfer in reinforcement learning, outperforming invariance-based methods in safety-critical applications.</div>
<div class="mono" style="margin-top:8px">论文提出了一种基于Le Cam统计实验理论的决策框架Le Cam Distortion，用方向可模拟性替代了特征不变性，以解决机器学习中的分布偏移问题。该方法避免了在信息量不均衡的领域出现的负面转移问题。跨基因组学、视觉和强化学习的实验表明，Le Cam Distortion实现了近乎完美的频率估计，保持了源数据的分类性能，并在强化学习控制中实现了安全的策略转移，优于基于不变性的方法在转移风险控制方面的表现。</div>
</details>
</div>
<div class="card">
<div class="title">Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing</div>
<div class="meta-line">Authors: Yuwen Li, Wei Zhang, Zelong Huang, Mason Yang, Jiajun Wu, Shawn Guo, Huahao Hu, Lingyi Sun, Jian Yang, Mingjie Tang, Byran Dai</div>
<div class="meta-line">First: 2025-12-29T17:12:39+00:00 · Latest: 2025-12-29T17:12:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23611v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23611v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Enabling Large Language Models (LLMs) to reliably invoke external tools remains a critical bottleneck for autonomous agents. Existing approaches suffer from three fundamental challenges: expensive human annotation for high-quality trajectories, poor generalization to unseen tools, and quality ceilings inherent in single-model synthesis that perpetuate biases and coverage gaps. We introduce InfTool, a fully autonomous framework that breaks these barriers through self-evolving multi-agent synthesis. Given only raw API specifications, InfTool orchestrates three collaborative agents (User Simulator, Tool-Calling Assistant, and MCP Server) to generate diverse, verified trajectories spanning single-turn calls to complex multi-step workflows. The framework establishes a closed loop: synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, the improved model generates higher-quality data targeting capability gaps, and this cycle iterates without human intervention. Experiments on the Berkeley Function-Calling Leaderboard (BFCL) demonstrate that InfTool transforms a base 32B model from 19.8% to 70.9% accuracy (+258%), surpassing models 10x larger and rivaling Claude-Opus, and entirely from synthetic data without human annotation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>闭合循环：通过多智能体角色扮演合成无限工具使用数据</div>
<div class="mono" style="margin-top:8px">使大型语言模型（LLMs）可靠地调用外部工具仍然是自主代理的关键瓶颈。现有方法面临三个根本挑战：高质量轨迹昂贵的人工注释、对未见过的工具的泛化能力差以及单模型合成固有的质量上限，这些上限会延续偏见和覆盖范围缺口。我们引入了InfTool，这是一种完全自主的框架，通过自我进化的多智能体合成打破了这些障碍。仅给定原始API规范，InfTool 就能协调三个协作智能体（用户模拟器、工具调用助手和MCP服务器）生成从单轮调用到复杂多步骤工作流的多样且验证过的轨迹。该框架建立了一个闭合循环：合成的数据通过门控奖励与组相对策略优化（GRPO）训练模型，改进后的模型生成更高质量的数据以针对能力缺口，这个循环无需人工干预即可迭代进行。在伯克利函数调用排行榜（BFCL）上的实验表明，InfTool 将基础32B模型的准确率从19.8%提高到70.9%（+258%），超过了大10倍的模型，并且与Claude-Opus相当，这一切都完全来自合成数据，无需人工注释。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to enable large language models to reliably use external tools, addressing challenges of expensive human annotation, poor generalization, and quality ceilings. InfTool, a self-evolving multi-agent framework, synthesizes diverse tool-use data through three collaborative agents. The framework uses Group Relative Policy Optimization (GRPO) with gated rewards to iteratively improve model performance. Experiments show InfTool significantly boosts accuracy from 19.8% to 70.9% on the BFCL, surpassing larger models and rivaling Claude-Opus, all from synthetic data without human annotation.</div>
<div class="mono" style="margin-top:8px">研究旨在解决使大型语言模型有效使用外部工具的问题，这对于自主代理至关重要。提出了InfTool，这是一种无需人工注释即可生成多样化工具使用轨迹的自进化多代理框架。该框架使用组相对策略优化（GRPO）来迭代提升模型性能，关闭能力缺口。实验表明，InfTool将一个32B模型在伯克利函数调用排行榜上的准确性从19.8%提升到70.9%，超越了更大规模的模型，并且完全通过合成数据生成实现了与Claude-Opus相当的性能。</div>
</details>
</div>
<div class="card">
<div class="title">OM4OV: Leveraging Ontology Matching for Ontology Versioning</div>
<div class="meta-line">Authors: Zhangcheng Qiang, Kerry Taylor, Weiqing Wang</div>
<div class="meta-line">First: 2024-09-30T14:00:04+00:00 · Latest: 2025-12-29T17:05:52+00:00</div>
<div class="meta-line">Comments: 16 pages, 8 figures, 1 table</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2409.20302v7">Abs</a> · <a href="https://arxiv.org/pdf/2409.20302v7">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Due to the dynamic nature of the Semantic Web, version control is necessary to manage changes in widely used ontologies. Despite the long-standing recognition of ontology versioning (OV) as a crucial component of efficient ontology management, many approaches treat OV as similar to ontology matching (OM) and directly reuse OM systems for OV tasks. In this study, we systematically analyse similarities and differences between OM and OV and formalise the OM4OV pipeline to offer more advanced OV support. The pipeline is implemented and evaluated in the state-of-the-art OM system Agent-OM. The experimental results indicate that OM systems can be reused for OV tasks, but without necessary extensions, the current OM4OV pipeline can produce skewed measurements, poor performance in detecting update entities, and limited explainability of false mappings. To tackle these issues, we propose an optimisation method called the cross-reference (CR) mechanism, which builds on existing OM alignments to reduce the number of matching candidates and to improve overall OV performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>OM4OV：利用本体匹配进行本体版本管理</div>
<div class="mono" style="margin-top:8px">由于语义网的动态性质，版本控制对于管理广泛使用的本体中的更改是必要的。尽管本体版本管理（OV）作为有效本体管理的关键组成部分已有长期的认识，但许多方法仍将OV视为类似于本体匹配（OM），并直接重用OM系统来执行OV任务。在本研究中，我们系统地分析了OM和OV之间的相似性和差异，并形式化了OM4OV管道，以提供更高级的OV支持。该管道在最先进的OM系统Agent-OM中实现和评估。实验结果表明，OM系统可以重用于OV任务，但如果没有必要的扩展，当前的OM4OV管道会产生失真的测量结果，检测更新实体的性能较差，并且对错误映射的解释能力有限。为了解决这些问题，我们提出了一种优化方法，称为交叉引用（CR）机制，该机制基于现有的OM对齐来减少匹配候选的数量，并提高整体的OV性能。</div>
</details>
</div>
<div class="card">
<div class="title">The Big Three in Marriage Talk: LLM-Assisted Analysis of Moral Ethics and Sentiment on Weibo and Xiaohongshu</div>
<div class="meta-line">Authors: Frank Tian-Fang Ye, Xiaozi Gao</div>
<div class="meta-line">First: 2025-12-29T17:05:06+00:00 · Latest: 2025-12-29T17:05:06+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23609v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23609v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">China&#x27;s marriage registrations have declined dramatically, dropping from 13.47 million couples in 2013 to 6.1 million in 2024. Understanding public attitudes toward marriage requires examining not only emotional sentiment but also the moral reasoning underlying these evaluations. This study analyzed 219,358 marriage-related posts from two major Chinese social media platforms (Sina Weibo and Xiaohongshu) using large language model (LLM)-assisted content analysis. Drawing on Shweder&#x27;s Big Three moral ethics framework, posts were coded for sentiment (positive, negative, neutral) and moral dimensions (Autonomy, Community, Divinity). Results revealed platform differences: Weibo discourse skewed positive, while Xiaohongshu was predominantly neutral. Most posts across both platforms lacked explicit moral framing. However, when moral ethics were invoked, significant associations with sentiment emerged. Posts invoking Autonomy ethics and Community ethics were predominantly negative, whereas Divinity-framed posts tended toward neutral or positive sentiment. These findings suggest that concerns about both personal autonomy constraints and communal obligations drive negative marriage attitudes in contemporary China. The study demonstrates LLMs&#x27; utility for scaling qualitative analysis and offers insights for developing culturally informed policies addressing marriage decline in Chinese contexts.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>婚姻对话中的三大要素：大语言模型辅助分析微博和小红书上的道德伦理与情感</div>
<div class="mono" style="margin-top:8px">中国婚姻登记人数大幅下降，从2013年的1347万对下降到2024年的610万对。理解公众对婚姻的态度不仅需要考察情感倾向，还需要分析这些评价背后的道德推理。本研究使用大语言模型（LLM）辅助内容分析，从两个主要的中国社交媒体平台（新浪微博和小红书）中分析了219,358条与婚姻相关的内容。基于Shweder的三大道德伦理框架，帖子被编码为情感（正面、负面、中性）和道德维度（自主、社群、神性）。研究结果表明，两个平台存在差异：微博上的讨论偏向正面，而小红书则主要为中性。两个平台上的大多数帖子缺乏明确的道德框架。然而，当涉及道德伦理时，情感倾向与道德伦理之间出现了显著关联。涉及自主伦理和社群伦理的帖子主要为负面，而神性框架的帖子则倾向于中性或正面情感。这些发现表明，个人自主权的限制和社群义务的担忧在中国当代社会中驱动着负面的婚姻态度。本研究展示了LLM在扩大定性分析方面的实用性，并为制定针对中国婚姻下降趋势的文化导向政策提供了见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study analyzed 219,358 marriage-related posts from Weibo and Xiaohongshu using LLM-assisted content analysis to understand public attitudes toward marriage. The research found that Weibo discourse was more positive, while Xiaohongshu was predominantly neutral. When moral ethics were invoked, posts framed by Autonomy and Community ethics were predominantly negative, while Divinity-framed posts tended toward neutral or positive sentiment. This suggests that concerns about personal autonomy and communal obligations drive negative marriage attitudes in China. The study highlights the utility of LLMs for qualitative analysis in large-scale social media data.</div>
<div class="mono" style="margin-top:8px">该研究使用LLM辅助内容分析了来自微博和小红书的219,358条婚姻相关帖子，以了解公众对婚姻的态度。研究发现，微博上的讨论更积极，而小红书则主要是中性的。当涉及道德伦理时，强调个人自主和社区义务的帖子大多持负面态度，而涉及神性的帖子则倾向于中性或积极的态度。这表明，个人自主权受限和社区义务感是中国当代婚姻态度消极的原因。该研究强调了LLM在定性分析中的应用价值，并为解决中国婚姻下降问题提供了文化背景下的见解。</div>
</details>
</div>
<div class="card">
<div class="title">Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation</div>
<div class="meta-line">Authors: Manh Hung Nguyen, Adish Singla</div>
<div class="meta-line">First: 2025-12-29T16:53:48+00:00 · Latest: 2025-12-29T16:53:48+00:00</div>
<div class="meta-line">Comments: Preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23601v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23601v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind&#x27;&#x27; effect, where they generate similar responses within the same model and produce homogeneous outputs across different models. As a consequence, students may be exposed to overly similar and repetitive LLM-generated problems, which harms diversity of thought. Drawing inspiration from Wallas&#x27;s theory of creativity and Guilford&#x27;s framework of divergent-convergent thinking, we propose CreativeDC, a two-phase prompting method that explicitly scaffolds the LLM&#x27;s reasoning into distinct phases. By decoupling creative exploration from constraint satisfaction, our method enables LLMs to explore a broader space of ideas before committing to a final problem. We evaluate CreativeDC for creative problem generation using a comprehensive set of metrics that capture diversity, novelty, and utility. The results show that CreativeDC achieves significantly higher diversity and novelty compared to baselines while maintaining high utility. Moreover, scaling analysis shows that CreativeDC generates a larger effective number of distinct problems as more are sampled, increasing at a faster rate than baseline methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大型语言模型中的发散-收敛思维在创造性问题生成中的应用</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）在生成教育性问题和题目方面具有巨大潜力，使教育者能够创建大规模的学习材料。然而，LLMs 本质上受到“人工蜂群”效应的限制，这种效应导致它们在同一个模型中生成相似的响应，并在不同模型中产生同质的输出。因此，学生可能会接触到过多相似和重复的LLM生成的问题，这损害了思维的多样性。借鉴Wallas的创造力理论和Guilford的发散-收敛思维框架，我们提出了一种名为CreativeDC的两阶段提示方法，该方法明确地将LLM的推理分为不同的阶段。通过将创造性探索与约束满足解耦，我们的方法使LLM能够在最终确定问题之前探索更广泛的想法空间。我们使用一系列全面的度量标准评估了CreativeDC在创造性问题生成中的表现，这些度量标准涵盖了多样性和新颖性以及实用性。结果显示，CreativeDC在多样性和新颖性方面显著优于基线方法，同时保持了高实用性。此外，扩展分析表明，随着采样的增加，CreativeDC生成的具有独特性的问题数量更多，增长速度也快于基线方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the issue of homogeneity in responses generated by large language models (LLMs) for educational purposes. It proposes CreativeDC, a two-phase prompting method inspired by creativity theories, to enhance diversity and novelty in generated problems. The method decouples creative exploration from constraint satisfaction, allowing LLMs to explore a broader range of ideas before finalizing problems. Experimental results show that CreativeDC outperforms baseline methods in terms of diversity and novelty while maintaining utility. Additionally, scaling analysis indicates that CreativeDC generates a larger number of distinct problems more efficiently.</div>
<div class="mono" style="margin-top:8px">论文针对大型语言模型（LLMs）在生成教育问题时存在的局限性，即生成的问题过于相似和重复，提出了CreativeDC，这是一种受创造力理论启发的两阶段提示方法，旨在增强问题生成的多样性和新颖性。该方法将创造性探索与约束满足分离，使LLMs能够在最终确定问题之前探索更广泛的想法空间。实验结果表明，CreativeDC在多样性和新颖性方面优于基线方法，同时保持了实用性，并且在生成独特问题方面具有更好的扩展性。</div>
</details>
</div>
<div class="card">
<div class="title">Scalable Residual Feature Aggregation Framework with Hybrid Metaheuristic Optimization for Robust Early Pancreatic Neoplasm Detection in Multimodal CT Imaging</div>
<div class="meta-line">Authors: Janani Annur Thiruvengadam, Kiran Mayee Nabigaru, Anusha Kovi</div>
<div class="meta-line">First: 2025-12-29T16:51:13+00:00 · Latest: 2025-12-29T16:51:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23597v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23597v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The early detection of pancreatic neoplasm is a major clinical dilemma, and it is predominantly so because tumors are likely to occur with minimal contrast margins and a large spread anatomy-wide variation amongst patients on a CT scan. These complexities require to be addressed with an effective and scalable system that can assist in enhancing the salience of the subtle visual cues and provide a high level of the generalization on the multimodal imaging data. A Scalable Residual Feature Aggregation (SRFA) framework is proposed to be used to meet these conditions in this study. The framework integrates a pipeline of preprocessing followed by the segmentation using the MAGRes-UNet that is effective in making the pancreatic structures and isolating regions of interest more visible. DenseNet-121 performed with residual feature storage is used to extract features to allow deep hierarchical features to be aggregated without properties loss. To go further, hybrid HHO-BA metaheuristic feature selection strategy is used, which guarantees the best feature subset refinement. To be classified, the system is trained based on a new hybrid model that integrates the ability to pay attention on the world, which is the Vision Transformer (ViT) with the high representational efficiency of EfficientNet-B3. A dual optimization mechanism incorporating SSA and GWO is used to fine-tune hyperparameters to enhance greater robustness and less overfitting. Experimental results support the significant improvement in performance, with the suggested model reaching 96.23% accuracy, 95.58% F1-score and 94.83% specificity, the model is significantly better than the traditional CNNs and contemporary transformer-based models. Such results highlight the possibility of the SRFA framework as a useful instrument in the early detection of pancreatic tumors.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于混合元启发式优化的可扩展残差特征聚合框架在多模态CT影像中稳健早期胰腺肿瘤检测</div>
<div class="mono" style="margin-top:8px">胰腺肿瘤的早期检测是临床的一大难题，主要是因为肿瘤可能在CT扫描中表现出微小的对比边缘和广泛的解剖变异。这些复杂性需要通过一个有效且可扩展的系统来解决，该系统能够增强细微视觉线索的显著性并提供对多模态影像数据的高度泛化能力。在本研究中，提出了一种可扩展残差特征聚合（SRFA）框架来满足这些条件。该框架结合了预处理管道和使用MAGRes-UNet进行分割，以使胰腺结构更加明显并隔离感兴趣区域。使用具有残差特征存储的DenseNet-121提取特征，以允许在不损失属性的情况下进行深层层次特征聚合。进一步地，使用混合HHO-BA元启发式特征选择策略，以确保最佳特征子集的细化。基于结合了注意力机制的Vision Transformer（ViT）与高效能的EfficientNet-B3的新混合模型进行训练。采用结合SSA和GWO的双重优化机制来微调超参数，以增强鲁棒性并减少过拟合。实验结果支持显著的性能改进，所建议的模型达到96.23%的准确率、95.58%的F1分数和94.83%的特异性，该模型明显优于传统CNN和当前的基于变换器的模型。这些结果突显了SRFA框架作为早期胰腺肿瘤检测有用工具的可能性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study addresses the challenge of early pancreatic neoplasm detection in CT imaging, where tumors are often subtle and patient anatomy varies widely. It proposes a Scalable Residual Feature Aggregation (SRFA) framework that includes preprocessing, segmentation using MAGRes-UNet, and feature extraction with DenseNet-121. Hybrid HHO-BA optimization is used for feature selection, and the model is trained with a hybrid Vision Transformer (ViT) and EfficientNet-B3. The results show significant improvements, with the model achieving 96.23% accuracy, 95.58% F1-score, and 94.83% specificity, outperforming traditional CNNs and contemporary transformer-based models.</div>
<div class="mono" style="margin-top:8px">研究旨在解决CT扫描中胰腺肿瘤早期检测的难题，其中肿瘤往往微小且患者间差异大。研究提出了一种可扩展的残差特征聚合（SRFA）框架，包括预处理、使用MAGRes-UNet进行分割和使用DenseNet-121进行特征提取。通过混合HHO-BA元启发式优化进行特征选择，并使用结合Vision Transformer (ViT)和EfficientNet-B3的混合模型进行训练，结合了SSA和GWO的双重优化机制。实验结果显示，该模型在准确率、F1分数和特异性方面分别达到了96.23%、95.58%和94.83%，显著优于传统CNN和当代基于变换器的模型。</div>
</details>
</div>
<div class="card">
<div class="title">How Safe Are AI-Generated Patches? A Large-scale Study on Security Risks in LLM and Agentic Automated Program Repair on SWE-bench</div>
<div class="meta-line">Authors: Amirali Sajadi, Kostadin Damevski, Preetha Chatterjee</div>
<div class="meta-line">First: 2025-06-30T21:10:19+00:00 · Latest: 2025-12-29T16:44:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.02976v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.02976v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) and their agentic frameworks are increasingly adopted to perform development tasks such as automated program repair (APR). While prior work has identified security risks in LLM-generated code, most have focused on synthetic, simplified, or isolated tasks that lack the complexity of real-world program repair. In this study, we present the first large-scale security analysis of LLM-generated patches using 20,000+ GitHub issues. We evaluate patches proposed by developers, a standalone LLM (Llama 3.3 Instruct-70B), and three top-performing agentic frameworks (OpenHands, AutoCodeRover, HoneyComb). Finally, we analyze a wide range of code, issue, and project-level factors to understand the conditions under which generating insecure patches is more likely. Our findings reveal that Llama introduces many new vulnerabilities, exhibiting unique patterns not found in developers&#x27; code. Agentic workflows also generate a number of vulnerabilities, particularly when given more autonomy. We find that vulnerabilities in LLM-generated patches are associated with distinctive code characteristics and are commonly observed in issues missing specific types of information. These results suggest that contextual factors play a critical role in the security of the generated patches and point toward the need for proactive risk assessment methods that account for both issue and code-level information.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AI生成补丁的安全性如何？基于SWE-bench的大规模研究</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）及其自主框架越来越多地被用于执行开发任务，如自动程序修复（APR）。尽管先前的工作已经识别出LLM生成代码中的安全风险，但大多数研究都集中在合成、简化或孤立的任务上，缺乏真实世界程序修复的复杂性。在本研究中，我们首次使用20,000多个GitHub问题对LLM生成的补丁进行大规模安全分析。我们评估了开发人员、独立LLM（Llama 3.3 Instruct-70B）和三个表现最佳的自主框架（OpenHands、AutoCodeRover、HoneyComb）提出的补丁。最后，我们分析了代码、问题和项目层面的各种因素，以了解生成不安全补丁的条件。我们的研究发现Llama引入了许多新的漏洞，表现出不同于开发人员代码的独特模式。自主工作流程在获得更多自主权时也会生成大量漏洞。我们发现，LLM生成补丁中的漏洞与特定的代码特征相关，并且通常出现在缺少特定类型信息的问题中。这些结果表明，上下文因素在生成补丁的安全性中起着关键作用，并指出了需要考虑问题和代码层面信息的前瞻性风险评估方法的必要性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates the security risks of AI-generated patches using large language models (LLMs) and agentic frameworks on 20,000+ GitHub issues. It evaluates patches from developers, a standalone LLM, and three agentic frameworks, revealing that LLMs introduce many new vulnerabilities, especially when given more autonomy. The research finds that vulnerabilities in LLM-generated patches are linked to specific code characteristics and missing issue information, highlighting the importance of context in assessing security risks.</div>
<div class="mono" style="margin-top:8px">本研究通过分析20,000+ GitHub 问题，评估了使用大型语言模型（LLMs）和代理框架生成的补丁的安全风险。研究比较了开发人员、独立的LLM以及三种顶级代理框架生成的补丁，发现LLMs引入了许多新的漏洞，尤其是在获得更多自主权时。研究发现，LLM生成的补丁中的漏洞与特定的代码特征和缺失的问题信息有关，强调了评估安全风险时考虑上下文的重要性。</div>
</details>
</div>
<div class="card">
<div class="title">Same or Not? Enhancing Visual Perception in Vision-Language Models</div>
<div class="meta-line">Authors: Damiano Marsili, Aditya Mehta, Ryan Y. Lin, Georgia Gkioxari</div>
<div class="meta-line">First: 2025-12-29T16:43:47+00:00 · Latest: 2025-12-29T16:43:47+00:00</div>
<div class="meta-line">Comments: Project webpage: https://glab-caltech.github.io/twin/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23592v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23592v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://glab-caltech.github.io/twin/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-language models (VLMs) excel at broad visual understanding but remain coarse-grained, exhibit visual biases, and miss subtle visual details. Existing training corpora reinforce this limitation by emphasizing general recognition (&quot;Is it a cat or a dog?&quot;) over fine-grained perception. To address this, we introduce a new training corpus and task designed to enhance the perceptual abilities of VLMs. TWIN is a large-scale dataset of 561,000 image-pair queries that task models to determine whether two visually similar images depict the same object, encouraging attention to nuanced visual cues. The dataset spans a diverse range of everyday objects across contexts, viewpoints, and appearances. Fine-tuning VLMs on TWIN yields notable gains in fine-grained recognition, even on unseen domains such as art, animals, plants, and landmarks. To quantify these gains, we introduce FGVQA, a benchmark suite of 12,000 queries that repurposes fine-grained recognition and retrieval datasets from multiple domains. While existing VLMs struggle on FGVQA, when fine-tuned on TWIN they improve by up to 19.3%, without compromising performance on general VQA benchmarks. Finally, our TWIN dataset scales favorably with object annotations, and our analysis shows that scale is key to performance. We envision TWIN as a drop-in addition to open-source VLM training corpora, advancing perceptual precision of future models. Project webpage: https://glab-caltech.github.io/twin/</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper introduces TWIN, a new dataset of 561,000 image-pair queries designed to enhance the fine-grained perception of vision-language models (VLMs). By focusing on determining whether two visually similar images depict the same object, TWIN encourages models to pay attention to subtle visual details. Fine-tuning VLMs on TWIN improves their performance in fine-grained recognition tasks, even in unseen domains, with up to 19.3% improvement on the FGVQA benchmark without affecting general VQA performance. The dataset&#x27;s scale is crucial for performance, and TWIN is proposed as an addition to VLM training corpora to advance perceptual precision.</div>
<div class="mono" style="margin-top:8px">该论文引入了TWIN，这是一个包含561,000对图像查询的新数据集，旨在增强视觉语言模型（VLM）的细粒度感知能力。通过在TWIN上微调VLM，模型在识别细微视觉差异方面表现出显著改进，甚至在未见过的领域如艺术和地标中也是如此。FGVQA基准测试表明，微调于TWIN的VLM比现有模型在细粒度识别和检索任务上表现更好，最高可提高19.3%，同时不牺牲通用VQA性能。TWIN的规模对于性能至关重要，作者将其视为VLM训练数据集的一个有价值的补充。</div>
</details>
</div>
<div class="card">
<div class="title">Leveraging Large Language Models for Rare Disease Named Entity Recognition</div>
<div class="meta-line">Authors: Nan Miles Xi, Yu Deng, Lin Wang</div>
<div class="meta-line">First: 2025-08-12T20:16:31+00:00 · Latest: 2025-12-29T16:39:56+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.09323v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.09323v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease NER under low-resource settings, using a range of prompt-based strategies including zero-shot prompting, few-shot in-context learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We design a structured prompting framework that encodes domain-specific knowledge and disambiguation rules for four entity types. We further introduce two semantically guided few-shot example selection methods to improve in-context performance while reducing labeling effort. Experiments on the RareDis Corpus show that GPT-4o achieves competitive or superior performance compared to BioClinicalBERT, with task-level fine-tuning yielding the strongest performance among the evaluated approaches and improving upon the previously reported BioClinicalBERT baseline. Cost-performance analysis reveals that few-shot prompting delivers high returns at low token budgets. RAG provides limited overall gains but can improve recall for challenging entity types, especially signs and symptoms. An error taxonomy highlights common failure modes such as boundary drift and type confusion, suggesting opportunities for post-processing and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can serve as effective, scalable alternatives to traditional supervised models in biomedical NER, particularly in rare disease applications where annotated data is scarce.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用大型语言模型进行罕见疾病命名实体识别</div>
<div class="mono" style="margin-top:8px">罕见疾病领域的命名实体识别（NER）由于标注数据有限、实体类型之间的语义模糊以及长尾分布，面临着独特的挑战。本研究评估了GPT-4o在低资源设置下进行罕见疾病NER的能力，使用了零样本提示、少量样本上下文学习、检索增强生成（RAG）和任务级微调等多种提示策略。我们设计了一个结构化的提示框架，编码了四种实体类型的领域特定知识和消歧规则。我们还引入了两种语义引导的少量样本示例选择方法，以提高上下文性能并减少标注工作量。在RareDis语料库上的实验表明，GPT-4o在与BioClinicalBERT的比较中取得了竞争力或更优的性能，任务级微调在评估方法中表现最佳，并且优于之前报告的BioClinicalBERT基线。成本-性能分析显示，少量样本提示在低令牌预算下提供了高回报。RAG总体上提供了有限的增益，但在处理具有挑战性的实体类型时可以提高召回率，尤其是症状和体征。错误分类学揭示了常见的失败模式，如边界漂移和类型混淆，这表明了后处理和混合精炼的机会。我们的结果表明，提示优化的LLM可以作为生物医学NER中传统监督模型的有效、可扩展的替代方案，特别是在标注数据稀缺的罕见疾病应用中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the challenges of Named Entity Recognition (NER) in the rare disease domain by evaluating GPT-4o&#x27;s capabilities under low-resource settings. Various prompt-based strategies, including zero-shot prompting, few-shot in-context learning, retrieval-augmented generation, and task-level fine-tuning, were used. The experiments on the RareDis Corpus show that task-level fine-tuning yields the strongest performance, outperforming the previously reported BioClinicalBERT baseline. Few-shot prompting is cost-effective, while RAG improves recall for challenging entity types. The study identifies common failure modes and suggests opportunities for post-processing and hybrid refinement.</div>
<div class="mono" style="margin-top:8px">研究通过在低资源环境下评估GPT-4o，解决罕见疾病领域命名实体识别（NER）的挑战，使用了多种提示策略。研究引入了结构化提示框架和语义引导的少量样本示例选择方法以提升性能。实验结果显示，GPT-4o的任务级微调在RareDis语料库中优于BioClinicalBERT，少量样本提示在低令牌预算下提供了高回报。检索增强生成（RAG）提供了有限的整体收益，但可以提高难以识别实体类型的召回率。研究还指出了常见的错误模式，并提出了后处理和混合精炼的机会。</div>
</details>
</div>
<div class="card">
<div class="title">Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models</div>
<div class="meta-line">Authors: Yu-Xiang Lin, Cheng-Han Chiang, Hung-yi Lee</div>
<div class="meta-line">First: 2025-12-29T16:23:54+00:00 · Latest: 2025-12-29T16:23:54+00:00</div>
<div class="meta-line">Comments: Work in progress</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23578v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23578v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper, we show that when spoken language models (SLMs) are instructed to speak in a specific speaking style at the beginning of a multi-turn conversation, they cannot maintain the required speaking styles after several turns of interaction; we refer to this as the style amnesia of SLMs. We focus on paralinguistic speaking styles, including emotion, accent, volume, and speaking speed. We evaluate three proprietary and two open-source SLMs, demonstrating that none of these models can maintain a consistent speaking style when instructed to do so. We further show that when SLMs are asked to recall the style instruction in later turns, they can recall the style instruction, but they fail to express it throughout the conversation. We also show that explicitly asking the model to recall the style instruction can partially mitigate style amnesia. In addition, we examine various prompting strategies and find that SLMs struggle to follow the required style when the instruction is placed in system messages rather than user messages, which contradicts the intended function of system prompts.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>风格失忆：多轮对话语音模型风格退化及其缓解研究</div>
<div class="mono" style="margin-top:8px">在本文中，我们展示了当语音模型（SLMs）在多轮对话的开始被指示以特定的说话风格进行交流时，它们在多次交互后无法维持所需的说话风格；我们将这种现象称为SLMs的风格失忆。我们关注副语言风格，包括情感、口音、音量和语速。我们评估了三个专有和两个开源的SLMs，发现这些模型在被指示维持一致的说话风格时都无法做到。我们进一步表明，当要求SLMs在后续轮次中回忆风格指令时，它们能够回忆起风格指令，但在对话中却无法表达出来。我们还表明，明确要求模型回忆风格指令可以部分缓解风格失忆。此外，我们研究了各种提示策略，发现当指令放置在系统消息而非用户消息中时，SLMs难以遵循所需的风格，这与系统提示的预期功能相矛盾。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper investigates the issue of style amnesia in spoken language models (SLMs), where models cannot maintain a specific speaking style after multiple turns of interaction. The study evaluates five SLMs and finds that none can consistently adhere to the instructed style. The research also shows that explicitly reminding the model of the style instruction can help mitigate this issue, but SLMs perform better when the instruction is given in user messages rather than system messages.</div>
<div class="mono" style="margin-top:8px">本文研究了多轮对话中语言模型（SLM）的风格健忘问题，即模型在多次交互后无法保持指定的说话风格。研究评估了五种SLM，发现它们都无法一致地遵循指令的风格。研究还表明，明确提醒模型风格指令可以部分缓解这一问题，但当指令来自用户消息而非系统消息时，模型的表现更好。</div>
</details>
</div>
<div class="card">
<div class="title">LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation</div>
<div class="meta-line">Authors: Ethan Chern, Zhulin Hu, Bohao Tang, Jiadi Su, Steffi Chern, Zhijie Deng, Pengfei Liu</div>
<div class="meta-line">First: 2025-12-29T16:17:36+00:00 · Latest: 2025-12-29T16:17:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23576v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23576v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Real-time video generation via diffusion is essential for building general-purpose multimodal interactive AI systems. However, the simultaneous denoising of all video frames with bidirectional attention via an iterative process in diffusion models prevents real-time interaction. While existing distillation methods can make the model autoregressive and reduce sampling steps to mitigate this, they focus primarily on text-to-video generation, leaving the human-AI interaction unnatural and less efficient. This paper targets real-time interactive video diffusion conditioned on a multimodal context, including text, image, and audio, to bridge the gap. Given the observation that the leading on-policy distillation approach Self Forcing encounters challenges (visual artifacts like flickering, black frames, and quality degradation) with multimodal conditioning, we investigate an improved distillation recipe with emphasis on the quality of condition inputs as well as the initialization and schedule for the on-policy optimization. On benchmarks for multimodal-conditioned (audio, image, and text) avatar video generation including HDTF, AVSpeech, and CelebV-HQ, our distilled model matches the visual quality of the full-step, bidirectional baselines of similar or larger size with 20x less inference cost and latency. Further, we integrate our model with audio language models and long-form video inference technique Anchor-Heavy Identity Sinks to build LiveTalk, a real-time multimodal interactive avatar system. System-level evaluation on our curated multi-turn interaction benchmark shows LiveTalk outperforms state-of-the-art models (Sora2, Veo3) in multi-turn video coherence and content quality, while reducing response latency from 1 to 2 minutes to real-time generation, enabling seamless human-AI multimodal interaction.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LiveTalk: 通过改进的在线策略蒸馏实现实时多模态交互视频扩散</div>
<div class="mono" style="margin-top:8px">通过扩散生成实时视频对于构建通用多模态交互AI系统至关重要。然而，通过迭代过程中的双向注意力同时对所有视频帧进行去噪会妨碍实时交互。虽然现有的蒸馏方法可以使模型自回归并减少采样步骤以缓解这一问题，但它们主要集中在文本到视频生成上，使得人机交互显得不自然且效率较低。本文旨在针对基于多模态上下文（包括文本、图像和音频）的实时交互视频扩散，以弥合这一差距。鉴于观察到领先的在线策略蒸馏方法Self Forcing在多模态条件下遇到挑战（如视觉伪影、黑屏和质量下降），我们研究了一种改进的蒸馏方案，强调条件输入的质量以及在线策略优化的初始化和调度。在包括HDTF、AVSpeech和CelebV-HQ的多模态条件（音频、图像和文本）生成头像视频的基准测试中，我们的蒸馏模型在视觉质量上与全步骤双向基线相当或更大规模的模型相比，推理成本和延迟降低了20倍。此外，我们将模型与音频语言模型和长视频推理技术Anchor-Heavy Identity Sinks结合，构建了LiveTalk实时多模态交互头像系统。在我们编纂的多轮交互基准测试中的系统级评估表明，LiveTalk在多轮视频连贯性和内容质量方面优于最先进的模型（Sora2、Veo3），同时将响应延迟从1到2分钟缩短到实时生成，从而实现无缝的人机多模态交互。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of real-time video generation via diffusion models for multimodal interactive AI systems. It introduces an improved on-policy distillation method to enhance the quality of condition inputs and the initialization and schedule for optimization. The distilled model achieves visual quality comparable to full-step baselines with 20 times less inference cost and latency, and integrates with audio language models and long-form video inference techniques to create LiveTalk, a real-time multimodal interactive avatar system that outperforms state-of-the-art models in multi-turn video coherence and content quality, with reduced response latency to real-time generation.</div>
<div class="mono" style="margin-top:8px">本文针对通过扩散模型进行实时视频生成以构建多模态交互AI系统的挑战，提出了一种改进的在线策略蒸馏方法，以提高条件输入的质量和优化的初始化及调度。蒸馏模型在20倍更低的推理成本和延迟下达到了与全步骤基线相当的视觉质量，并结合了音频语言模型和长视频推理技术，构建了实时多模态交互头像系统LiveTalk，该系统在多轮视频连贯性和内容质量方面优于最先进的模型，响应延迟从1到2分钟缩短至实时生成。</div>
</details>
</div>
<div class="card">
<div class="title">ProGuard: Towards Proactive Multimodal Safeguard</div>
<div class="meta-line">Authors: Shaohan Yu, Lijun Li, Chenyang Si, Lu Sheng, Jing Shao</div>
<div class="meta-line">First: 2025-12-29T16:13:23+00:00 · Latest: 2025-12-29T16:13:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23573v1">Abs</a> · <a href="https://arxiv.org/pdf/2512.23573v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The rapid evolution of generative models has led to a continuous emergence of multimodal safety risks, exposing the limitations of existing defense methods. To address these challenges, we propose ProGuard, a vision-language proactive guard that identifies and describes out-of-distribution (OOD) safety risks without the need for model adjustments required by traditional reactive approaches. We first construct a modality-balanced dataset of 87K samples, each annotated with both binary safety labels and risk categories under a hierarchical multimodal safety taxonomy, effectively mitigating modality bias and ensuring consistent moderation across text, image, and text-image inputs. Based on this dataset, we train our vision-language base model purely through reinforcement learning (RL) to achieve efficient and concise reasoning. To approximate proactive safety scenarios in a controlled setting, we further introduce an OOD safety category inference task and augment the RL objective with a synonym-bank-based similarity reward that encourages the model to generate concise descriptions for unseen unsafe categories. Experimental results show that ProGuard achieves performance comparable to closed-source large models on binary safety classification, substantially outperforms existing open-source guard models on unsafe content categorization. Most notably, ProGuard delivers a strong proactive moderation ability, improving OOD risk detection by 52.6% and OOD risk description by 64.8%.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ProGuard：面向主动多模态保护</div>
<div class="mono" style="margin-top:8px">生成模型的快速进化导致了持续出现的多模态安全风险，暴露了现有防御方法的局限性。为应对这些挑战，我们提出了ProGuard，这是一种视觉-语言主动保护，能够在无需传统反应式方法所需的模型调整的情况下，识别和描述离分布（OOD）的安全风险。我们首先构建了一个包含87,000个样本的模态平衡数据集，每个样本都标注了二元安全标签和在多模态安全分类学下的风险类别，有效缓解了模态偏差，确保了文本、图像和图文输入的一致性审查。基于此数据集，我们通过强化学习（RL）训练我们的视觉-语言基础模型，以实现高效和简洁的推理。为了在受控环境中模拟主动安全场景，我们进一步引入了离分布安全类别推断任务，并通过基于同义词库的相似度奖励来增强RL目标，鼓励模型为未见过的不安全类别生成简洁描述。实验结果表明，ProGuard在二元安全分类上的性能与闭源大型模型相当，在不安全内容分类上显著优于现有开源保护模型。最值得注意的是，ProGuard提供了强大的主动审查能力，将离分布风险检测提高了52.6%，离分布风险描述提高了64.8%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">ProGuard is designed to address the emerging multimodal safety risks in generative models by identifying and describing out-of-distribution (OOD) risks without model adjustments. It uses a modality-balanced dataset of 87K samples, each annotated with safety labels and risk categories, and trains a vision-language model via reinforcement learning to generate concise descriptions. ProGuard outperforms existing open-source guard models in unsafe content categorization and shows a strong proactive moderation ability, improving OOD risk detection and description by 52.6% and 64.8%, respectively.</div>
<div class="mono" style="margin-top:8px">ProGuard 是一种使用模态平衡数据集和强化学习构建的主动多模态安全防护系统，能够识别和描述超出分布的安全风险。它在二元安全分类上的性能与闭源大型模型相当，并在不安全内容分类上优于现有开源防护模型。特别地，ProGuard 将超出分布的风险检测能力提高了 52.6%，风险描述能力提高了 64.8%。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20251231_0326.html">20251231_0326</a>
<a href="archive/20251230_0324.html">20251230_0324</a>
<a href="archive/20251229_0320.html">20251229_0320</a>
<a href="archive/20251228_0323.html">20251228_0323</a>
<a href="archive/20251227_0321.html">20251227_0321</a>
<a href="archive/20251226_0320.html">20251226_0320</a>
<a href="archive/20251225_0320.html">20251225_0320</a>
<a href="archive/20251224_0323.html">20251224_0323</a>
<a href="archive/20251223_0323.html">20251223_0323</a>
<a href="archive/20251222_0320.html">20251222_0320</a>
<a href="archive/20251221_0320.html">20251221_0320</a>
<a href="archive/20251220_0323.html">20251220_0323</a>
<a href="archive/20251219_0323.html">20251219_0323</a>
<a href="archive/20251218_0335.html">20251218_0335</a>
<a href="archive/20251217_0324.html">20251217_0324</a>
<a href="archive/20251216_0325.html">20251216_0325</a>
<a href="archive/20251215_1246.html">20251215_1246</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
